"""
Foolboxå®˜æ–¹æ”»å‡»æ–¹æ³•çš„å°è£…
ä½¿ç”¨å®˜æ–¹å®ç°ç¡®ä¿baselineçš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦
"""

import torch
import numpy as np
import foolbox as fb
from foolbox.attacks import FGSM, PGD, L2DeepFoolAttack, BoundaryAttack, L2CarliniWagnerAttack


def create_foolbox_model(model, bounds=(0, 1), preprocessing=None):
    """
    åˆ›å»ºFoolboxæ¨¡å‹åŒ…è£…å™¨
    
    Args:
        model: PyTorchæ¨¡å‹
        bounds: è¾“å…¥èŒƒå›´
        preprocessing: é¢„å¤„ç†å­—å…¸
    """
    if preprocessing is None:
        # CIFAR-10çš„æ ‡å‡†åŒ–å‚æ•°
        preprocessing = {
            'mean': [0.5, 0.5, 0.5],
            'std': [0.5, 0.5, 0.5],
            'axis': -3  # channels first
        }
    
    fmodel = fb.PyTorchModel(model, bounds=bounds, preprocessing=preprocessing)
    return fmodel


def foolbox_jsma_attack(image, label, model, max_pixels=5, device='cuda'):
    """
    ä½¿ç”¨Foolboxçš„å®˜æ–¹JSMAå®ç°
    æ³¨æ„ï¼šFoolbox 3.x æ²¡æœ‰ç›´æ¥çš„JSMAå®ç°ï¼Œæˆ‘ä»¬ä½¿ç”¨DeepFoolä½œä¸ºæ›¿ä»£
    
    Args:
        image: è¾“å…¥å›¾åƒ [C, H, W]
        label: çœŸå®æ ‡ç­¾
        model: PyTorchæ¨¡å‹
        max_pixels: æœ€å¤§ä¿®æ”¹åƒç´ æ•°ï¼ˆç”¨äºåå¤„ç†ï¼‰
        device: è®¾å¤‡
    
    Returns:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ ä½ç½®åˆ—è¡¨
    """
    # æ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        initial_output = model(image.unsqueeze(0))
        initial_pred = initial_output.argmax(dim=1).item()
        
        if initial_pred != label:
            return False, image, []
    
    # åˆ›å»ºFoolboxæ¨¡å‹
    fmodel = create_foolbox_model(model)
    
    # DeepFoolæ˜¯ä¸€ä¸ªå¥½çš„æ›¿ä»£æ–¹æ¡ˆï¼ˆè¿­ä»£å¼ï¼Œä¿®æ”¹è¾ƒå°‘åƒç´ ï¼‰
    attack = L2DeepFoolAttack()
    
    # è½¬æ¢ä¸ºnumpy
    image_np = image.cpu().numpy()
    label_np = np.array([label])
    
    # æ‰§è¡Œæ”»å‡»
    try:
        _, adv_np, success = attack(fmodel, image_np[np.newaxis, ...], label_np, epsilons=None)
        
        if not success[0]:
            return False, image, []
        
        # è½¬æ¢å›torch
        adv_image = torch.from_numpy(adv_np[0]).to(device)
        
        # éªŒè¯æ”»å‡»æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                return False, image, []
        
        # æ‰¾åˆ°ä¿®æ”¹çš„åƒç´ 
        diff = torch.abs(adv_image - image)
        modified_mask = diff.sum(dim=0) > 1e-6
        modified_pixels = modified_mask.nonzero(as_tuple=False).cpu().tolist()
        
        return True, adv_image, modified_pixels
        
    except Exception as e:
        print(f"Foolbox DeepFoolæ”»å‡»å¤±è´¥: {e}")
        return False, image, []


def foolbox_boundary_attack(image, label, model, max_iterations=100, device='cuda'):
    """
    ä½¿ç”¨Foolboxçš„Boundary Attackï¼ˆå†³ç­–è¾¹ç•Œæ”»å‡»ï¼Œé€‚åˆç¨€ç–æ”»å‡»ï¼‰
    
    Args:
        image: è¾“å…¥å›¾åƒ [C, H, W]
        label: çœŸå®æ ‡ç­¾
        model: PyTorchæ¨¡å‹
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        device: è®¾å¤‡
    
    Returns:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ ä½ç½®åˆ—è¡¨
    """
    # æ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        initial_output = model(image.unsqueeze(0))
        initial_pred = initial_output.argmax(dim=1).item()
        
        if initial_pred != label:
            return False, image, []
    
    # åˆ›å»ºFoolboxæ¨¡å‹
    fmodel = create_foolbox_model(model)
    
    # Boundary Attack
    attack = BoundaryAttack(steps=max_iterations)
    
    # è½¬æ¢ä¸ºnumpy
    image_np = image.cpu().numpy()
    label_np = np.array([label])
    
    # æ‰§è¡Œæ”»å‡»
    try:
        _, adv_np, success = attack(fmodel, image_np[np.newaxis, ...], label_np, epsilons=None)
        
        if not success[0]:
            return False, image, []
        
        # è½¬æ¢å›torch
        adv_image = torch.from_numpy(adv_np[0]).to(device)
        
        # éªŒè¯æ”»å‡»æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                return False, image, []
        
        # æ‰¾åˆ°ä¿®æ”¹çš„åƒç´ 
        diff = torch.abs(adv_image - image)
        modified_mask = diff.sum(dim=0) > 1e-6
        modified_pixels = modified_mask.nonzero(as_tuple=False).cpu().tolist()
        
        return True, adv_image, modified_pixels
        
    except Exception as e:
        print(f"Foolbox Boundaryæ”»å‡»å¤±è´¥: {e}")
        return False, image, []


def foolbox_cw_attack(image, label, model, confidence=0, max_iterations=100, device='cuda'):
    """
    ä½¿ç”¨Foolboxçš„C&W L2æ”»å‡»
    
    Args:
        image: è¾“å…¥å›¾åƒ [C, H, W]
        label: çœŸå®æ ‡ç­¾
        model: PyTorchæ¨¡å‹
        confidence: ç½®ä¿¡åº¦å‚æ•°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        device: è®¾å¤‡
    
    Returns:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ ä½ç½®åˆ—è¡¨
    """
    # æ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        initial_output = model(image.unsqueeze(0))
        initial_pred = initial_output.argmax(dim=1).item()
        
        if initial_pred != label:
            return False, image, []
    
    # åˆ›å»ºFoolboxæ¨¡å‹
    fmodel = create_foolbox_model(model)
    
    # C&W Attack
    attack = L2CarliniWagnerAttack(
        binary_search_steps=9,
        steps=max_iterations,
        stepsize=0.01,
        confidence=confidence,
        initial_const=0.001,
        abort_early=True
    )
    
    # è½¬æ¢ä¸ºnumpy
    image_np = image.cpu().numpy()
    label_np = np.array([label])
    
    # æ‰§è¡Œæ”»å‡»
    try:
        _, adv_np, success = attack(fmodel, image_np[np.newaxis, ...], label_np, epsilons=None)
        
        if not success[0]:
            return False, image, []
        
        # è½¬æ¢å›torch
        adv_image = torch.from_numpy(adv_np[0]).to(device)
        
        # éªŒè¯æ”»å‡»æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                return False, image, []
        
        # æ‰¾åˆ°ä¿®æ”¹çš„åƒç´ 
        diff = torch.abs(adv_image - image)
        modified_mask = diff.sum(dim=0) > 1e-6
        modified_pixels = modified_mask.nonzero(as_tuple=False).cpu().tolist()
        
        return True, adv_image, modified_pixels
        
    except Exception as e:
        print(f"Foolbox C&Wæ”»å‡»å¤±è´¥: {e}")
        return False, image, []


def foolbox_fgsm_attack(image, label, model, epsilon=0.1, device='cuda'):
    """
    ä½¿ç”¨Foolboxçš„FGSMæ”»å‡»
    
    Args:
        image: è¾“å…¥å›¾åƒ [C, H, W]
        label: çœŸå®æ ‡ç­¾
        model: PyTorchæ¨¡å‹
        epsilon: æ‰°åŠ¨å¤§å°
        device: è®¾å¤‡
    
    Returns:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ ä½ç½®åˆ—è¡¨
    """
    # æ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        initial_output = model(image.unsqueeze(0))
        initial_pred = initial_output.argmax(dim=1).item()
        
        if initial_pred != label:
            return False, image, []
    
    # åˆ›å»ºFoolboxæ¨¡å‹
    fmodel = create_foolbox_model(model)
    
    # FGSM Attack
    attack = FGSM()
    
    # è½¬æ¢ä¸ºnumpy
    image_np = image.cpu().numpy()
    label_np = np.array([label])
    
    # æ‰§è¡Œæ”»å‡»
    try:
        _, adv_np, success = attack(fmodel, image_np[np.newaxis, ...], label_np, epsilons=epsilon)
        
        if not success[0]:
            return False, image, []
        
        # è½¬æ¢å›torch
        adv_image = torch.from_numpy(adv_np[0]).to(device)
        
        # éªŒè¯æ”»å‡»æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                return False, image, []
        
        # æ‰¾åˆ°ä¿®æ”¹çš„åƒç´ 
        diff = torch.abs(adv_image - image)
        modified_mask = diff.sum(dim=0) > 1e-6
        modified_pixels = modified_mask.nonzero(as_tuple=False).cpu().tolist()
        
        return True, adv_image, modified_pixels
        
    except Exception as e:
        print(f"Foolbox FGSMæ”»å‡»å¤±è´¥: {e}")
        return False, image, []


# ä½¿ç”¨è¯´æ˜
if __name__ == "__main__":
    print("=" * 80)
    print("ğŸ“š Foolboxå®˜æ–¹æ”»å‡»æ–¹æ³•å°è£…")
    print("=" * 80)
    print("""
    æœ¬æ¨¡å—æä¾›äº†ä»¥ä¸‹Foolboxå®˜æ–¹æ”»å‡»æ–¹æ³•çš„å°è£…ï¼š
    
    1. DeepFool Attack (æ›¿ä»£JSMA)
       - è¿­ä»£å¼æ”»å‡»ï¼Œå¯»æ‰¾æœ€å°æ‰°åŠ¨
       - é€‚åˆç¨€ç–æ”»å‡»åœºæ™¯
       - ä½¿ç”¨: foolbox_jsma_attack()
    
    2. Boundary Attack
       - å†³ç­–è¾¹ç•Œæ”»å‡»
       - ä¸éœ€è¦æ¢¯åº¦ä¿¡æ¯
       - ä½¿ç”¨: foolbox_boundary_attack()
    
    3. C&W L2 Attack
       - ç»å…¸çš„ä¼˜åŒ–åŸºæ”»å‡»
       - ç”Ÿæˆé«˜è´¨é‡å¯¹æŠ—æ ·æœ¬
       - ä½¿ç”¨: foolbox_cw_attack()
    
    4. FGSM Attack
       - å¿«é€Ÿæ¢¯åº¦ç¬¦å·æ”»å‡»
       - æœ€å¿«çš„æ”»å‡»æ–¹æ³•
       - ä½¿ç”¨: foolbox_fgsm_attack()
    
    æ¨èç”¨äºè®ºæ–‡å¯¹æ¯”ï¼š
    - DeepFool: ä½œä¸ºJSMAçš„æ›¿ä»£ï¼ˆFoolbox 3.xæ²¡æœ‰JSMAï¼‰
    - C&W: ç»å…¸å¼ºåŸºå‡†
    - Boundary: é»‘ç›’æ”»å‡»åŸºå‡†
    """)

