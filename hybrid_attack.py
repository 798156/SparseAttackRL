# hybrid_attack.py
"""
æ··åˆæ”»å‡»ç­–ç•¥ï¼šç»“åˆ RL å’Œ JSMA
æ ¸å¿ƒæ€æƒ³ï¼šç”¨JSMAå¿«é€Ÿé€¼è¿‘ï¼Œç”¨RLç²¾ç»†ä¼˜åŒ–
"""

import torch
import numpy as np
from jsma_attack import jsma_attack, compute_jacobian, compute_saliency_map


class HybridAttackStrategy:
    """
    æ··åˆæ”»å‡»ç­–ç•¥
    
    ç­–ç•¥ï¼š
    - å‰æœŸï¼šä½¿ç”¨JSMAå¿«é€Ÿé€‰æ‹©é«˜å½±å“åŠ›çš„åƒç´ 
    - åæœŸï¼šä½¿ç”¨RLè¿›è¡Œç²¾ç»†è°ƒæ•´
    """
    
    def __init__(self, rl_agent, model, max_steps=5, rl_ratio_schedule='dynamic'):
        """
        å‚æ•°:
            rl_agent: è®­ç»ƒå¥½çš„RLæ™ºèƒ½ä½“
            model: ç›®æ ‡æ¨¡å‹
            max_steps: æœ€å¤§æ”»å‡»æ­¥æ•°
            rl_ratio_schedule: RLä½¿ç”¨æ¯”ä¾‹è°ƒåº¦
                - 'static': å›ºå®šæ¯”ä¾‹ (0.5)
                - 'increasing': é€’å¢ (0.3 -> 0.7 -> 1.0)
                - 'dynamic': æ ¹æ®ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´
        """
        self.rl_agent = rl_agent
        self.model = model
        self.max_steps = max_steps
        self.rl_ratio_schedule = rl_ratio_schedule
        self.device = next(model.parameters()).device
    
    def attack(self, image, label, verbose=False):
        """
        æ‰§è¡Œæ··åˆæ”»å‡»
        
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ (C, H, W)
            label: çœŸå®æ ‡ç­¾
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            success: æ˜¯å¦æˆåŠŸ
            adv_image: å¯¹æŠ—æ ·æœ¬
            modified_pixels: ä¿®æ”¹çš„åƒç´ åˆ—è¡¨
            method_used: æ¯æ­¥ä½¿ç”¨çš„æ–¹æ³•
        """
        adv_image = image.clone().to(self.device)
        modified_pixels = []
        method_used = []
        
        for step in range(self.max_steps):
            # æ£€æŸ¥æ˜¯å¦å·²ç»æˆåŠŸ
            with torch.no_grad():
                output = self.model(adv_image.unsqueeze(0))
                pred = output.argmax(dim=1).item()
                confidence = torch.softmax(output, dim=1)[0, label].item()
            
            if pred != label:
                if verbose:
                    print(f"âœ… æ”»å‡»æˆåŠŸï¼æ­¥æ•°: {step}")
                return True, adv_image, modified_pixels, method_used
            
            # å†³å®šä½¿ç”¨å“ªç§æ–¹æ³•
            use_rl = self._should_use_rl(step, confidence)
            
            if use_rl:
                # ä½¿ç”¨ RL ç­–ç•¥
                if verbose:
                    print(f"æ­¥éª¤ {step+1}: ä½¿ç”¨ RL")
                
                x, y, r, g, b = self._rl_select_action(adv_image)
                method = 'RL'
                
            else:
                # ä½¿ç”¨ JSMA å¯å‘å¼
                if verbose:
                    print(f"æ­¥éª¤ {step+1}: ä½¿ç”¨ JSMA")
                
                x, y, r, g, b = self._jsma_select_action(adv_image, label)
                method = 'JSMA'
            
            # åº”ç”¨ä¿®æ”¹
            adv_image = self._apply_modification(adv_image, x, y, r, g, b)
            modified_pixels.append((x, y))
            method_used.append(method)
        
        # æœ€åæ£€æŸ¥ä¸€æ¬¡
        with torch.no_grad():
            output = self.model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
        
        success = (pred != label)
        
        if verbose:
            if success:
                print(f"âœ… æ”»å‡»æˆåŠŸï¼")
            else:
                print(f"âŒ æ”»å‡»å¤±è´¥")
        
        return success, adv_image, modified_pixels, method_used
    
    def _should_use_rl(self, step, confidence):
        """
        å†³å®šæ˜¯å¦ä½¿ç”¨RL
        
        å‚æ•°:
            step: å½“å‰æ­¥æ•°
            confidence: å½“å‰ç½®ä¿¡åº¦
        
        è¿”å›:
            bool: Trueè¡¨ç¤ºä½¿ç”¨RLï¼ŒFalseè¡¨ç¤ºä½¿ç”¨JSMA
        """
        if self.rl_ratio_schedule == 'static':
            # å›ºå®š50%æ¦‚ç‡ä½¿ç”¨RL
            return np.random.rand() < 0.5
        
        elif self.rl_ratio_schedule == 'increasing':
            # é€’å¢ï¼šå‰30%ç”¨30% RLï¼Œä¸­é—´40%ç”¨70% RLï¼Œæœ€å30%ç”¨100% RL
            progress = step / self.max_steps
            if progress < 0.3:
                rl_prob = 0.3
            elif progress < 0.7:
                rl_prob = 0.7
            else:
                rl_prob = 1.0
            return np.random.rand() < rl_prob
        
        elif self.rl_ratio_schedule == 'dynamic':
            # åŠ¨æ€ï¼šæ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´
            # é«˜ç½®ä¿¡åº¦æ—¶å¤šç”¨JSMAï¼ˆå¿«é€Ÿé™ä½ï¼‰ï¼Œä½ç½®ä¿¡åº¦æ—¶å¤šç”¨RLï¼ˆç²¾ç»†è°ƒæ•´ï¼‰
            if confidence > 0.7:
                rl_prob = 0.3  # ä¸»è¦ç”¨JSMA
            elif confidence > 0.4:
                rl_prob = 0.6  # æ··åˆ
            else:
                rl_prob = 0.9  # ä¸»è¦ç”¨RL
            return np.random.rand() < rl_prob
        
        else:
            return True
    
    def _rl_select_action(self, image):
        """
        ä½¿ç”¨RLæ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
        
        è¿”å›:
            x, y, r, g, b: åƒç´ ä½ç½®å’ŒRGBä¿®æ”¹å€¼
        """
        # æ³¨æ„ï¼šå¦‚æœagentæ˜¯ç”¨å¢å¼ºçŠ¶æ€è®­ç»ƒçš„ï¼Œéœ€è¦æä¾›å¢å¼ºçŠ¶æ€
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨éšæœºåŠ¨ä½œ
        try:
            # å°è¯•ä½¿ç”¨åŸå§‹å›¾åƒ
            obs = image.cpu().numpy()
            action, _ = self.rl_agent.predict(obs, deterministic=False)
        except Exception as e:
            # å¦‚æœå¤±è´¥ï¼ˆçŠ¶æ€ç©ºé—´ä¸åŒ¹é…ï¼‰ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œ
            # print(f"RLé¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œ: {e}")
            action = self.rl_agent.action_space.sample()
        
        x, y, dr, dg, db = action
        x = int(np.clip(x, 0, image.shape[2] - 1))
        y = int(np.clip(y, 0, image.shape[1] - 1))
        
        return x, y, dr, dg, db
    
    def _jsma_select_action(self, image, label):
        """
        ä½¿ç”¨JSMAå¯å‘å¼é€‰æ‹©åŠ¨ä½œ
        
        è¿”å›:
            x, y, r, g, b: åƒç´ ä½ç½®å’ŒRGBä¿®æ”¹å€¼
        """
        # è®¡ç®—æ˜¾è‘—æ€§å›¾
        image_batch = image.unsqueeze(0).requires_grad_(True)
        
        # è®¡ç®—é›…å¯æ¯”çŸ©é˜µ
        output = self.model(image_batch)
        num_classes = output.shape[1]
        
        jacobian = torch.zeros((1, num_classes, *image.shape), device=self.device)
        
        for class_idx in range(num_classes):
            self.model.zero_grad()
            if image_batch.grad is not None:
                image_batch.grad.zero_()
            
            class_output = output[0, class_idx]
            class_output.backward(retain_graph=True)
            
            if image_batch.grad is not None:
                jacobian[0, class_idx] = image_batch.grad[0].clone()
        
        # é€‰æ‹©ç¬¬äºŒé«˜çš„ç±»åˆ«ä½œä¸ºç›®æ ‡
        sorted_preds = output.argsort(dim=1, descending=True)[0]
        target_class = sorted_preds[1].item() if sorted_preds[0].item() == label else sorted_preds[0].item()
        
        # è®¡ç®—æ˜¾è‘—æ€§
        grad_target = jacobian[0, target_class]
        grad_source = jacobian[0, label]
        
        alpha = grad_target
        beta = -grad_source
        
        valid = (alpha > 0) & (beta > 0)
        saliency = alpha * beta * valid.float()
        
        # æ‰¾åˆ°æ˜¾è‘—æ€§æœ€é«˜çš„åƒç´ 
        saliency_flat = saliency.view(-1)
        max_idx = saliency_flat.argmax().item()
        
        C, H, W = image.shape
        c = max_idx // (H * W)
        h = (max_idx % (H * W)) // W
        w = max_idx % W
        
        # ç¡®å®šä¿®æ”¹æ–¹å‘
        direction = 1.0 if jacobian[0, target_class, c, h, w] > 0 else -1.0
        
        # RGBå€¼ï¼ˆç®€åŒ–ï¼šç»Ÿä¸€ä¿®æ”¹ï¼‰
        dr = dg = db = direction * 128  # ä¸­ç­‰å¼ºåº¦
        
        return w, h, dr, dg, db
    
    def _apply_modification(self, image, x, y, dr, dg, db):
        """
        åº”ç”¨åƒç´ ä¿®æ”¹
        
        è¿”å›:
            modified_image: ä¿®æ”¹åçš„å›¾åƒ
        """
        # åå½’ä¸€åŒ–
        mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(self.device)
        std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(self.device)
        
        img_unnorm = image * std + mean
        
        # åº”ç”¨ä¿®æ”¹
        delta = torch.tensor([dr, dg, db]).view(3, 1, 1).to(self.device) / 255.0
        img_unnorm[:, y:y+1, x:x+1] += delta
        
        # è£å‰ªå¹¶é‡æ–°å½’ä¸€åŒ–
        img_unnorm = torch.clamp(img_unnorm, 0, 1)
        modified_image = (img_unnorm - mean) / std
        
        return modified_image


def hybrid_attack(image, label, model, rl_agent, max_pixels=5, strategy='dynamic'):
    """
    ä¾¿æ·çš„æ··åˆæ”»å‡»æ¥å£
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ
        label: çœŸå®æ ‡ç­¾  
        model: ç›®æ ‡æ¨¡å‹
        rl_agent: RLæ™ºèƒ½ä½“
        max_pixels: æœ€å¤§ä¿®æ”¹åƒç´ æ•°
        strategy: ç­–ç•¥ç±»å‹ ('static', 'increasing', 'dynamic')
    
    è¿”å›:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ 
        method_used: ä½¿ç”¨çš„æ–¹æ³•è®°å½•
    """
    hybrid_strategy = HybridAttackStrategy(
        rl_agent=rl_agent,
        model=model,
        max_steps=max_pixels,
        rl_ratio_schedule=strategy
    )
    
    return hybrid_strategy.attack(image, label, verbose=False)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•æ··åˆæ”»å‡»ç­–ç•¥")
    
    from torchvision import datasets, transforms
    from target_model import load_target_model
    from stable_baselines3 import PPO
    import os
    
    # åŠ è½½æ•°æ®å’Œæ¨¡å‹
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    target_model = load_target_model('resnet18', num_classes=10)
    
    # åŠ è½½RLæ™ºèƒ½ä½“
    agent_path = "ppo_sparse_model.zip"
    if os.path.exists(agent_path):
        rl_agent = PPO.load(agent_path)
    else:
        print("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„RLæ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ")
        exit()
    
    # æµ‹è¯•å‡ ä¸ªæ ·æœ¬
    print("\næµ‹è¯•æ··åˆæ”»å‡»ç­–ç•¥:")
    print("=" * 60)
    
    for strategy in ['static', 'increasing', 'dynamic']:
        print(f"\nç­–ç•¥: {strategy}")
        successes = 0
        
        for i in range(5):
            image, label = test_set[i]
            
            success, adv_img, pixels, methods = hybrid_attack(
                image, label, target_model, rl_agent,
                max_pixels=5, strategy=strategy
            )
            
            if success:
                successes += 1
                print(f"  æ ·æœ¬ {i}: âœ… æˆåŠŸ | æ­¥æ•°: {len(pixels)} | æ–¹æ³•: {methods}")
            else:
                print(f"  æ ·æœ¬ {i}: âŒ å¤±è´¥")
        
        print(f"æˆåŠŸç‡: {successes}/5 = {successes/5*100:.1f}%")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")

