"""
One-Pixelæ”»å‡»ä¿®å¤ - è½»é‡çº§å®‰å…¨ç‰ˆæœ¬
é™ä½CPUè´Ÿè½½ï¼Œå¿«é€ŸéªŒè¯æ˜¯å¦æœ‰æ•ˆ
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
from pathlib import Path
import json
from tqdm import tqdm
import time

from one_pixel_attack import one_pixel_attack

def load_model():
    """åŠ è½½VGG16æ¨¡å‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = torchvision.models.vgg16(weights=None)
    num_ftrs = model.classifier[6].in_features
    model.classifier[6] = nn.Linear(num_ftrs, 10)
    
    model.load_state_dict(torch.load('cifar10_vgg16.pth', map_location=device, weights_only=False))
    model.to(device)
    model.eval()
    
    return model, device

def load_test_data():
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    return testset

def test_lite_config(model, device, testset, config_name, max_iter, pop_size, num_samples=10):
    """è½»é‡çº§æµ‹è¯•"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª {config_name}")
    print(f"{'='*80}")
    print(f"å‚æ•°: maxiter={max_iter}, popsize={pop_size}, æ ·æœ¬æ•°={num_samples}")
    print(f"é¢„è®¡æ—¶é—´: {num_samples * max_iter * pop_size / 40000:.1f}-{num_samples * max_iter * pop_size / 20000:.1f}åˆ†é’Ÿ")
    
    # é€‰æ‹©æ ·æœ¬
    selected_samples = []
    for idx in range(len(testset)):
        if len(selected_samples) >= num_samples:
            break
        
        image, label = testset[idx]
        image_batch = image.unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
        
        if pred == label:
            selected_samples.append((idx, image, label))
    
    print(f"âœ… é€‰æ‹©äº† {len(selected_samples)} ä¸ªæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬\n")
    
    # æ”»å‡»æµ‹è¯•
    success_count = 0
    l0_values = []
    results = []
    
    for i, (idx, image, label) in enumerate(tqdm(selected_samples, desc="æ”»å‡»è¿›åº¦")):
        start_time = time.time()
        
        success, adv_image, modified_info = one_pixel_attack(
            image=image,
            label=label,
            model=model,
            max_iter=max_iter,
            pop_size=pop_size
        )
        
        attack_time = time.time() - start_time
        
        if success:
            diff = (adv_image - image).abs()
            modified_pixels = (diff.sum(dim=0) > 0).sum().item()
            l0_values.append(modified_pixels)
            success_count += 1
            
            results.append({
                'sample_id': idx,
                'success': True,
                'l0': modified_pixels,
                'time': attack_time,
                'modified_pixel': modified_info
            })
            
            print(f"  âœ… æ ·æœ¬{i+1}: æˆåŠŸ! L0={modified_pixels}, æ—¶é—´={attack_time:.1f}s")
        else:
            results.append({
                'sample_id': idx,
                'success': False,
                'time': attack_time
            })
    
    asr = success_count / len(selected_samples) * 100
    avg_l0 = np.mean(l0_values) if l0_values else 0
    
    print(f"\nğŸ“Š ç»“æœ: ASR={asr:.1f}% ({success_count}/{len(selected_samples)})")
    if avg_l0 > 0:
        print(f"    å¹³å‡L0={avg_l0:.2f}")
    
    return {
        'config': config_name,
        'max_iter': max_iter,
        'pop_size': pop_size,
        'asr': asr,
        'success_count': success_count,
        'total_samples': len(selected_samples),
        'avg_l0': avg_l0,
        'detailed_results': results
    }

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸ”§ One-Pixelæ”»å‡»ä¿®å¤ - è½»é‡çº§å®‰å…¨ç‰ˆæœ¬")
    print("="*80)
    print("\nğŸ’¡ ä¼˜åŒ–ç­–ç•¥:")
    print("  âœ… åªæµ‹è¯•3ä¸ªå…³é”®é…ç½®ï¼ˆä¸æ˜¯7ä¸ªï¼‰")
    print("  âœ… æ¯ä¸ªé…ç½®10ä¸ªæ ·æœ¬ï¼ˆä¸æ˜¯30ä¸ªï¼‰")
    print("  âœ… é™ä½è®¡ç®—å¼ºåº¦50%")
    print("  âœ… é¢„è®¡æ¸©åº¦: 85-88Â°C (ç›¸å¯¹å®‰å…¨)")
    print("  âœ… é¢„è®¡æ€»æ—¶é—´: 15-25åˆ†é’Ÿ\n")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½VGG16æ¨¡å‹...")
    model, device = load_model()
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {device}\n")
    
    # åŠ è½½æ•°æ®
    print("ğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®...")
    testset = load_test_data()
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ\n")
    
    # è½»é‡çº§é…ç½®ï¼ˆåªæµ‹3ä¸ªå…³é”®ç‚¹ï¼‰
    configs = [
        ("è½»é‡é…ç½®", 50, 200, 10),      # åŸºå‡†ï¼š10,000æ¬¡è¿­ä»£
        ("æ ‡å‡†é…ç½®", 100, 300, 10),     # ä¸­ç­‰ï¼š30,000æ¬¡è¿­ä»£
        ("å¢å¼ºé…ç½®", 150, 400, 10),     # å¢å¼ºï¼š60,000æ¬¡è¿­ä»£
    ]
    
    all_results = []
    start_time_total = time.time()
    
    for config_name, max_iter, pop_size, num_samples in configs:
        result = test_lite_config(
            model=model,
            device=device,
            testset=testset,
            config_name=config_name,
            max_iter=max_iter,
            pop_size=pop_size,
            num_samples=num_samples
        )
        all_results.append(result)
        
        # å¦‚æœå‘ç°æœ‰æ•ˆé…ç½®ï¼Œè®°å½•å¹¶ç»§ç»­
        if result['asr'] > 0:
            print(f"\nğŸ‰ å‘ç°æœ‰æ•ˆé…ç½®ï¼{config_name} ASR={result['asr']:.1f}%")
    
    total_time = time.time() - start_time_total
    
    # æ±‡æ€»ç»“æœ
    print(f"\n{'='*80}")
    print("ğŸ“Š è½»é‡çº§æµ‹è¯•æ±‡æ€»")
    print(f"{'='*80}")
    print(f"æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ\n")
    
    print(f"{'é…ç½®':<12} {'MaxIter':<10} {'PopSize':<10} {'ASR':<10} {'å¹³å‡L0'}")
    print("-"*60)
    for r in all_results:
        print(f"{r['config']:<12} {r['max_iter']:<10} {r['pop_size']:<10} "
              f"{r['asr']:<10.1f} {r['avg_l0']:.2f}")
    
    # æ‰¾åˆ°æœ€ä½³é…ç½®
    best_config = max(all_results, key=lambda x: x['asr'])
    
    print(f"\n{'='*80}")
    if best_config['asr'] > 0:
        print(f"âœ… æœ€ä½³é…ç½®: {best_config['config']}")
        print(f"{'='*80}")
        print(f"  MaxIter: {best_config['max_iter']}")
        print(f"  PopSize: {best_config['pop_size']}")
        print(f"  ASR: {best_config['asr']:.1f}%")
        print(f"  å¹³å‡L0: {best_config['avg_l0']:.2f}")
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print(f"  1. ä½¿ç”¨æ­¤é…ç½®è¿›è¡Œå®Œæ•´æµ‹è¯•ï¼ˆ100æ ·æœ¬ï¼‰")
        print(f"  2. é¢„è®¡æ—¶é—´: {100 * best_config['max_iter'] * best_config['pop_size'] / 30000:.0f}-{100 * best_config['max_iter'] * best_config['pop_size'] / 15000:.0f}åˆ†é’Ÿ")
        print(f"  3. å»ºè®®åˆ†æ‰¹è¿›è¡Œï¼ˆæ¯æ‰¹25æ ·æœ¬ï¼Œé—´éš”ä¼‘æ¯5åˆ†é’Ÿï¼‰")
    else:
        print("âš ï¸  æ‰€æœ‰è½»é‡çº§é…ç½®çš„ASRéƒ½æ˜¯0%")
        print(f"{'='*80}")
        print("\nè¿™è¡¨æ˜:")
        print("  â€¢ VGG16å¯¹One-Pixelæ”»å‡»ç¡®å®é«˜åº¦é²æ£’")
        print("  â€¢ å³ä½¿å¢å¼ºé…ç½®ä¹Ÿæ— æ³•æ”»å‡»æˆåŠŸ")
        print("  â€¢ è¿™æ˜¯é‡è¦çš„ç ”ç©¶å‘ç°ï¼")
        print("\nğŸ’¡ å»ºè®®:")
        print("  1. æ¥å—è¿™ä¸ªç»“æœä½œä¸ºé‡è¦å‘ç°")
        print("  2. åœ¨è®ºæ–‡ä¸­è¯¦ç»†è®¨è®ºVGG16çš„é²æ£’æ€§")
        print("  3. å¯¹æ¯”åˆ†æï¼šä¸ºä»€ä¹ˆVGG16å…ç–«è€Œå…¶ä»–æ¨¡å‹ä¸å…ç–«")
    
    # ä¿å­˜ç»“æœ
    output_dir = Path('results/onepixel_fix')
    output_dir.mkdir(exist_ok=True, parents=True)
    
    with open(output_dir / 'lite_test_results.json', 'w') as f:
        json.dump(all_results, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_dir / 'lite_test_results.json'}")
    
    print(f"\n{'='*80}")
    print("ğŸ‰ è½»é‡çº§æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}\n")

if __name__ == "__main__":
    main()







