# run_vgg16_experiment.py
"""
è¿è¡ŒVGG16å®Œæ•´å®éªŒ
æµ‹è¯•æ‰€æœ‰æ”»å‡»æ–¹æ³•ï¼šRL V1, RL V2, JSMA, One-Pixel, SparseFool

é¢„è®¡æ—¶é—´ï¼š2-3å°æ—¶ï¼ˆ100-200æ ·æœ¬ï¼‰
"""

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset
import numpy as np
import json
import time
from datetime import datetime
import os
from skimage.metrics import structural_similarity as ssim_func

# å¯¼å…¥æ”»å‡»æ–¹æ³•
from jsma_attack import jsma_attack
from one_pixel_attack import one_pixel_attack
from sparsefool_attack import sparsefool_attack
from stable_baselines3 import PPO
from sparse_attack_env import SparseAttackEnv
from sparse_attack_env_v2 import SparseAttackEnvV2


def load_vgg16_model(model_path='cifar10_vgg16.pth', device='cuda'):
    """åŠ è½½VGG16æ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½VGG16æ¨¡å‹: {model_path}")
    
    model = torchvision.models.vgg16(weights=None)
    num_ftrs = model.classifier[6].in_features
    model.classifier[6] = torch.nn.Linear(num_ftrs, 10)
    
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()
    
    print("âœ… VGG16æ¨¡å‹åŠ è½½å®Œæˆ")
    return model


def verify_model_accuracy(model, testloader, device='cuda'):
    """éªŒè¯æ¨¡å‹å‡†ç¡®ç‡"""
    print("\nğŸ” éªŒè¯æ¨¡å‹å‡†ç¡®ç‡...")
    
    correct = 0
    total = 0
    
    with torch.no_grad():
        for inputs, targets in testloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
    
    accuracy = 100. * correct / total
    print(f"âœ… æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2f}%")
    return accuracy


def test_jsma(model, sample, label, device='cuda'):
    """æµ‹è¯•JSMAæ”»å‡»"""
    try:
        start_time = time.time()
        
        # JSMAè¿”å› (success, adv_image, modified_pixels)
        success, adv_image, modified_pixels = jsma_attack(
            image=sample.squeeze(0),  # å»æ‰batchç»´åº¦
            label=label,
            model=model,
            max_pixels=10,
            theta=1.0
        )
        elapsed = time.time() - start_time
        
        # è®¡ç®—L0å’ŒL2
        if success:
            l0 = len(modified_pixels)
            diff = (adv_image - sample.squeeze(0)).cpu().numpy()
            l2 = np.linalg.norm(diff)
            
            # è®¡ç®—SSIM
            img1 = sample.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            img2 = adv_image.cpu().numpy().transpose(1, 2, 0)
            ssim = ssim_func(img1, img2, multichannel=True, channel_axis=2, data_range=img2.max()-img2.min())
        else:
            l0 = l2 = ssim = 0.0
        
        return {
            'success': success,
            'l0': l0,
            'l2': l2,
            'ssim': ssim,
            'time': elapsed
        }
    except Exception as e:
        print(f"  JSMAé”™è¯¯: {str(e)}")
        return None


def test_onepixel(model, sample, label, device='cuda'):
    """æµ‹è¯•One-Pixelæ”»å‡»"""
    try:
        start_time = time.time()
        
        # One-Pixelè¿”å› (success, adv_image, modified_info)
        success, adv_image, modified_info = one_pixel_attack(
            image=sample.squeeze(0),
            label=label,
            model=model,
            max_iter=75,
            pixels=1
        )
        elapsed = time.time() - start_time
        
        # è®¡ç®—æŒ‡æ ‡
        if success:
            l0 = 1.0  # One-Pixelå›ºå®šä¿®æ”¹1ä¸ªåƒç´ 
            diff = (adv_image - sample.squeeze(0)).cpu().numpy()
            l2 = np.linalg.norm(diff)
            
            img1 = sample.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            img2 = adv_image.cpu().numpy().transpose(1, 2, 0)
            ssim = ssim_func(img1, img2, multichannel=True, channel_axis=2, data_range=img2.max()-img2.min())
        else:
            l0 = l2 = ssim = 0.0
        
        return {
            'success': success,
            'l0': l0,
            'l2': l2,
            'ssim': ssim,
            'time': elapsed
        }
    except Exception as e:
        print(f"  One-Pixelé”™è¯¯: {str(e)}")
        return None


def test_sparsefool(model, sample, label, device='cuda'):
    """æµ‹è¯•SparseFoolæ”»å‡»"""
    try:
        start_time = time.time()
        
        # SparseFoolè¿”å› (success, adv_image, modified_pixels)
        success, adv_image, modified_pixels = sparsefool_attack(
            image=sample.squeeze(0),
            label=label,
            model=model,
            max_iterations=20,
            lambda_=3.0
        )
        elapsed = time.time() - start_time
        
        # è®¡ç®—æŒ‡æ ‡
        if success:
            l0 = len(modified_pixels)
            diff = (adv_image - sample.squeeze(0)).cpu().numpy()
            l2 = np.linalg.norm(diff)
            
            img1 = sample.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            img2 = adv_image.cpu().numpy().transpose(1, 2, 0)
            ssim = ssim_func(img1, img2, multichannel=True, channel_axis=2, data_range=img2.max()-img2.min())
        else:
            l0 = l2 = ssim = 0.0
        
        return {
            'success': success,
            'l0': l0,
            'l2': l2,
            'ssim': ssim,
            'time': elapsed
        }
    except Exception as e:
        print(f"  SparseFoolé”™è¯¯: {str(e)}")
        return None


def test_rl_v1(model, sample, label, device='cuda'):
    """æµ‹è¯•RL V1æ”»å‡»"""
    try:
        if not os.path.exists('ppo_sparse_v1.zip'):
            print("  âš ï¸  RL V1æ¨¡å‹ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return None
        
        start_time = time.time()
        
        # åˆ›å»ºç¯å¢ƒ - å‚æ•°æ˜¯ (clean_image, true_label, model, max_steps)
        env = SparseAttackEnv(
            clean_image=sample.squeeze(0),
            true_label=label,
            model=model,
            max_steps=5
        )
        
        # åŠ è½½è®­ç»ƒå¥½çš„RL agent
        rl_agent = PPO.load('ppo_sparse_v1', device=device)
        rl_agent.set_env(env)
        
        # é‡ç½®ç¯å¢ƒ
        obs, _ = env.reset()
        
        # æ‰§è¡Œæ”»å‡»
        done = False
        step = 0
        
        while not done and step < 10:
            action, _ = rl_agent.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            step += 1
        
        elapsed = time.time() - start_time
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        with torch.no_grad():
            output = model(env.current_image)
            pred = output.argmax(dim=1).item()
            success = (pred != label)
        
        # è®¡ç®—æŒ‡æ ‡
        if success:
            l0 = env.current_step
            diff = (env.current_image - env.clean_image).cpu().numpy()
            l2 = np.linalg.norm(diff)
            
            img1 = env.clean_image.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            img2 = env.current_image.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            ssim = ssim_func(img1, img2, multichannel=True, channel_axis=2, data_range=img2.max()-img2.min())
        else:
            l0 = l2 = ssim = 0.0
        
        return {
            'success': success,
            'l0': l0,
            'l2': l2,
            'ssim': ssim,
            'time': elapsed
        }
    except Exception as e:
        print(f"  RL V1é”™è¯¯: {str(e)}")
        return None


def test_rl_v2(model, sample, label, device='cuda'):
    """æµ‹è¯•RL V2æ”»å‡»"""
    try:
        if not os.path.exists('ppo_sparse_v2.zip'):
            print("  âš ï¸  RL V2æ¨¡å‹ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return None
        
        start_time = time.time()
        
        # åˆ›å»ºç¯å¢ƒ - å‚æ•°æ˜¯ (clean_image, true_label, model, max_steps)
        env = SparseAttackEnvV2(
            clean_image=sample.squeeze(0),
            true_label=label,
            model=model,
            max_steps=5,
            use_saliency=True
        )
        
        # åŠ è½½è®­ç»ƒå¥½çš„RL agent  
        rl_agent = PPO.load('ppo_sparse_v2', device=device)
        rl_agent.set_env(env)
        
        # é‡ç½®ç¯å¢ƒ
        obs, _ = env.reset()
        
        # æ‰§è¡Œæ”»å‡»
        done = False
        step = 0
        
        while not done and step < 10:
            action, _ = rl_agent.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            step += 1
        
        elapsed = time.time() - start_time
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        with torch.no_grad():
            output = model(env.current_image)
            pred = output.argmax(dim=1).item()
            success = (pred != label)
        
        # è®¡ç®—æŒ‡æ ‡
        if success:
            l0 = env.current_step
            diff = (env.current_image - env.clean_image).cpu().numpy()
            l2 = np.linalg.norm(diff)
            
            img1 = env.clean_image.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            img2 = env.current_image.squeeze(0).cpu().numpy().transpose(1, 2, 0)
            ssim = ssim_func(img1, img2, multichannel=True, channel_axis=2, data_range=img2.max()-img2.min())
        else:
            l0 = l2 = ssim = 0.0
        
        return {
            'success': success,
            'l0': l0,
            'l2': l2,
            'ssim': ssim,
            'time': elapsed
        }
    except Exception as e:
        print(f"  RL V2é”™è¯¯: {str(e)}")
        return None


def run_experiments(num_samples=100):
    """è¿è¡Œå®Œæ•´å®éªŒ"""
    print("=" * 80)
    print("ğŸ¯ VGG16å®Œæ•´å®éªŒ")
    print("=" * 80)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½VGG16æ¨¡å‹
    if not os.path.exists('cifar10_vgg16.pth'):
        print("âŒ é”™è¯¯ï¼šVGG16æ¨¡å‹ä¸å­˜åœ¨ï¼")
        print("è¯·å…ˆè¿è¡Œ: python train_cifar10_vgg16.py")
        return
    
    model = load_vgg16_model(device=device)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\nğŸ“¦ åŠ è½½CIFAR-10æµ‹è¯•æ•°æ®...")
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    
    # éªŒè¯æ¨¡å‹å‡†ç¡®ç‡
    testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)
    accuracy = verify_model_accuracy(model, testloader, device)
    
    if accuracy < 75.0:
        print(f"âš ï¸  è­¦å‘Šï¼šæ¨¡å‹å‡†ç¡®ç‡è¾ƒä½ ({accuracy:.2f}%)ï¼Œå®éªŒç»“æœå¯èƒ½ä¸ç†æƒ³")
    
    # é€‰æ‹©æµ‹è¯•æ ·æœ¬ï¼ˆåªé€‰æ‹©æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬ï¼‰
    print(f"\nğŸ” é€‰æ‹©{num_samples}ä¸ªæµ‹è¯•æ ·æœ¬...")
    
    correct_indices = []
    with torch.no_grad():
        for idx in range(len(testset)):
            sample, label = testset[idx]
            sample = sample.unsqueeze(0).to(device)
            output = model(sample)
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                correct_indices.append(idx)
            
            if len(correct_indices) >= num_samples:
                break
    
    print(f"âœ… é€‰æ‹©äº†{len(correct_indices)}ä¸ªæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬")
    
    # å‡†å¤‡æ”»å‡»æ–¹æ³•
    attack_methods = {
        'JSMA': test_jsma,
        'One-Pixel': test_onepixel,
        'SparseFool': test_sparsefool,
        'RL-V1': test_rl_v1,
        'RL-V2': test_rl_v2,
    }
    
    # åˆå§‹åŒ–ç»“æœ
    results = {method: [] for method in attack_methods.keys()}
    
    # è¿è¡Œå®éªŒ
    print("\n" + "=" * 80)
    print("å¼€å§‹æ”»å‡»æµ‹è¯•...")
    print("=" * 80 + "\n")
    
    start_time = time.time()
    
    for idx, sample_idx in enumerate(correct_indices):
        sample, label = testset[sample_idx]
        sample = sample.unsqueeze(0).to(device)
        
        print(f"[{idx+1}/{len(correct_indices)}] æ ·æœ¬ {sample_idx}, æ ‡ç­¾ {label}")
        
        for method_name, method_func in attack_methods.items():
            print(f"  æµ‹è¯• {method_name}...", end=' ')
            result = method_func(model, sample, label, device)
            
            if result is not None:
                results[method_name].append(result)
                status = "âœ…" if result['success'] else "âŒ"
                print(f"{status} L0={result['l0']:.2f}, Time={result['time']:.3f}s")
            else:
                print("âš ï¸  è·³è¿‡")
    
    total_time = time.time() - start_time
    
    # ç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š å®éªŒç»“æœç»Ÿè®¡")
    print("=" * 80 + "\n")
    
    summary = {}
    
    for method_name, method_results in results.items():
        if not method_results:
            print(f"{method_name}: æ— ç»“æœ")
            continue
        
        successes = [r for r in method_results if r['success']]
        asr = len(successes) / len(method_results) * 100
        
        if successes:
            avg_l0 = np.mean([r['l0'] for r in successes])
            avg_l2 = np.mean([r['l2'] for r in successes])
            avg_ssim = np.mean([r['ssim'] for r in successes])
            avg_time = np.mean([r['time'] for r in method_results])
        else:
            avg_l0 = avg_l2 = avg_ssim = avg_time = 0.0
        
        summary[method_name] = {
            'ASR': float(asr),
            'L0': float(avg_l0),
            'L2': float(avg_l2),
            'SSIM': float(avg_ssim),
            'Time': float(avg_time)
        }
        
        print(f"{method_name}:")
        print(f"  ASR:  {asr:.1f}%")
        print(f"  L0:   {avg_l0:.2f}")
        print(f"  L2:   {avg_l2:.4f}")
        print(f"  SSIM: {avg_ssim:.4f}")
        print(f"  Time: {avg_time:.3f}s")
        print()
    
    # ä¿å­˜ç»“æœ
    output_dir = 'results/week1_day2'
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜JSON
    output_file = os.path.join(output_dir, 'vgg16_summary.json')
    with open(output_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_file = os.path.join(output_dir, 'vgg16_detailed.json')
    with open(detailed_file, 'w') as f:
        # å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
        serializable_results = {}
        for method, method_results in results.items():
            serializable_results[method] = [
                {k: float(v) if isinstance(v, (np.floating, np.integer)) else v 
                 for k, v in r.items()}
                for r in method_results
            ]
        json.dump(serializable_results, f, indent=2)
    
    print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {detailed_file}")
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 80)
    print(f"ğŸ‰ å®éªŒå®Œæˆï¼")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    print(f"ğŸ“Š æµ‹è¯•æ ·æœ¬æ•°: {len(correct_indices)}")
    print(f"ğŸ¯ VGG16å‡†ç¡®ç‡: {accuracy:.2f}%")
    print("=" * 80)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='VGG16å®Œæ•´å®éªŒ')
    parser.add_argument('--num_samples', type=int, default=100, help='æµ‹è¯•æ ·æœ¬æ•°')
    args = parser.parse_args()
    
    run_experiments(num_samples=args.num_samples)

