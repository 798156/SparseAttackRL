"""
è°ƒè¯•æ–°æ¨¡å‹ä¸Šçš„æ”»å‡»æ–¹æ³•
æ‰¾å‡ºä¸ºä»€ä¹ˆæ‰€æœ‰æ”»å‡»æˆåŠŸç‡éƒ½å¾ˆä½
"""

import torch
import torchvision
import torchvision.transforms as transforms
from target_model import load_target_model
from jsma_attack import jsma_attack
from one_pixel_attack import one_pixel_attack
from sparsefool_attack import sparsefool_attack_simple
from evaluation_metrics import compute_l0_norm

def debug_single_sample():
    """è¯¦ç»†è°ƒè¯•å•ä¸ªæ ·æœ¬"""
    print("=" * 80)
    print("ğŸ” è°ƒè¯•æ–°æ¨¡å‹(88.8%)ä¸Šçš„æ”»å‡»æ–¹æ³•")
    print("=" * 80)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    model = load_target_model("resnet18")
    model = model.to(device)
    model.eval()
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    
    # æ‰¾ä¸€ä¸ªæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬
    print("\nğŸ“ å¯»æ‰¾æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬...")
    for idx in range(len(testset)):
        image, label = testset[idx]
        image = image.to(device)
        
        with torch.no_grad():
            output = model(image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            confidence = torch.softmax(output, dim=1)[0, pred].item()
            
            if pred == label:
                print(f"\nâœ… æ‰¾åˆ°æ ·æœ¬ #{idx}")
                print(f"   æ ‡ç­¾: {label}")
                print(f"   é¢„æµ‹: {pred}")
                print(f"   ç½®ä¿¡åº¦: {confidence:.4f}")
                break
    
    # æµ‹è¯•ä¸åŒå¼ºåº¦çš„æ”»å‡»
    print("\n" + "=" * 80)
    print("ğŸ§ª æµ‹è¯•ä¸åŒæ”»å‡»å¼ºåº¦")
    print("=" * 80)
    
    # 1. One-Pixel - æµ‹è¯•ä¸åŒmax_iter
    print("\nğŸ“ One-Pixelæ”»å‡» - æµ‹è¯•ä¸åŒè¿­ä»£æ¬¡æ•°")
    print("-" * 80)
    for max_iter in [50, 100, 200, 400]:
        try:
            success, params = one_pixel_attack(image, label, model, max_iter=max_iter)
            print(f"  max_iter={max_iter:3d}: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
            if success:
                break
        except Exception as e:
            print(f"  max_iter={max_iter:3d}: âŒ é”™è¯¯ - {e}")
    
    # 2. JSMA - æµ‹è¯•ä¸åŒtheta
    print("\nğŸ“ JSMAæ”»å‡» - æµ‹è¯•ä¸åŒthetaå€¼")
    print("-" * 80)
    for theta in [1.0, 2.0, 5.0, 10.0, 20.0, 50.0]:
        try:
            success, adv, pixels = jsma_attack(image, label, model, max_pixels=10, theta=theta)
            if success:
                l0 = compute_l0_norm(image.cpu(), adv.cpu())
                with torch.no_grad():
                    final_pred = model(adv.unsqueeze(0)).argmax(dim=1).item()
                    final_conf = torch.softmax(model(adv.unsqueeze(0)), dim=1)[0, final_pred].item()
                print(f"  theta={theta:5.1f}: âœ… æˆåŠŸ, L0={l0}, æœ€ç»ˆé¢„æµ‹={final_pred}, ç½®ä¿¡åº¦={final_conf:.4f}")
            else:
                print(f"  theta={theta:5.1f}: âŒ å¤±è´¥")
        except Exception as e:
            print(f"  theta={theta:5.1f}: âŒ é”™è¯¯ - {e}")
    
    # 3. SparseFool - æµ‹è¯•ä¸åŒperturbation
    print("\nğŸ“ SparseFoolæ”»å‡» - å½“å‰perturbation=0.8")
    print("-" * 80)
    try:
        success, adv, pixels = sparsefool_attack_simple(image, label, model, max_pixels=10)
        if success:
            l0 = compute_l0_norm(image.cpu(), adv.cpu())
            with torch.no_grad():
                final_pred = model(adv.unsqueeze(0)).argmax(dim=1).item()
                final_conf = torch.softmax(model(adv.unsqueeze(0)), dim=1)[0, final_pred].item()
            print(f"  âœ… æˆåŠŸ, L0={l0}, æœ€ç»ˆé¢„æµ‹={final_pred}, ç½®ä¿¡åº¦={final_conf:.4f}")
        else:
            print(f"  âŒ å¤±è´¥")
    except Exception as e:
        print(f"  âŒ é”™è¯¯ - {e}")
    
    # 4. æ£€æŸ¥æ¨¡å‹çš„é²æ£’æ€§
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¨¡å‹é²æ£’æ€§åˆ†æ")
    print("=" * 80)
    
    # æµ‹è¯•å¤šä¸ªæ ·æœ¬çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
    print("\næ”¶é›†å‰50ä¸ªæ­£ç¡®åˆ†ç±»æ ·æœ¬çš„ç½®ä¿¡åº¦...")
    confidences = []
    
    for idx in range(min(50, len(testset))):
        img, lbl = testset[idx]
        img = img.to(device)
        
        with torch.no_grad():
            out = model(img.unsqueeze(0))
            pred = out.argmax(dim=1).item()
            
            if pred == lbl:
                conf = torch.softmax(out, dim=1)[0, pred].item()
                confidences.append(conf)
    
    import numpy as np
    print(f"  æ ·æœ¬æ•°: {len(confidences)}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.4f}")
    print(f"  ä¸­ä½æ•°: {np.median(confidences):.4f}")
    print(f"  æœ€å°å€¼: {np.min(confidences):.4f}")
    print(f"  æœ€å¤§å€¼: {np.max(confidences):.4f}")
    
    print("\n" + "=" * 80)
    print("ğŸ’¡ ç»“è®ºå’Œå»ºè®®")
    print("=" * 80)
    print("""
1. æ¨¡å‹å‡†ç¡®ç‡æå‡åˆ°88.8%ï¼Œç¡®å®æ›´éš¾æ”»å‡»
2. éœ€è¦å¢åŠ æ”»å‡»å¼ºåº¦ï¼š
   - One-Pixel: å¢åŠ maxiteråˆ°200-400
   - JSMA: å¢åŠ thetaåˆ°10-50
   - SparseFool: å¯èƒ½éœ€è¦è°ƒæ•´perturbation
   
3. å¦‚æœé«˜ç½®ä¿¡åº¦æ ·æœ¬å¤šï¼Œè¯´æ˜æ¨¡å‹å¾ˆ"è‡ªä¿¡"ï¼Œéœ€è¦æ›´å¼ºçš„æ”»å‡»

4. å»ºè®®ï¼š
   - ä½¿ç”¨æ‰¾åˆ°çš„æœ‰æ•ˆå‚æ•°è¿è¡Œå®Œæ•´å®éªŒ
   - æˆ–è€…è€ƒè™‘ä½¿ç”¨84%æ¨¡å‹è¿›è¡Œåˆæ­¥è®ºæ–‡å®éªŒ
   - 88.8%æ¨¡å‹å¯ä»¥ä½œä¸º"é²æ£’æ€§éªŒè¯"éƒ¨åˆ†
    """)


if __name__ == "__main__":
    debug_single_sample()

