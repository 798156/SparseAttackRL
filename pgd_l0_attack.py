"""
PGD-L0 Attack
åŸºäºæŠ•å½±æ¢¯åº¦ä¸‹é™çš„L0ç¨€ç–æ”»å‡»
æ¯æ¬¡è¿­ä»£é€‰æ‹©æ¢¯åº¦æœ€å¤§çš„kä¸ªåƒç´ è¿›è¡Œä¿®æ”¹
"""

import torch
import numpy as np

def pgd_l0_attack(image, label, model, max_pixels=10, step_size=0.1, num_steps=20):
    """
    PGD-L0ç¨€ç–æ”»å‡»
    
    åŸç†ï¼š
    1. è®¡ç®—æ¢¯åº¦
    2. é€‰æ‹©æ¢¯åº¦æœ€å¤§çš„kä¸ªåƒç´ 
    3. åœ¨è¿™äº›åƒç´ ä¸ŠåšPGDæ›´æ–°
    4. æŠ•å½±å›L0çº¦æŸ
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ (C, H, W)
        label: çœŸå®æ ‡ç­¾
        model: ç›®æ ‡æ¨¡å‹
        max_pixels: æœ€å¤§ä¿®æ”¹åƒç´ æ•°
        step_size: PGDæ­¥é•¿
        num_steps: PGDè¿­ä»£æ¬¡æ•°
    
    è¿”å›:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ åˆ—è¡¨
    """
    device = next(model.parameters()).device
    adv_image = image.clone().to(device)
    
    # å½’ä¸€åŒ–å‚æ•°
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)
    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)
    
    # é¦–å…ˆæ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        output = model(adv_image.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        if pred != label:
            return False, adv_image, []
    
    # åˆå§‹åŒ–ï¼šæ‰¾åˆ°æœ€é‡è¦çš„åƒç´ 
    adv_image_batch = adv_image.unsqueeze(0).requires_grad_(True)
    output = model(adv_image_batch)
    loss = output[0, label]
    
    model.zero_grad()
    loss.backward()
    grad = adv_image_batch.grad[0]
    
    # é€‰æ‹©æ¢¯åº¦ç»å¯¹å€¼æœ€å¤§çš„max_pixelsä¸ªåƒç´ 
    grad_abs = torch.abs(grad)
    grad_flat = grad_abs.view(-1)
    
    # è·å–top-kç´¢å¼•
    C, H, W = adv_image.shape
    k = min(max_pixels * C, grad_flat.numel())  # max_pixelsä¸ªåƒç´  Ã— 3é€šé“
    _, topk_indices = torch.topk(grad_flat, k)
    
    # åˆ›å»ºæ©ç ï¼šåªåœ¨è¿™äº›ä½ç½®ä¸Šä¿®æ”¹
    mask = torch.zeros_like(adv_image, dtype=torch.bool)
    for idx in topk_indices:
        c = idx // (H * W)
        h = (idx % (H * W)) // W
        w = idx % W
        mask[c, h, w] = True
    
    # è®°å½•ä¿®æ”¹çš„åƒç´ ä½ç½®ï¼ˆå»é‡ï¼‰
    modified_pixels_set = set()
    for idx in topk_indices:
        idx_item = idx.item()  # å…ˆè½¬æ¢ä¸ºint
        c = idx_item // (H * W)
        h = (idx_item % (H * W)) // W
        w = idx_item % W
        modified_pixels_set.add((h, w, c))
    
    # PGDè¿­ä»£
    best_adv = adv_image.clone()
    best_conf = 1.0
    
    for step in range(num_steps):
        # æ£€æŸ¥å½“å‰æ˜¯å¦æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            
            if pred != label:
                return True, adv_image, list(modified_pixels_set)
            
            # è®°å½•æœ€ä½³ï¼ˆç½®ä¿¡åº¦æœ€ä½çš„ï¼‰
            conf = torch.softmax(output[0], dim=0)[label].item()
            if conf < best_conf:
                best_conf = conf
                best_adv = adv_image.clone()
        
        # è®¡ç®—æ¢¯åº¦
        adv_image_temp = adv_image.clone().requires_grad_(True)
        adv_image_batch = adv_image_temp.unsqueeze(0)
        
        output = model(adv_image_batch)
        loss = output[0, label]
        
        model.zero_grad()
        loss.backward()
        
        if adv_image_batch.grad is None:
            # å¦‚æœæ¢¯åº¦è®¡ç®—å¤±è´¥ï¼Œåœæ­¢
            break
        
        grad = adv_image_batch.grad[0]
        
        # åªåœ¨maskä½ç½®ä¸Šæ›´æ–°
        with torch.no_grad():
            # PGDæ›´æ–°
            perturbation = step_size * torch.sign(grad)
            adv_image = adv_image - perturbation * mask.float()
            
            # æŠ•å½±åˆ°[0, 1]
            adv_image = torch.clamp(adv_image, 0, 1)
    
    # æœ€åæ£€æŸ¥ä¸€æ¬¡best_adv
    with torch.no_grad():
        output = model(best_adv.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        if pred != label:
            return True, best_adv, list(modified_pixels_set)
    
    return False, best_adv, list(modified_pixels_set)


def test_pgd_l0():
    """æµ‹è¯•PGD-L0æ”»å‡»"""
    import torchvision
    import torchvision.transforms as transforms
    from torch import nn
    
    print("="*80)
    print("ğŸ§ª æµ‹è¯• PGD-L0 Attack")
    print("="*80)
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    
    # åŠ è½½æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = torchvision.models.resnet18(weights=None)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 10)
    model.load_state_dict(torch.load('cifar10_resnet18.pth', map_location=device, weights_only=False))
    model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}\n")
    
    # æµ‹è¯•10ä¸ªæ ·æœ¬
    success_count = 0
    total_l0 = 0
    
    print("å¼€å§‹æµ‹è¯•10ä¸ªæ ·æœ¬...\n")
    
    for i in range(10):
        image, label = testset[i]
        
        # ç¡®ä¿åˆå§‹é¢„æµ‹æ­£ç¡®
        with torch.no_grad():
            output = model(image.unsqueeze(0).to(device))
            pred = output.argmax(dim=1).item()
            if pred != label:
                continue
        
        # æ‰§è¡Œæ”»å‡»
        success, adv_image, modified_pixels = pgd_l0_attack(
            image=image,
            label=label,
            model=model,
            max_pixels=10,
            step_size=0.1,
            num_steps=20
        )
        
        if success:
            success_count += 1
            l0 = len(set([(h, w) for h, w, c in modified_pixels]))
            total_l0 += l0
            print(f"âœ… æ ·æœ¬{i}: æ”»å‡»æˆåŠŸ, L0={l0}")
        else:
            print(f"âŒ æ ·æœ¬{i}: æ”»å‡»å¤±è´¥")
    
    print(f"\n" + "="*80)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  ASR: {success_count}/10 = {success_count*10}%")
    if success_count > 0:
        print(f"  å¹³å‡L0: {total_l0/success_count:.2f}")
    print("="*80)


if __name__ == "__main__":
    test_pgd_l0()

