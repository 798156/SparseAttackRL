# train_rl_v3_simple.py
"""
ç®€åŒ–ç‰ˆRL V3è®­ç»ƒ - ç›´æ¥ä½¿ç”¨å·²æµ‹è¯•çš„ä»£ç 
å…³é”®æ”¹è¿›ï¼š
1. max_stepså¢åŠ åˆ°10
2. é€‰æ‹©ç®€å•æ ·æœ¬ï¼ˆä½ç½®ä¿¡åº¦ï¼‰
3. å¢åŠ ç½®ä¿¡åº¦å¥–åŠ±æƒé‡åˆ°15
"""

import torch
import torchvision
from torchvision import transforms
from sparse_attack_env_v2 import SparseAttackEnvV2
import numpy as np
import os
import time


def select_easy_samples(model, dataset, num_samples=100, max_conf=0.85, device='cuda'):
    """é€‰æ‹©ç®€å•æ ·æœ¬ï¼ˆä½ç½®ä¿¡åº¦ï¼‰"""
    print(f"ğŸ“Š é€‰æ‹©ç®€å•æ ·æœ¬ï¼ˆç½®ä¿¡åº¦<{max_conf}ï¼‰...")
    
    easy_indices = []
    confidences = []
    
    with torch.no_grad():
        for idx in range(min(len(dataset), num_samples * 5)):
            image, label = dataset[idx]
            output = model(image.unsqueeze(0).to(device))
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                conf = torch.softmax(output, dim=1)[0, label].item()
                if conf < max_conf:
                    easy_indices.append(idx)
                    confidences.append(conf)
            
            if len(easy_indices) >= num_samples:
                break
    
    if easy_indices:
        avg_conf = np.mean(confidences)
        print(f"âœ… é€‰æ‹©äº†{len(easy_indices)}ä¸ªæ ·æœ¬ï¼Œå¹³å‡ç½®ä¿¡åº¦: {avg_conf:.3f}")
    else:
        print("âš ï¸  æ‰¾ä¸åˆ°è¶³å¤Ÿç®€å•æ ·æœ¬ï¼Œä½¿ç”¨æ‰€æœ‰æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬")
        for idx in range(min(len(dataset), num_samples * 2)):
            image, label = dataset[idx]
            output = model(image.unsqueeze(0).to(device))
            pred = output.argmax(dim=1).item()
            if pred == label:
                easy_indices.append(idx)
            if len(easy_indices) >= num_samples:
                break
    
    return easy_indices


def main():
    print("=" * 80)
    print("ğŸ¯ RL V3 ç®€åŒ–ç‰ˆè®­ç»ƒ")
    print("=" * 80)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½ResNet18...")
    model = torchvision.models.resnet18(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, 10)
    model.load_state_dict(torch.load('cifar10_resnet18.pth', 
                                     map_location=device, weights_only=False))
    model = model.to(device)
    model.eval()
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    dataset = torchvision.datasets.CIFAR10(root='./data', train=False, 
                                          download=True, transform=transform)
    
    # é€‰æ‹©ç®€å•æ ·æœ¬
    easy_samples = select_easy_samples(model, dataset, num_samples=100, device=device)
    
    if len(easy_samples) < 30:
        print("âŒ ç®€å•æ ·æœ¬å¤ªå°‘")
        return
    
    # é…ç½®
    print("\n" + "=" * 80)
    print("é…ç½®:")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(easy_samples)}")
    print(f"  max_steps: 10")
    print(f"  timesteps: 80,000")
    print(f"  ç½®ä¿¡åº¦æƒé‡: 15.0")
    print("=" * 80)
    
    response = input("\nå¼€å§‹è®­ç»ƒï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        return
    
    # ä½¿ç”¨å·²æµ‹è¯•çš„DynamicSampleEnv
    from ppo_trainer_v3_improved import DynamicSampleEnv
    from stable_baselines3.common.vec_env import DummyVecEnv
    from stable_baselines3 import PPO
    from ppo_trainer_v2 import CNNFeatureExtractor
    import gymnasium as gym
    
    # åˆ›å»ºä¿®æ”¹è¿‡çš„ç¯å¢ƒç±»
    class EasySparseAttackEnvV2(SparseAttackEnvV2):
        """å¢å¼ºç‰ˆï¼šæ›´å¼ºçš„ç½®ä¿¡åº¦å¥–åŠ±"""
        def __init__(self, clean_image, true_label, model, max_steps=10):
            super().__init__(clean_image, true_label, model, max_steps, 
                           use_saliency=True, confidence_reward_weight=15.0)
    
    # åˆ›å»ºåŠ¨æ€ç¯å¢ƒ
    class EasyDynamicSampleEnv(gym.Env):
        def __init__(self):
            super().__init__()
            idx = np.random.choice(easy_samples)
            image, label = dataset[idx]
            self.current_env = EasySparseAttackEnvV2(image, label, model)
            self.action_space = self.current_env.action_space
            self.observation_space = self.current_env.observation_space
        
        def reset(self, **kwargs):
            # éšæœºé€‰æ‹©æ–°æ ·æœ¬
            idx = np.random.choice(easy_samples)
            image, label = dataset[idx]
            self.current_env = EasySparseAttackEnvV2(image, label, model)
            return self.current_env.reset(**kwargs)
        
        def step(self, action):
            return self.current_env.step(action)
    
    # åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
    env = DummyVecEnv([lambda: EasyDynamicSampleEnv()])
    
    # åˆ›å»ºPPO agent
    policy_kwargs = dict(
        features_extractor_class=CNNFeatureExtractor,
        features_extractor_kwargs=dict(features_dim=256),
        net_arch=dict(pi=[128, 128], vf=[128, 128])  # ä¿®æ­£æ ¼å¼
    )
    
    agent = PPO(
        "CnnPolicy", env,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        ent_coef=0.01,
        policy_kwargs=policy_kwargs,
        verbose=1,
        tensorboard_log="./logs/",
        device=device
    )
    
    # è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...\n")
    start_time = time.time()
    
    try:
        agent.learn(total_timesteps=80000, progress_bar=True,
                   tb_log_name="ppo_resnet18_v3_simple")
        
        # ä¿å­˜
        os.makedirs('models', exist_ok=True)
        agent.save('models/ppo_resnet18_v3_simple')
        
        elapsed = time.time() - start_time
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼è€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ")
        print("ğŸ“ ä¿å­˜: models/ppo_resnet18_v3_simple.zip")
        
        # å¿«é€ŸéªŒè¯
        print("\nğŸ§ª å¿«é€ŸéªŒè¯...")
        successes = 0
        
        for i in range(10):
            idx = easy_samples[i]
            image, label = dataset[idx]
            
            test_env = EasySparseAttackEnvV2(image, label, model)
            obs, _ = test_env.reset()
            
            for _ in range(15):
                action, _ = agent.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = test_env.step(action)
                if terminated or truncated:
                    break
            
            with torch.no_grad():
                pred = model(test_env.current_image).argmax(dim=1).item()
            
            if pred != label:
                successes += 1
                print(f"  æ ·æœ¬{i}: âœ…")
            else:
                print(f"  æ ·æœ¬{i}: âŒ")
        
        print(f"\nASR: {successes*10}%")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒä¸­æ–­")
        agent.save('models/ppo_resnet18_v3_simple_interrupted')
    except Exception as e:
        print(f"\nâŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()








