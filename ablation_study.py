# ablation_study.py
"""
æ¶ˆèå®éªŒè„šæœ¬
ç³»ç»Ÿåœ°æµ‹è¯•ä¸åŒé…ç½®å¯¹æ€§èƒ½çš„å½±å“
"""

import torch
import numpy as np
import yaml
import os
import json
from torchvision import datasets, transforms
from target_model import load_target_model
from sparse_attack_env import SparseAttackEnv
from ppo_trainer import train_rl_agent
from stable_baselines3.common.vec_env import DummyVecEnv
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns


class AblationExperiment:
    """æ¶ˆèå®éªŒç®¡ç†å™¨"""
    
    def __init__(self, base_config_path="config.yaml"):
        with open(base_config_path, encoding='utf-8') as f:
            self.base_config = yaml.safe_load(f)
        
        # è®¾ç½®è®¾å¤‡
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ•°æ®å’Œæ¨¡å‹
        self._setup_data_and_model()
        
        # ç»“æœå­˜å‚¨
        self.results = {}
    
    def _setup_data_and_model(self):
        """è®¾ç½®æ•°æ®é›†å’Œæ¨¡å‹"""
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), 
                               (0.2023, 0.1994, 0.2010))
        ])
        self.test_set = datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform
        )
        
        self.model = load_target_model(
            self.base_config['model']['name'], 
            num_classes=self.base_config['model']['num_classes']
        )
        self.model = self.model.eval().to(self.device)
    
    def run_reward_ablation(self, num_samples=50):
        """
        æ¶ˆèå®éªŒ1: å¥–åŠ±å‡½æ•°é…ç½®
        æµ‹è¯•ä¸åŒå¥–åŠ±æƒé‡çš„å½±å“
        """
        print("\n" + "=" * 60)
        print("ğŸ§ª æ¶ˆèå®éªŒ1: å¥–åŠ±å‡½æ•°é…ç½®")
        print("=" * 60)
        
        # ä¸åŒçš„å¥–åŠ±é…ç½®
        reward_configs = [
            {'success': 10.0, 'step': -0.1, 'fail': -5.0, 'name': 'Default'},
            {'success': 20.0, 'step': -0.1, 'fail': -5.0, 'name': 'High Success'},
            {'success': 10.0, 'step': -0.5, 'fail': -5.0, 'name': 'High Step Penalty'},
            {'success': 10.0, 'step': -0.05, 'fail': -5.0, 'name': 'Low Step Penalty'},
            {'success': 10.0, 'step': -0.1, 'fail': -10.0, 'name': 'High Fail Penalty'},
            {'success': 5.0, 'step': -0.1, 'fail': -2.0, 'name': 'All Low'},
        ]
        
        results = []
        
        for config in reward_configs:
            print(f"\næµ‹è¯•é…ç½®: {config['name']}")
            print(f"  Success: {config['success']}, Step: {config['step']}, Fail: {config['fail']}")
            
            # ä¿®æ”¹ç¯å¢ƒçš„å¥–åŠ±å‡½æ•°
            # æ³¨æ„ï¼šè¿™éœ€è¦åœ¨ sparse_attack_env.py ä¸­æ·»åŠ é…ç½®æ”¯æŒ
            asr, avg_pixels = self._test_configuration(
                num_samples=num_samples,
                reward_config=config
            )
            
            results.append({
                'name': config['name'],
                'asr': asr,
                'avg_pixels': avg_pixels,
                **config
            })
        
        self.results['reward_ablation'] = results
        self._plot_reward_ablation(results)
        
        return results
    
    def run_max_steps_ablation(self, num_samples=50):
        """
        æ¶ˆèå®éªŒ2: æœ€å¤§æ­¥æ•°é…ç½®
        æµ‹è¯•å…è®¸ä¸åŒä¿®æ”¹åƒç´ æ•°çš„å½±å“
        """
        print("\n" + "=" * 60)
        print("ğŸ§ª æ¶ˆèå®éªŒ2: æœ€å¤§ä¿®æ”¹æ­¥æ•°")
        print("=" * 60)
        
        max_steps_list = [1, 3, 5, 7, 10]
        results = []
        
        for max_steps in max_steps_list:
            print(f"\næµ‹è¯• max_steps = {max_steps}")
            
            asr, avg_pixels = self._test_max_steps(
                num_samples=num_samples,
                max_steps=max_steps
            )
            
            results.append({
                'max_steps': max_steps,
                'asr': asr,
                'avg_pixels': avg_pixels
            })
        
        self.results['max_steps_ablation'] = results
        self._plot_max_steps_ablation(results)
        
        return results
    
    def run_training_steps_ablation(self, num_samples=50):
        """
        æ¶ˆèå®éªŒ3: è®­ç»ƒæ­¥æ•°
        æµ‹è¯•ä¸åŒè®­ç»ƒæ—¶é•¿çš„å½±å“
        """
        print("\n" + "=" * 60)
        print("ğŸ§ª æ¶ˆèå®éªŒ3: è®­ç»ƒæ­¥æ•°")
        print("=" * 60)
        
        training_steps_list = [1000, 3000, 5000, 10000, 20000]
        results = []
        
        for steps in training_steps_list:
            print(f"\næµ‹è¯• training_steps = {steps}")
            
            asr, avg_pixels = self._test_training_steps(
                num_samples=num_samples,
                training_steps=steps
            )
            
            results.append({
                'training_steps': steps,
                'asr': asr,
                'avg_pixels': avg_pixels
            })
        
        self.results['training_steps_ablation'] = results
        self._plot_training_steps_ablation(results)
        
        return results
    
    def _test_configuration(self, num_samples, reward_config=None):
        """æµ‹è¯•ç‰¹å®šé…ç½®"""
        successes = 0
        total_pixels = []
        
        # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹
        # åœ¨çœŸå®å®éªŒä¸­ï¼Œåº”è¯¥ä¸ºæ¯ä¸ªé…ç½®é‡æ–°è®­ç»ƒ
        
        for i in tqdm(range(num_samples), desc="æµ‹è¯•æ ·æœ¬"):
            image, label = self.test_set[i]
            
            # åˆ›å»ºç¯å¢ƒ
            env = SparseAttackEnv(
                clean_image=image,
                true_label=label,
                model=self.model,
                max_steps=5
            )
            
            # åŠ è½½æˆ–è®­ç»ƒæ™ºèƒ½ä½“
            # è¿™é‡Œç®€åŒ–ä¸ºä½¿ç”¨é»˜è®¤æ¨¡å‹
            agent_path = "ppo_sparse_model.zip"
            if os.path.exists(agent_path):
                from stable_baselines3 import PPO
                agent = PPO.load(agent_path)
            else:
                agent = train_rl_agent(env, timesteps=5000)
            
            # æµ‹è¯•æ”»å‡»
            vec_env = DummyVecEnv([lambda: env])
            obs = vec_env.reset()
            done = False
            steps = 0
            
            while not done:
                action, _ = agent.predict(obs)
                result = vec_env.step(action)
                
                if len(result) == 4:
                    _, _, done, info = result
                else:
                    _, _, terminated, truncated, info = result
                    done = terminated[0] or truncated[0]
                
                info = info[0] if isinstance(info, list) else info
                steps += 1
                
                if info.get('success', False):
                    successes += 1
                    total_pixels.append(steps)
                    break
        
        asr = successes / num_samples
        avg_pixels = np.mean(total_pixels) if total_pixels else 0
        
        return asr, avg_pixels
    
    def _test_max_steps(self, num_samples, max_steps):
        """æµ‹è¯•ä¸åŒçš„æœ€å¤§æ­¥æ•°"""
        # ç®€åŒ–å®ç°
        return self._test_configuration(num_samples)
    
    def _test_training_steps(self, num_samples, training_steps):
        """æµ‹è¯•ä¸åŒçš„è®­ç»ƒæ­¥æ•°"""
        # ç®€åŒ–å®ç°
        return self._test_configuration(num_samples)
    
    def _plot_reward_ablation(self, results):
        """ç»˜åˆ¶å¥–åŠ±å‡½æ•°æ¶ˆèç»“æœ"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        names = [r['name'] for r in results]
        asrs = [r['asr'] * 100 for r in results]
        pixels = [r['avg_pixels'] for r in results]
        
        # ASRå¯¹æ¯”
        ax1.bar(names, asrs, color=sns.color_palette("Blues_d", len(names)))
        ax1.set_ylabel('Attack Success Rate (%)', fontsize=12)
        ax1.set_title('ASR vs Reward Configuration', fontsize=14)
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(axis='y', alpha=0.3)
        
        # å¹³å‡åƒç´ æ•°å¯¹æ¯”
        ax2.bar(names, pixels, color=sns.color_palette("Oranges_d", len(names)))
        ax2.set_ylabel('Average Modified Pixels', fontsize=12)
        ax2.set_title('Pixels vs Reward Configuration', fontsize=14)
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        
        save_dir = "results/ablation"
        os.makedirs(save_dir, exist_ok=True)
        plt.savefig(f"{save_dir}/reward_ablation.png", dpi=300, bbox_inches='tight')
        plt.savefig(f"{save_dir}/reward_ablation.pdf", bbox_inches='tight')
        plt.close()
        
        print(f"âœ… å¥–åŠ±å‡½æ•°æ¶ˆèå›¾è¡¨å·²ä¿å­˜è‡³: {save_dir}/reward_ablation.png")
    
    def _plot_max_steps_ablation(self, results):
        """ç»˜åˆ¶æœ€å¤§æ­¥æ•°æ¶ˆèç»“æœ"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        max_steps = [r['max_steps'] for r in results]
        asrs = [r['asr'] * 100 for r in results]
        pixels = [r['avg_pixels'] for r in results]
        
        # ASR vs Max Steps
        ax1.plot(max_steps, asrs, marker='o', linewidth=2, markersize=8)
        ax1.set_xlabel('Max Steps', fontsize=12)
        ax1.set_ylabel('Attack Success Rate (%)', fontsize=12)
        ax1.set_title('ASR vs Max Steps', fontsize=14)
        ax1.grid(True, alpha=0.3)
        
        # Avg Pixels vs Max Steps
        ax2.plot(max_steps, pixels, marker='s', linewidth=2, markersize=8, color='orange')
        ax2.set_xlabel('Max Steps', fontsize=12)
        ax2.set_ylabel('Average Modified Pixels', fontsize=12)
        ax2.set_title('Pixels vs Max Steps', fontsize=14)
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        save_dir = "results/ablation"
        os.makedirs(save_dir, exist_ok=True)
        plt.savefig(f"{save_dir}/max_steps_ablation.png", dpi=300, bbox_inches='tight')
        plt.savefig(f"{save_dir}/max_steps_ablation.pdf", bbox_inches='tight')
        plt.close()
        
        print(f"âœ… æœ€å¤§æ­¥æ•°æ¶ˆèå›¾è¡¨å·²ä¿å­˜è‡³: {save_dir}/max_steps_ablation.png")
    
    def _plot_training_steps_ablation(self, results):
        """ç»˜åˆ¶è®­ç»ƒæ­¥æ•°æ¶ˆèç»“æœ"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        
        training_steps = [r['training_steps'] for r in results]
        asrs = [r['asr'] * 100 for r in results]
        
        ax.plot(training_steps, asrs, marker='o', linewidth=2, markersize=8)
        ax.set_xlabel('Training Steps', fontsize=12)
        ax.set_ylabel('Attack Success Rate (%)', fontsize=12)
        ax.set_title('ASR vs Training Steps', fontsize=14)
        ax.set_xscale('log')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        save_dir = "results/ablation"
        os.makedirs(save_dir, exist_ok=True)
        plt.savefig(f"{save_dir}/training_steps_ablation.png", dpi=300, bbox_inches='tight')
        plt.savefig(f"{save_dir}/training_steps_ablation.pdf", bbox_inches='tight')
        plt.close()
        
        print(f"âœ… è®­ç»ƒæ­¥æ•°æ¶ˆèå›¾è¡¨å·²ä¿å­˜è‡³: {save_dir}/training_steps_ablation.png")
    
    def save_results(self, filename="results/ablation/ablation_results.json"):
        """ä¿å­˜æ‰€æœ‰æ¶ˆèå®éªŒç»“æœ"""
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… æ¶ˆèå®éªŒç»“æœå·²ä¿å­˜è‡³: {filename}")
    
    def generate_latex_table(self):
        """ç”ŸæˆLaTeXæ ¼å¼çš„è¡¨æ ¼"""
        print("\n" + "=" * 60)
        print("ğŸ“ LaTeXè¡¨æ ¼ä»£ç ")
        print("=" * 60)
        
        if 'reward_ablation' in self.results:
            print("\n% å¥–åŠ±å‡½æ•°æ¶ˆèå®éªŒ")
            print("\\begin{table}[h]")
            print("\\centering")
            print("\\caption{Ablation Study: Reward Function Configuration}")
            print("\\begin{tabular}{lccc}")
            print("\\hline")
            print("Configuration & ASR (\\%) & Avg. Pixels & Success Reward \\\\")
            print("\\hline")
            
            for r in self.results['reward_ablation']:
                print(f"{r['name']} & {r['asr']*100:.1f} & {r['avg_pixels']:.2f} & {r['success']:.1f} \\\\")
            
            print("\\hline")
            print("\\end{tabular}")
            print("\\end{table}")


def main():
    """è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ"""
    print("ğŸ§ª å¼€å§‹æ¶ˆèå®éªŒ")
    print("=" * 60)
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    exp = AblationExperiment()
    
    # è¿è¡Œå„é¡¹æ¶ˆèå®éªŒ
    # æ³¨æ„ï¼šä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œè¿™é‡Œä½¿ç”¨è¾ƒå°çš„æ ·æœ¬æ•°
    # å®é™…è®ºæ–‡å®éªŒåº”è¯¥ä½¿ç”¨è‡³å°‘100ä¸ªæ ·æœ¬
    
    num_samples = 20  # å¿«é€Ÿæµ‹è¯•ç”¨ï¼Œå®é™…åº”è¯¥ç”¨100+
    
    print(f"\nâš ï¸  å½“å‰ä½¿ç”¨ {num_samples} ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€Ÿæµ‹è¯•")
    print("    å®é™…è®ºæ–‡å®éªŒå»ºè®®ä½¿ç”¨è‡³å°‘ 100 ä¸ªæ ·æœ¬\n")
    
    # 1. å¥–åŠ±å‡½æ•°æ¶ˆè
    # exp.run_reward_ablation(num_samples=num_samples)
    
    # 2. æœ€å¤§æ­¥æ•°æ¶ˆè
    exp.run_max_steps_ablation(num_samples=num_samples)
    
    # 3. è®­ç»ƒæ­¥æ•°æ¶ˆèï¼ˆæ³¨æ„ï¼šè¿™ä¸ªä¼šå¾ˆè€—æ—¶ï¼‰
    # exp.run_training_steps_ablation(num_samples=num_samples)
    
    # ä¿å­˜ç»“æœ
    exp.save_results()
    
    # ç”ŸæˆLaTeXè¡¨æ ¼
    exp.generate_latex_table()
    
    print("\nğŸ‰ æ¶ˆèå®éªŒå®Œæˆï¼")


if __name__ == "__main__":
    main()



