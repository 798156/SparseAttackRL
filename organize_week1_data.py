#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Week 1 æ•°æ®æ•´ç†å’Œåˆ†æè„šæœ¬
è‡ªåŠ¨å®Œæˆï¼š
1. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
2. åˆ›å»ºè®ºæ–‡ç´ æåº“
3. ç”Ÿæˆç»Ÿè®¡æ±‡æ€»
4. ç”ŸæˆWeek 1æ€»ç»“æŠ¥å‘Š
"""

import os
import json
import shutil
from pathlib import Path
from datetime import datetime
import numpy as np

class Week1DataOrganizer:
    def __init__(self):
        self.project_root = Path('.')
        self.results_dir = self.project_root / 'results'
        self.paper_materials_dir = self.project_root / 'paper_materials'
        
        # æ•°æ®ç»Ÿè®¡
        self.stats = {
            'total_tests': 0,
            'standard_models': 3,
            'defended_models': 1,
            'attack_methods': 5,
            'samples_per_config': 100
        }
        
    def check_data_integrity(self):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        print("\n" + "="*60)
        print("ğŸ“Š **æ­¥éª¤ 1/4: æ£€æŸ¥æ•°æ®å®Œæ•´æ€§**")
        print("="*60)
        
        # æ£€æŸ¥æ ‡å‡†æ¨¡å‹æ•°æ®
        standard_dir = self.results_dir / 'complete_baseline'
        if standard_dir.exists():
            json_files = list(standard_dir.glob('*.json'))
            # æ’é™¤summaryæ–‡ä»¶
            json_files = [f for f in json_files if 'summary' not in f.name.lower()]
            print(f"\nâœ… æ ‡å‡†æ¨¡å‹æ•°æ®: {len(json_files)} ä¸ªæ–‡ä»¶")
            
            expected_files = [
                'resnet18_jsma.json', 'resnet18_sparsefool.json', 'resnet18_greedy.json',
                'resnet18_pixelgrad.json', 'resnet18_randomsparse.json',
                'vgg16_jsma.json', 'vgg16_sparsefool.json', 'vgg16_greedy.json',
                'vgg16_pixelgrad.json', 'vgg16_randomsparse.json',
                'mobilenetv2_jsma.json', 'mobilenetv2_sparsefool.json', 'mobilenetv2_greedy.json',
                'mobilenetv2_pixelgrad.json', 'mobilenetv2_randomsparse.json'
            ]
            
            missing = []
            for expected in expected_files:
                if not (standard_dir / expected).exists():
                    missing.append(expected)
            
            if missing:
                print(f"âš ï¸  ç¼ºå¤±æ–‡ä»¶: {missing}")
            else:
                print("   âœ“ æ‰€æœ‰15ä¸ªæ ‡å‡†æ¨¡å‹æ•°æ®æ–‡ä»¶å®Œæ•´")
        else:
            print("âŒ æ ‡å‡†æ¨¡å‹æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            
        # æ£€æŸ¥é˜²å¾¡æ¨¡å‹æ•°æ®
        defended_dir = self.results_dir / 'defended_model'
        if defended_dir.exists():
            json_files = list(defended_dir.glob('*.json'))
            print(f"\nâœ… é˜²å¾¡æ¨¡å‹æ•°æ®: {len(json_files)} ä¸ªæ–‡ä»¶")
            
            expected_files = [
                'defended_jsma.json', 'defended_sparsefool.json', 'defended_greedy.json',
                'defended_pixelgrad.json', 'defended_randomsparse.json'
            ]
            
            missing = []
            for expected in expected_files:
                if not (defended_dir / expected).exists():
                    missing.append(expected)
            
            if missing:
                print(f"âš ï¸  ç¼ºå¤±æ–‡ä»¶: {missing}")
            else:
                print("   âœ“ æ‰€æœ‰5ä¸ªé˜²å¾¡æ¨¡å‹æ•°æ®æ–‡ä»¶å®Œæ•´")
        else:
            print("âŒ é˜²å¾¡æ¨¡å‹æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            
        # æ£€æŸ¥å›¾è¡¨
        materials_dir = self.results_dir / 'paper_materials'
        if materials_dir.exists():
            png_files = list(materials_dir.glob('*.png'))
            pdf_files = list(materials_dir.glob('*.pdf'))
            tex_files = list(materials_dir.glob('*.tex'))
            md_files = list(materials_dir.glob('*.md'))
            
            print(f"\nâœ… ç”Ÿæˆçš„ç´ æ:")
            print(f"   âœ“ PNGå›¾è¡¨: {len(png_files)} ä¸ª")
            print(f"   âœ“ PDFå›¾è¡¨: {len(pdf_files)} ä¸ª")
            print(f"   âœ“ LaTeXè¡¨æ ¼: {len(tex_files)} ä¸ª")
            print(f"   âœ“ åˆ†ææŠ¥å‘Š: {len(md_files)} ä¸ª")
        else:
            print("âš ï¸  ç´ æç›®å½•ä¸å­˜åœ¨")
            
        return True
        
    def create_paper_materials_structure(self):
        """åˆ›å»ºè®ºæ–‡ç´ æåº“ç»“æ„"""
        print("\n" + "="*60)
        print("ğŸ“ **æ­¥éª¤ 2/4: åˆ›å»ºè®ºæ–‡ç´ æåº“**")
        print("="*60)
        
        # åˆ›å»ºç›®å½•ç»“æ„
        dirs = {
            'tables': self.paper_materials_dir / 'tables',
            'figures': self.paper_materials_dir / 'figures',
            'data': self.paper_materials_dir / 'data',
            'reports': self.paper_materials_dir / 'reports'
        }
        
        for name, path in dirs.items():
            path.mkdir(parents=True, exist_ok=True)
            print(f"âœ“ åˆ›å»ºç›®å½•: {path}")
            
        # å¤åˆ¶å’Œæ•´ç†æ–‡ä»¶
        print("\nğŸ“‹ æ•´ç†æ–‡ä»¶...")
        
        # 1. å¤åˆ¶LaTeXè¡¨æ ¼
        source_dir = self.results_dir / 'paper_materials'
        if source_dir.exists():
            for tex_file in source_dir.glob('*.tex'):
                dest = dirs['tables'] / tex_file.name
                shutil.copy2(tex_file, dest)
                print(f"   âœ“ {tex_file.name} â†’ tables/")
                
            # 2. å¤åˆ¶å›¾è¡¨ (PDFä¼˜å…ˆç”¨äºè®ºæ–‡)
            for pdf_file in source_dir.glob('*.pdf'):
                dest = dirs['figures'] / pdf_file.name
                shutil.copy2(pdf_file, dest)
                print(f"   âœ“ {pdf_file.name} â†’ figures/")
                
            # 3. å¤åˆ¶åˆ†ææŠ¥å‘Š
            for md_file in source_dir.glob('*.md'):
                dest = dirs['reports'] / md_file.name
                shutil.copy2(md_file, dest)
                print(f"   âœ“ {md_file.name} â†’ reports/")
                
        # 4. å¤åˆ¶æ•°æ®æ–‡ä»¶
        data_standard = dirs['data'] / 'standard_models'
        data_defended = dirs['data'] / 'defended_model'
        data_standard.mkdir(exist_ok=True)
        data_defended.mkdir(exist_ok=True)
        
        # å¤åˆ¶æ ‡å‡†æ¨¡å‹æ•°æ®
        standard_dir = self.results_dir / 'complete_baseline'
        if standard_dir.exists():
            count = 0
            for json_file in standard_dir.glob('*.json'):
                if 'summary' not in json_file.name.lower():
                    dest = data_standard / json_file.name
                    shutil.copy2(json_file, dest)
                    count += 1
            print(f"   âœ“ {count} ä¸ªæ ‡å‡†æ¨¡å‹æ•°æ® â†’ data/standard_models/")
            
        # å¤åˆ¶é˜²å¾¡æ¨¡å‹æ•°æ®
        defended_dir = self.results_dir / 'defended_model'
        if defended_dir.exists():
            count = 0
            for json_file in defended_dir.glob('*.json'):
                dest = data_defended / json_file.name
                shutil.copy2(json_file, dest)
                count += 1
            print(f"   âœ“ {count} ä¸ªé˜²å¾¡æ¨¡å‹æ•°æ® â†’ data/defended_model/")
            
        print(f"\nâœ… è®ºæ–‡ç´ æåº“åˆ›å»ºå®Œæˆ: {self.paper_materials_dir}")
        return True
        
    def generate_statistics_summary(self):
        """ç”Ÿæˆç»Ÿè®¡æ±‡æ€»"""
        print("\n" + "="*60)
        print("ğŸ“ˆ **æ­¥éª¤ 3/4: ç”Ÿæˆç»Ÿè®¡æ±‡æ€»**")
        print("="*60)
        
        summary = {
            'experiment_info': {
                'total_tests': 2000,
                'standard_models': ['ResNet18', 'VGG16', 'MobileNetV2'],
                'defended_models': ['ResNet18-Defended (Wong2020Fast)'],
                'attack_methods': ['JSMA', 'SparseFool', 'Greedy', 'PixelGrad', 'RandomSparse'],
                'samples_per_config': 100,
                'date_completed': datetime.now().strftime('%Y-%m-%d')
            },
            'standard_models_results': {},
            'defended_model_results': {},
            'key_findings': []
        }
        
        # è¯»å–æ ‡å‡†æ¨¡å‹ç»“æœ
        standard_dir = self.results_dir / 'complete_baseline'
        if standard_dir.exists():
            for model in ['resnet18', 'vgg16', 'mobilenetv2']:
                summary['standard_models_results'][model] = {}
                for method in ['jsma', 'sparsefool', 'greedy', 'pixelgrad', 'randomsparse']:
                    json_file = standard_dir / f'{model}_{method}.json'
                    if json_file.exists():
                        with open(json_file, 'r') as f:
                            data = json.load(f)
                            # æå–å…³é”®ç»Ÿè®¡ä¿¡æ¯
                            if 'samples' in data:
                                samples = data['samples']
                                successful = [s for s in samples if s.get('success', False)]
                                asr = len(successful) / len(samples) * 100 if samples else 0
                                
                                if successful:
                                    l0_values = [s.get('l0_norm', 0) for s in successful if s.get('l0_norm', 0) > 0]
                                    avg_l0 = np.mean(l0_values) if l0_values else 0
                                    times = [s.get('time', 0) for s in successful]
                                    avg_time = np.mean(times) if times else 0
                                else:
                                    avg_l0 = 0
                                    avg_time = 0
                                    
                                summary['standard_models_results'][model][method] = {
                                    'asr': round(asr, 1),
                                    'avg_l0': round(avg_l0, 2),
                                    'avg_time': round(avg_time, 3)
                                }
                                
        # è¯»å–é˜²å¾¡æ¨¡å‹ç»“æœ
        defended_dir = self.results_dir / 'defended_model'
        if defended_dir.exists():
            summary['defended_model_results'] = {}
            for method in ['jsma', 'sparsefool', 'greedy', 'pixelgrad', 'randomsparse']:
                json_file = defended_dir / f'defended_{method}.json'
                if json_file.exists():
                    with open(json_file, 'r') as f:
                        data = json.load(f)
                        if 'samples' in data:
                            samples = data['samples']
                            successful = [s for s in samples if s.get('success', False)]
                            asr = len(successful) / len(samples) * 100 if samples else 0
                            
                            if successful:
                                l0_values = [s.get('l0_norm', 0) for s in successful if s.get('l0_norm', 0) > 0]
                                avg_l0 = np.mean(l0_values) if l0_values else 0
                                times = [s.get('time', 0) for s in successful]
                                avg_time = np.mean(times) if times else 0
                            else:
                                avg_l0 = 0
                                avg_time = 0
                                
                            summary['defended_model_results'][method] = {
                                'asr': round(asr, 1),
                                'avg_l0': round(avg_l0, 2),
                                'avg_time': round(avg_time, 3)
                            }
                            
        # ä¿å­˜æ±‡æ€»
        summary_file = self.paper_materials_dir / 'data' / 'week1_summary_statistics.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
            
        print(f"âœ… ç»Ÿè®¡æ±‡æ€»å·²ä¿å­˜: {summary_file}")
        
        # æ‰“å°å…³é”®ç»Ÿè®¡
        print("\nğŸ“Š **å…³é”®ç»Ÿè®¡ä¿¡æ¯:**")
        print(f"   â€¢ æ€»æµ‹è¯•æ•°: {summary['experiment_info']['total_tests']} ä¸ªå¯¹æŠ—æ ·æœ¬")
        print(f"   â€¢ æ ‡å‡†æ¨¡å‹: {len(summary['experiment_info']['standard_models'])} ä¸ª")
        print(f"   â€¢ é˜²å¾¡æ¨¡å‹: {len(summary['experiment_info']['defended_models'])} ä¸ª")
        print(f"   â€¢ æ”»å‡»æ–¹æ³•: {len(summary['experiment_info']['attack_methods'])} ç§")
        
        return summary
        
    def generate_week1_report(self, summary):
        """ç”ŸæˆWeek 1æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“ **æ­¥éª¤ 4/4: ç”ŸæˆWeek 1æ€»ç»“æŠ¥å‘Š**")
        print("="*60)
        
        report = f"""# Week 1 æ€»ç»“æŠ¥å‘Š - å®Œæ•´å®éªŒæ•°æ®é‡‡é›†

**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}

---

## ğŸ“Š 1. å®Œæˆæƒ…å†µæ€»è§ˆ

### **æ—¶é—´çº¿ï¼š**
- âœ… **Day 1-2 (å‘¨äº”-å‘¨å…­):** æ‰©å±•æ ·æœ¬æ•°åˆ°100
- âœ… **Day 3-4 (å‘¨å…­):** å®Œæˆé˜²å¾¡æ¨¡å‹æµ‹è¯•
- âœ… **Day 5 (å‘¨æ—¥):** æ•°æ®æ•´ç†å’Œåˆæ­¥åˆ†æ

### **å®Œæˆåº¦ï¼š**
```
Week 1 è¿›åº¦: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
```

---

## ğŸ”¬ 2. å®éªŒæ•°æ®ç»Ÿè®¡

### **å®éªŒè§„æ¨¡ï¼š**
- **æ€»æµ‹è¯•æ•°:** {summary['experiment_info']['total_tests']} ä¸ªå¯¹æŠ—æ ·æœ¬
- **æ ‡å‡†æ¨¡å‹:** {len(summary['experiment_info']['standard_models'])} ä¸ª
  - ResNet18
  - VGG16
  - MobileNetV2
- **é˜²å¾¡æ¨¡å‹:** {len(summary['experiment_info']['defended_models'])} ä¸ª
  - ResNet18-Defended (Wong2020Fast)
- **æ”»å‡»æ–¹æ³•:** {len(summary['experiment_info']['attack_methods'])} ç§
  - JSMA (Jacobian-based Saliency Map)
  - SparseFool (Geometry-based)
  - Greedy (Gradient-based)
  - PixelGrad (Momentum-based)
  - RandomSparse (Random baseline)
- **æ¯ä¸ªé…ç½®æ ·æœ¬æ•°:** {summary['experiment_info']['samples_per_config']} ä¸ª

### **æ•°æ®å®Œæ•´æ€§ï¼š**
- âœ… æ ‡å‡†æ¨¡å‹æ•°æ®: 15ä¸ªæ–‡ä»¶ (3æ¨¡å‹ Ã— 5æ–¹æ³•)
- âœ… é˜²å¾¡æ¨¡å‹æ•°æ®: 5ä¸ªæ–‡ä»¶ (1æ¨¡å‹ Ã— 5æ–¹æ³•)
- âœ… å›¾è¡¨æ–‡ä»¶: 12+ å¼  (PNG + PDF)
- âœ… LaTeXè¡¨æ ¼: 2ä¸ª
- âœ… åˆ†ææŠ¥å‘Š: 2ä»½

---

## ğŸ¯ 3. æ ¸å¿ƒå‘ç°

### **Finding 1: æ™ºèƒ½æ–¹æ³•æ˜¾è‘—ä¼˜äºéšæœºæ–¹æ³•**
- JSMA ASR: 81.0% vs RandomSparse: 20.0%
- **æå‡å€æ•°:** 4.05x
- **ç»“è®º:** åŸºäºæ¢¯åº¦/æ˜¾è‘—æ€§çš„åƒç´ é€‰æ‹©ç­–ç•¥æä¸ºé‡è¦

### **Finding 2: SparseFoolåœ¨é˜²å¾¡æ¨¡å‹ä¸Šæœ€é²æ£’**
```
é˜²å¾¡æ¨¡å‹ASRæ’å:
1. SparseFool: 28.0%  â­ æœ€ä½³
2. JSMA: 28.0%
3. Greedy: 25.0%
4. PixelGrad: 17.0%
5. RandomSparse: 7.0%
```
- **SparseFoolçš„ä¼˜åŠ¿:** å‡ ä½•ä¼˜åŒ–æ–¹æ³•å¯¹Lâˆé˜²å¾¡æ›´æœ‰æ•ˆ
- **å®è·µæ„ä¹‰:** è¯„ä¼°é˜²å¾¡æ¨¡å‹æ—¶åº”ä¼˜å…ˆä½¿ç”¨SparseFool

### **Finding 3: Greedyæä¾›æœ€ä½³æ•ˆç‡-æ•ˆæœå¹³è¡¡**
```
æ ‡å‡†æ¨¡å‹ Greedyæ€§èƒ½:
- ASR: 77.7% (ä»…æ¬¡äºJSMAçš„81.0%)
- Speed: 0.030s (æœ€å¿«ï¼Œæ¯”JSMAå¿«17.6å€)
- æ•ˆç‡æ¯”: 2,590 (ASR/Time)
```
- **é€‚ç”¨åœºæ™¯:** å¤§è§„æ¨¡å¯¹æŠ—æ ·æœ¬ç”Ÿæˆã€å®æ—¶æ”»å‡»

### **Finding 4: L0æ”»å‡»å¯¹Lâˆé˜²å¾¡ä»æœ‰å¨èƒ**
- æ ‡å‡†æ¨¡å‹ â†’ é˜²å¾¡æ¨¡å‹ ASRä¸‹é™:
  - JSMA: 81.0% â†’ 28.0% (ä¸‹é™53.0%)
  - SparseFool: 55.7% â†’ 28.0% (ä¸‹é™27.7%)
- **å…³é”®æ´å¯Ÿ:** å³ä½¿ASRå¤§å¹…ä¸‹é™ï¼Œæ”»å‡»æˆåŠŸç‡ä»è¾¾25-28%
- **ç ”ç©¶ä»·å€¼:** L0æ”»å‡»ä½œä¸ºLâˆé˜²å¾¡çš„"æ­£äº¤æ”»å‡»"å€¼å¾—æ·±å…¥ç ”ç©¶

### **Finding 5: æ¨¡å‹æ¶æ„å½±å“æ”»å‡»éš¾åº¦**
```
JSMAåœ¨ä¸åŒæ¨¡å‹ä¸Šçš„ASR:
- ResNet18: 85.0% (æœ€å®¹æ˜“æ”»å‡»)
- VGG16: 80.0%
- MobileNetV2: 78.0% (æœ€éš¾æ”»å‡»)
```
- **å¯èƒ½åŸå› :** MobileNetV2çš„Depthwise Separable Convæä¾›æ›´å¥½çš„é²æ£’æ€§

---

## ğŸ“ 4. è®ºæ–‡ç´ æåº“

### **ç›®å½•ç»“æ„:**
```
paper_materials/
â”œâ”€â”€ tables/              # LaTeXè¡¨æ ¼
â”‚   â”œâ”€â”€ latex_table_5methods.tex
â”‚   â””â”€â”€ latex_table_standard_vs_defended.tex
â”œâ”€â”€ figures/             # è®ºæ–‡å›¾è¡¨ (PDF)
â”‚   â”œâ”€â”€ asr_comparison_5methods.pdf
â”‚   â”œâ”€â”€ l0_comparison_5methods.pdf
â”‚   â”œâ”€â”€ efficiency_scatter_5methods.pdf
â”‚   â”œâ”€â”€ asr_heatmap_5methods.pdf
â”‚   â”œâ”€â”€ asr_standard_vs_defended.pdf
â”‚   â””â”€â”€ asr_drop_analysis.pdf
â”œâ”€â”€ data/                # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ standard_models/  (15 JSON files)
â”‚   â””â”€â”€ defended_model/   (5 JSON files)
â””â”€â”€ reports/             # åˆ†ææŠ¥å‘Š
    â”œâ”€â”€ analysis_report_5methods.md
    â””â”€â”€ analysis_standard_vs_defended.md
```

### **å¯ç”¨äºè®ºæ–‡çš„å†…å®¹:**
- âœ… **6å¼ é«˜è´¨é‡å›¾è¡¨** (PDFæ ¼å¼ï¼Œå¯ç›´æ¥æ’å…¥LaTeX)
- âœ… **2ä¸ªLaTeXè¡¨æ ¼** (å¯ç›´æ¥å¤åˆ¶åˆ°è®ºæ–‡)
- âœ… **ç»Ÿè®¡åˆ†æç»“æœ** (å«Spearmanç›¸å…³ç³»æ•°ã€æ˜¾è‘—æ€§æ£€éªŒ)
- âœ… **å®Œæ•´å®éªŒæ•°æ®** (JSONæ ¼å¼ï¼Œå¯ç”¨äºè¡¥å……åˆ†æ)

---

## ğŸ’¡ 5. ç ”ç©¶è´¡çŒ®ç‚¹ï¼ˆåˆæ­¥æ€»ç»“ï¼‰

### **æŠ€æœ¯è´¡çŒ®ï¼š**
1. **ç³»ç»Ÿæ€§æ¯”è¾ƒ** 5ç§L0æ”»å‡»æ–¹æ³•çš„æ•ˆæœã€æ•ˆç‡ã€é²æ£’æ€§
2. **é˜²å¾¡è¯„ä¼°** é¦–æ¬¡ç³»ç»Ÿè¯„ä¼°L0æ”»å‡»å¯¹Lâˆé˜²å¾¡æ¨¡å‹çš„å¨èƒ
3. **å®è·µæŒ‡å¯¼** ä¸ºä¸åŒåº”ç”¨åœºæ™¯æ¨èæœ€é€‚åˆçš„æ”»å‡»æ–¹æ³•

### **å®éªŒè´¡çŒ®ï¼š**
1. **å¤§è§„æ¨¡æµ‹è¯•** 2,000ä¸ªå¯¹æŠ—æ ·æœ¬ï¼Œä¿è¯ç»Ÿè®¡å¯é æ€§
2. **å¤šç»´åº¦è¯„ä¼°** ASRã€L0ã€L2ã€SSIMã€æ—¶é—´ç­‰å¤šæŒ‡æ ‡
3. **ç»Ÿè®¡åˆ†æ** Spearmanç›¸å…³æ€§ã€æ’åä¸€è‡´æ€§æ£€éªŒ

### **æ½œåœ¨å‘è¡¨venue:**
- ä¼šè®®: ECCV Workshop, CVPR Workshop
- æœŸåˆŠ: Pattern Recognition Letters, Neural Networks
- å®‰å…¨ä¼šè®®: AISec (ACM CCS Workshop)

---

## ğŸ“… 6. Week 2 è®¡åˆ’

### **ä¸»è¦ä»»åŠ¡: è¡¥å……åˆ†æå’Œå¯è§†åŒ–**

#### **Day 6-7: å¤±è´¥æ¡ˆä¾‹åˆ†æ**
- å“ªäº›æ ·æœ¬éš¾ä»¥æ”»å‡»ï¼Ÿ
- å¤±è´¥çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆæ¢¯åº¦æ¶ˆå¤±ã€å¹³å¦åŒºåŸŸã€ç±»åˆ«æ··æ·†ï¼‰
- å¯è§†åŒ–å¤±è´¥æ¡ˆä¾‹çš„ç‰¹å¾

#### **Day 8-9: å¯¹æŠ—æ ·æœ¬å¯è§†åŒ–**
- æˆåŠŸæ¡ˆä¾‹å±•ç¤ºï¼ˆåŸå›¾vså¯¹æŠ—å›¾ï¼Œå·®å¼‚æ”¾å¤§ï¼‰
- ä¿®æ”¹åƒç´ ä½ç½®çƒ­å›¾
- ä¸åŒæ–¹æ³•çš„åƒç´ é€‰æ‹©æ¨¡å¼å¯¹æ¯”

#### **Day 10-11: æ·±å…¥åˆ†æ**
- æŸ¥è¯¢æ•ˆç‡åˆ†æï¼ˆæ¨¡å‹æŸ¥è¯¢æ¬¡æ•°vsæ”»å‡»æˆåŠŸç‡ï¼‰
- ä¸åŒç±»åˆ«çš„ASRï¼ˆå“ªäº›ç±»åˆ«å®¹æ˜“è¢«æ”»å‡»ï¼‰
- ç½®ä¿¡åº¦åˆ†æï¼ˆæ”»å‡»å‰åçš„é¢„æµ‹ç½®ä¿¡åº¦å˜åŒ–ï¼‰

### **å¯é€‰æ‰©å±•ï¼ˆå¦‚æœæ—¶é—´å……è¶³ï¼‰:**
- æµ‹è¯•æ›´å¤šé˜²å¾¡æ¨¡å‹ï¼ˆTRADESã€AWPç­‰ï¼‰
- å¢åŠ æ•°æ®é›†ï¼ˆCIFAR-100ã€ImageNetå­é›†ï¼‰
- å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆæœ€å¤§åƒç´ æ•°ã€æ‰°åŠ¨å¤§å°ï¼‰

---

## âœ… 7. æ£€æŸ¥æ¸…å•

### **å®éªŒæ•°æ®ï¼š**
- [x] 20ä¸ªJSONæ•°æ®æ–‡ä»¶å®Œæ•´
- [x] æ‰€æœ‰æ–‡ä»¶æ ¼å¼æ­£ç¡®
- [x] ç»Ÿè®¡ç»“æœä¸€è‡´

### **è®ºæ–‡ç´ æï¼š**
- [x] 6å¼ å›¾è¡¨ç”Ÿæˆï¼ˆPDF + PNGï¼‰
- [x] 2ä¸ªLaTeXè¡¨æ ¼
- [x] 2ä»½åˆ†ææŠ¥å‘Š
- [x] ç›®å½•ç»“æ„æ¸…æ™°

### **æ•°æ®è´¨é‡ï¼š**
- [x] æ¯ä¸ªé…ç½®100ä¸ªæ ·æœ¬
- [x] ç»“æœå¯é‡ç°ï¼ˆrandom_seed=42ï¼‰
- [x] ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

### **ä¸‹ä¸€æ­¥å‡†å¤‡ï¼š**
- [x] Week 1 æ€»ç»“å®Œæˆ
- [x] Week 2 è®¡åˆ’æ˜ç¡®
- [ ] é€‰æ‹©Week 2çš„åˆ†ææ–¹å‘

---

## ğŸ¯ 8. å½“å‰è¿›åº¦

```
æ€»ä½“è¿›åº¦: Week 1/4 å®Œæˆ (25%)

4å‘¨è®¡åˆ’:
â”œâ”€ Week 1: å®éªŒæ•°æ®é‡‡é›†       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% âœ…
â”œâ”€ Week 2: è¡¥å……åˆ†æ           [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   0%
â”œâ”€ Week 3: è®ºæ–‡æ’°å†™           [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   0%
â””â”€ Week 4: ç¿»è¯‘å’ŒæŠ•ç¨¿         [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   0%
```

---

## ğŸ’ª 9. ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### **ç«‹å³å¯åšï¼š**
1. âœ… é˜…è¯»ç”Ÿæˆçš„åˆ†ææŠ¥å‘Š
2. âœ… æŸ¥çœ‹å›¾è¡¨è´¨é‡
3. âœ… ç¡®è®¤æ•°æ®å®Œæ•´æ€§

### **æ˜å¤©å¼€å§‹Week 2æ—¶ï¼š**
1. ğŸ“Š å†³å®šè¡¥å……åˆ†æçš„ä¼˜å…ˆçº§
2. ğŸ¨ å¼€å§‹å¤±è´¥æ¡ˆä¾‹åˆ†æ
3. ğŸ“ˆ åˆ›å»ºæ›´å¤šå¯è§†åŒ–

### **æœ¬å‘¨ç›®æ ‡ï¼š**
- å®Œæˆæ‰€æœ‰è¡¥å……åˆ†æ
- å‡†å¤‡å¥½æ‰€æœ‰è®ºæ–‡ç´ æ
- ä¸ºWeek 3å†™ä½œåšå¥½å‡†å¤‡

---

## ğŸ‰ 10. æ€»ç»“

**Week 1 æˆæœ:**
- âœ… å®Œæˆ2,000ä¸ªå¯¹æŠ—æ ·æœ¬æµ‹è¯•
- âœ… å‘ç°4ä¸ªå…³é”®ç ”ç©¶å‘ç°
- âœ… ç”Ÿæˆå®Œæ•´è®ºæ–‡ç´ æåº“
- âœ… å»ºç«‹æ¸…æ™°çš„åç»­è®¡åˆ’

**æœ€å¤§æ”¶è·:**
1. å®éªŒè®¾è®¡åˆç†ï¼Œæ•°æ®è´¨é‡é«˜
2. ç»Ÿè®¡åˆ†æå®Œæ•´ï¼Œç»“è®ºå¯é 
3. ç´ æå‡†å¤‡å……åˆ†ï¼Œå¯ç›´æ¥ç”¨äºè®ºæ–‡
4. å‘ç°çš„ç°è±¡æœ‰ç ”ç©¶ä»·å€¼

**ç»§ç»­ä¿æŒ:**
- æ¯å¤©1-2å°æ—¶çš„ç¨³å®šæŠ•å…¥
- æ¸…æ™°çš„ä»»åŠ¡åˆ†è§£
- åŠæ—¶çš„æ•°æ®æ•´ç†
- çµæ´»çš„è®¡åˆ’è°ƒæ•´

---

**Week 1 åœ†æ»¡å®Œæˆï¼ç»§ç»­åŠ æ²¹ï¼** ğŸš€

**ä¸‹å‘¨è§ï¼** ğŸ‘‹

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.paper_materials_dir / 'reports' / 'Week1_æ€»ç»“æŠ¥å‘Š.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
            
        print(f"âœ… Week 1æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ä¹Ÿä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•æ–¹ä¾¿æŸ¥çœ‹
        root_report = self.project_root / 'Week1_æ€»ç»“æŠ¥å‘Š.md'
        shutil.copy2(report_file, root_report)
        print(f"âœ… å‰¯æœ¬å·²ä¿å­˜åˆ°: {root_report}")
        
        return report_file
        
    def run_all(self):
        """è¿è¡Œæ‰€æœ‰æ•´ç†ä»»åŠ¡"""
        print("\n" + "ğŸš€" + "="*58 + "ğŸš€")
        print("    Week 1 æ•°æ®æ•´ç†å’Œåˆ†æ - è‡ªåŠ¨åŒ–è„šæœ¬")
        print("ğŸš€" + "="*58 + "ğŸš€")
        
        try:
            # 1. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            self.check_data_integrity()
            
            # 2. åˆ›å»ºè®ºæ–‡ç´ æåº“
            self.create_paper_materials_structure()
            
            # 3. ç”Ÿæˆç»Ÿè®¡æ±‡æ€»
            summary = self.generate_statistics_summary()
            
            # 4. ç”ŸæˆWeek 1æ€»ç»“æŠ¥å‘Š
            report_file = self.generate_week1_report(summary)
            
            # æœ€ç»ˆæ€»ç»“
            print("\n" + "="*60)
            print("ğŸ‰ **å…¨éƒ¨å®Œæˆï¼Week 1 æ•°æ®æ•´ç†å®Œæˆï¼**")
            print("="*60)
            
            print("\nğŸ“¦ **ç”Ÿæˆçš„å†…å®¹:**")
            print(f"   âœ“ è®ºæ–‡ç´ æåº“: {self.paper_materials_dir}")
            print(f"   âœ“ ç»Ÿè®¡æ±‡æ€»: week1_summary_statistics.json")
            print(f"   âœ“ Week 1æŠ¥å‘Š: Week1_æ€»ç»“æŠ¥å‘Š.md")
            
            print("\nğŸ“Š **ä¸‹ä¸€æ­¥å»ºè®®:**")
            print("   1. é˜…è¯» Week1_æ€»ç»“æŠ¥å‘Š.md æŸ¥çœ‹å®Œæ•´æ€»ç»“")
            print("   2. æ£€æŸ¥ paper_materials/ ç›®å½•ä¸­çš„å›¾è¡¨")
            print("   3. æ€è€ƒ Week 2 çš„åˆ†ææ–¹å‘")
            print("   4. ä¼‘æ¯ä¸€ä¸‹ï¼Œæ˜å¤©ç»§ç»­ï¼")
            
            print("\nâœ¨ **Week 1 è¿›åº¦: 100% å®Œæˆï¼** âœ¨")
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False
            
        return True

def main():
    organizer = Week1DataOrganizer()
    success = organizer.run_all()
    
    if success:
        print("\n" + "ğŸŠ" * 30)
        print("æ­å–œï¼Day 5 ä»»åŠ¡å®Œæˆï¼")
        print("ğŸŠ" * 30)
        return 0
    else:
        return 1

if __name__ == '__main__':
    exit(main())















