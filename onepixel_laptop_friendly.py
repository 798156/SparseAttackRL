"""
One-Pixelæ”»å‡» - ç¬”è®°æœ¬å‹å¥½ç‰ˆ
æ¯ä¸ªæ¨¡å‹20æ ·æœ¬ï¼Œå‚æ•°é€‚ä¸­ï¼Œå¯åˆ†æ‰¹è¿è¡Œ
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
from pathlib import Path
import json
from tqdm import tqdm
import time
import sys

from one_pixel_attack import one_pixel_attack

def load_cifar10_data():
    """åŠ è½½CIFAR-10æµ‹è¯•æ•°æ®"""
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    return testset

def load_model(model_name, device):
    """åŠ è½½æŒ‡å®šæ¨¡å‹"""
    if model_name == 'ResNet18':
        model = torchvision.models.resnet18(weights=None)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, 10)
        model.load_state_dict(torch.load('cifar10_resnet18.pth', map_location=device, weights_only=False))
    
    elif model_name == 'VGG16':
        model = torchvision.models.vgg16(weights=None)
        num_ftrs = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(num_ftrs, 10)
        model.load_state_dict(torch.load('cifar10_vgg16.pth', map_location=device, weights_only=False))
    
    elif model_name == 'MobileNetV2':
        model = torchvision.models.mobilenet_v2(weights=None)
        num_ftrs = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(num_ftrs, 10)
        model.load_state_dict(torch.load('cifar10_mobilenetv2.pth', map_location=device, weights_only=False))
    
    model.to(device)
    model.eval()
    return model

def test_single_model(model_name, device, testset, num_samples=20):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹ï¼ˆç¬”è®°æœ¬å‹å¥½ç‰ˆï¼‰"""
    print(f"\n{'='*80}")
    print(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"{'='*80}")
    print(f"å‚æ•°: maxiter=50, popsize=150 (é€‚ä¸­é…ç½®)")
    print(f"æ ·æœ¬æ•°: {num_samples}")
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½{model_name}...")
    model = load_model(model_name, device)
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # é€‰æ‹©æ ·æœ¬
    print(f"\nğŸ“Š é€‰æ‹©{num_samples}ä¸ªæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬...")
    selected_samples = []
    for idx in range(len(testset)):
        if len(selected_samples) >= num_samples:
            break
        
        image, label = testset[idx]
        image_batch = image.unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
        
        if pred == label:
            selected_samples.append((idx, image, label))
    
    print(f"âœ… é€‰æ‹©äº† {len(selected_samples)} ä¸ªæ ·æœ¬")
    
    # é¢„è®¡æ—¶é—´
    estimated_time = len(selected_samples) * 150 / 60
    print(f"â° é¢„è®¡æ—¶é—´: {estimated_time:.0f}-{estimated_time*1.5:.0f}åˆ†é’Ÿ")
    print(f"ğŸ’¡ æ¸©é¦¨æç¤º: ç¡®ä¿ç¬”è®°æœ¬æ•£çƒ­è‰¯å¥½ï¼Œå¯éšæ—¶æŒ‰Ctrl+Cæš‚åœ\n")
    
    # æ”»å‡»æµ‹è¯•
    success_count = 0
    l0_values = []
    l2_values = []
    time_values = []
    results = []
    
    start_time_total = time.time()
    
    for i, (idx, image, label) in enumerate(tqdm(selected_samples, desc=f"{model_name}")):
        start_time = time.time()
        
        try:
            success, adv_image, modified_info = one_pixel_attack(
                image=image,
                label=label,
                model=model,
                max_iter=50,
                pop_size=150  # é€‚ä¸­çš„å‚æ•°ï¼Œå¹³è¡¡æ•ˆæœå’Œæ—¶é—´
            )
            
            attack_time = time.time() - start_time
            time_values.append(attack_time)
            
            if success:
                diff = (adv_image - image).abs()
                l0 = (diff.sum(dim=0) > 0).sum().item()
                l2 = torch.norm(diff).item()
                
                l0_values.append(l0)
                l2_values.append(l2)
                success_count += 1
                
                results.append({
                    'sample_id': int(idx),
                    'success': True,
                    'l0': float(l0),
                    'l2': float(l2),
                    'time': float(attack_time)
                })
                
                # æ¯5ä¸ªæˆåŠŸæ‰“å°ä¸€æ¬¡
                if success_count % 5 == 0:
                    current_asr = success_count / (i+1) * 100
                    avg_time_so_far = np.mean(time_values)
                    remaining_samples = len(selected_samples) - (i+1)
                    remaining_time = remaining_samples * avg_time_so_far / 60
                    print(f"  âœ… è¿›åº¦: {success_count}/{i+1}, ASR={current_asr:.1f}%, "
                          f"å‰©ä½™çº¦{remaining_time:.0f}åˆ†é’Ÿ")
            else:
                results.append({
                    'sample_id': int(idx),
                    'success': False,
                    'time': float(attack_time)
                })
        
        except KeyboardInterrupt:
            print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼å·²å®Œæˆ {i}/{len(selected_samples)} ä¸ªæ ·æœ¬")
            print(f"å½“å‰ASR: {success_count}/{i} = {success_count/max(i,1)*100:.1f}%")
            save_partial = input("æ˜¯å¦ä¿å­˜å½“å‰ç»“æœï¼Ÿ(y/n): ")
            if save_partial.lower() == 'y':
                break
            else:
                sys.exit(0)
    
    total_time = time.time() - start_time_total
    
    # ç»Ÿè®¡ç»“æœ
    completed_samples = len([r for r in results if 'success' in r])
    asr = success_count / completed_samples * 100 if completed_samples > 0 else 0
    avg_l0 = np.mean(l0_values) if l0_values else 0
    avg_l2 = np.mean(l2_values) if l2_values else 0
    avg_time = np.mean(time_values) if time_values else 0
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {model_name} æµ‹è¯•ç»“æœ")
    print(f"{'='*80}")
    print(f"  å®Œæˆæ ·æœ¬: {completed_samples}/{num_samples}")
    print(f"  ASR: {success_count}/{completed_samples} = {asr:.1f}%")
    print(f"  å¹³å‡L0: {avg_l0:.2f}")
    print(f"  å¹³å‡L2: {avg_l2:.4f}")
    print(f"  å¹³å‡æ—¶é—´: {avg_time:.1f}ç§’")
    print(f"  æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    print(f"{'='*80}\n")
    
    result_data = {
        'model': model_name,
        'parameters': {
            'max_iter': 50,
            'pop_size': 150,
            'seed': 'None'
        },
        'asr': float(asr),
        'success_count': success_count,
        'completed_samples': completed_samples,
        'target_samples': num_samples,
        'avg_l0': float(avg_l0),
        'avg_l2': float(avg_l2),
        'avg_time': float(avg_time),
        'total_time_minutes': float(total_time/60),
        'detailed_results': results
    }
    
    # ä¿å­˜ç»“æœ
    output_dir = Path('results/onepixel_laptop')
    output_dir.mkdir(exist_ok=True, parents=True)
    
    with open(output_dir / f'{model_name.lower()}_result.json', 'w') as f:
        json.dump(result_data, f, indent=2)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_dir / f'{model_name.lower()}_result.json'}\n")
    
    return result_data

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸ”¬ One-Pixelæ”»å‡» - ç¬”è®°æœ¬å‹å¥½ç‰ˆ")
    print("="*80)
    print("\nğŸ’¡ è®¾è®¡ç†å¿µ:")
    print("  âœ… æ¯ä¸ªæ¨¡å‹20æ ·æœ¬ï¼ˆç»Ÿè®¡è¶³å¤Ÿï¼‰")
    print("  âœ… å‚æ•°é€‚ä¸­ï¼ˆpopsize=150ï¼‰")
    print("  âœ… å¯åˆ†æ‰¹è¿è¡Œï¼ˆä¸€æ¬¡ä¸€ä¸ªæ¨¡å‹ï¼‰")
    print("  âœ… æ”¯æŒä¸­æ–­æ¢å¤")
    print("  âœ… é¢„è®¡1å°æ—¶/æ¨¡å‹\n")
    
    # é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹
    print("è¯·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹:")
    print("  1. ResNet18")
    print("  2. MobileNetV2")
    print("  3. VGG16 (è¡¥å……10ä¸ªæ ·æœ¬)")
    print("  4. å…¨éƒ¨æµ‹è¯•ï¼ˆåˆ†3æ‰¹ï¼‰")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-4): ").strip()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    testset = load_cifar10_data()
    
    if choice == '1':
        test_single_model('ResNet18', device, testset, num_samples=20)
    elif choice == '2':
        test_single_model('MobileNetV2', device, testset, num_samples=20)
    elif choice == '3':
        test_single_model('VGG16', device, testset, num_samples=10)
    elif choice == '4':
        print("\nâš ï¸  å»ºè®®åˆ†æ‰¹è¿è¡Œï¼Œæ¯æ‰¹ä¹‹é—´è®©ç¬”è®°æœ¬ä¼‘æ¯15åˆ†é’Ÿ")
        confirm = input("ç¡®è®¤å…¨éƒ¨è¿è¡Œï¼Ÿ(y/n): ")
        if confirm.lower() == 'y':
            test_single_model('ResNet18', device, testset, num_samples=20)
            print("\nğŸ’¤ å»ºè®®è®©ç¬”è®°æœ¬ä¼‘æ¯15åˆ†é’Ÿå†ç»§ç»­...")
            input("æŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å‹...")
            
            test_single_model('MobileNetV2', device, testset, num_samples=20)
            print("\nğŸ’¤ å»ºè®®è®©ç¬”è®°æœ¬ä¼‘æ¯15åˆ†é’Ÿå†ç»§ç»­...")
            input("æŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å‹...")
            
            test_single_model('VGG16', device, testset, num_samples=10)
    else:
        print("æ— æ•ˆé€‰é¡¹")
        return
    
    print(f"\n{'='*80}")
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}\n")

if __name__ == "__main__":
    main()







