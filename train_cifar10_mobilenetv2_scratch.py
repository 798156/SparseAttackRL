# train_cifar10_mobilenetv2_scratch.py
"""
ä»å¤´è®­ç»ƒCIFAR-10 MobileNetV2æ¨¡å‹ï¼ˆä¸ç”¨é¢„è®­ç»ƒæƒé‡ï¼‰
é’ˆå¯¹CIFAR-10çš„32x32å°å›¾åƒä¼˜åŒ–

é¢„è®¡æ—¶é—´ï¼šGPUçº¦1-2å°æ—¶
ç›®æ ‡å‡†ç¡®ç‡ï¼š85-90%
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader


def main():
    print("=" * 80)
    print("ğŸš€ ä»å¤´è®­ç»ƒCIFAR-10 MobileNetV2ï¼ˆä¸ç”¨é¢„è®­ç»ƒï¼‰")
    print("=" * 80)

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    if device == 'cpu':
        print("âš ï¸  è­¦å‘Šï¼šä½¿ç”¨CPUè®­ç»ƒä¼šéå¸¸æ…¢ï¼å»ºè®®ä½¿ç”¨GPU")
        response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
        if response.lower() != 'y':
            return

    # æ•°æ®å¢å¼ºï¼ˆé’ˆå¯¹å°å›¾åƒï¼‰
    print("\nğŸ“¦ åŠ è½½CIFAR-10æ•°æ®...")
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])

    num_workers = 0
    
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=num_workers)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=num_workers)

    # ä»å¤´åˆ›å»ºMobileNetV2ï¼ˆä¸ç”¨é¢„è®­ç»ƒæƒé‡ï¼‰
    print("\nğŸ”§ åˆ›å»ºMobileNetV2æ¨¡å‹ï¼ˆä»å¤´è®­ç»ƒï¼‰...")
    model = torchvision.models.mobilenet_v2(weights=None)  # ä¸ç”¨é¢„è®­ç»ƒæƒé‡
    
    # ä¿®æ”¹åˆ†ç±»å™¨
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)
    model = model.to(device)
    
    print(f"âœ… MobileNetV2åˆ›å»ºå®Œæˆï¼ˆéšæœºåˆå§‹åŒ–ï¼‰")
    print(f"   æ€»å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")

    # è®­ç»ƒè®¾ç½®
    criterion = nn.CrossEntropyLoss()
    
    # ä»å¤´è®­ç»ƒï¼Œæ‰€æœ‰å±‚ç”¨ç›¸åŒçš„å­¦ä¹ ç‡
    optimizer = torch.optim.SGD(
        model.parameters(),
        lr=0.1,  # ä»å¤´è®­ç»ƒç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡
        momentum=0.9,
        weight_decay=5e-4
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer, 
        milestones=[60, 120, 160],  # æ›´é•¿çš„è®­ç»ƒå‘¨æœŸ
        gamma=0.2
    )

    num_epochs = 200  # ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šepoch
    print(f"\nğŸ“ å¼€å§‹è®­ç»ƒï¼ˆ{num_epochs} epochsï¼‰...")
    print(f"é¢„è®¡æ—¶é—´: GPUçº¦1-2å°æ—¶")
    print(f"ç›®æ ‡å‡†ç¡®ç‡: 85-90%\n")

    best_acc = 0

    for epoch in range(num_epochs):
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, targets) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
        
        train_acc = 100. * correct / total
        
        # æµ‹è¯•
        model.eval()
        test_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for inputs, targets in testloader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                test_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
        
        test_acc = 100. * correct / total
        
        current_lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch+1:3d}/{num_epochs} | LR: {current_lr:.4f} | '
              f'Train: {train_acc:6.2f}% | Test: {test_acc:6.2f}%', end='')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_acc:
            print(f' ğŸ’¾ [æœ€ä½³]')
            best_acc = test_acc
            torch.save(model.state_dict(), 'cifar10_mobilenetv2.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'accuracy': test_acc,
            }, 'cifar10_mobilenetv2_best.pth')
        else:
            print()
        
        scheduler.step()

    print("\n" + "=" * 80)
    print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: cifar10_mobilenetv2.pth")
    print("=" * 80)


if __name__ == '__main__':
    main()








