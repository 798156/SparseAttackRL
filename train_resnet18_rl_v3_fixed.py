# train_resnet18_rl_v3_fixed.py
"""
ä¿®å¤ç‰ˆï¼šResNet18 RL V3è®­ç»ƒ
å…³é”®æ”¹è¿›ï¼š
1. å¢åŠ max_steps: 5 â†’ 10
2. é€‰æ‹©ç®€å•æ ·æœ¬ï¼ˆä½ç½®ä¿¡åº¦ï¼‰
3. å¢åŠ ç½®ä¿¡åº¦å¥–åŠ±æƒé‡
4. å»¶é•¿è®­ç»ƒæ—¶é—´
"""

import torch
import torchvision
from torchvision import transforms
from sparse_attack_env_v2 import SparseAttackEnvV2
import numpy as np
import os
import time

# ä¿®æ”¹ç¯å¢ƒï¼Œå¢åŠ å¥–åŠ±æƒé‡
class EnhancedSparseAttackEnvV2(SparseAttackEnvV2):
    """å¢å¼ºç‰ˆç¯å¢ƒï¼šæ›´å¼ºçš„å¥–åŠ±ä¿¡å·"""
    
    def __init__(self, clean_image, true_label, model, max_steps=10, 
                 use_saliency=True, confidence_reward_weight=15.0):
        # ä½¿ç”¨æ›´é«˜çš„ç½®ä¿¡åº¦å¥–åŠ±æƒé‡
        super().__init__(clean_image, true_label, model, max_steps, 
                        use_saliency, confidence_reward_weight)
        
        self.last_modified_pos = None
    
    def step(self, action):
        """å¢å¼ºç‰ˆstepï¼šæƒ©ç½šé‡å¤ä¿®æ”¹åŒä¸€ä½ç½®"""
        obs, reward, terminated, truncated, info = super().step(action)
        
        # è·å–ä¿®æ”¹ä½ç½®
        x, y = int(action[0]), int(action[1])
        current_pos = (x, y)
        
        # å¦‚æœè¿ç»­ä¿®æ”¹åŒä¸€ä½ç½®ï¼Œé¢å¤–æƒ©ç½š
        if self.last_modified_pos == current_pos and not (terminated or truncated):
            reward -= 0.5  # é¢å¤–æƒ©ç½š
        
        self.last_modified_pos = current_pos
        
        return obs, reward, terminated, truncated, info


def select_easy_samples(model, dataset, num_samples=100, device='cuda'):
    """é€‰æ‹©ç®€å•æ ·æœ¬ï¼ˆä½ç½®ä¿¡åº¦ï¼‰"""
    print(f"ğŸ“Š é€‰æ‹©{num_samples}ä¸ªç®€å•æ ·æœ¬ï¼ˆç½®ä¿¡åº¦<0.85ï¼‰...")
    
    sample_difficulties = []
    
    with torch.no_grad():
        for idx in range(min(len(dataset), num_samples * 5)):
            image, label = dataset[idx]
            image_batch = image.unsqueeze(0).to(device)
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                conf = torch.softmax(output, dim=1)[0, label].item()
                # åªé€‰æ‹©ç½®ä¿¡åº¦<0.85çš„æ ·æœ¬ï¼ˆæ›´å®¹æ˜“æ”»å‡»ï¼‰
                if conf < 0.85:
                    sample_difficulties.append((idx, conf))
            
            if len(sample_difficulties) >= num_samples:
                break
    
    # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå…ˆè®­ç»ƒç®€å•çš„
    sample_difficulties.sort(key=lambda x: x[1])
    selected = [idx for idx, _ in sample_difficulties[:num_samples]]
    
    if selected:
        avg_conf = np.mean([conf for _, conf in sample_difficulties[:num_samples]])
        print(f"âœ… é€‰æ‹©äº†{len(selected)}ä¸ªæ ·æœ¬ï¼Œå¹³å‡ç½®ä¿¡åº¦: {avg_conf:.3f}")
    else:
        print("âš ï¸  æ²¡æ‰¾åˆ°è¶³å¤Ÿçš„ç®€å•æ ·æœ¬ï¼Œä½¿ç”¨æ‰€æœ‰æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬")
        selected = []
        for idx in range(min(len(dataset), num_samples * 2)):
            image, label = dataset[idx]
            image_batch = image.unsqueeze(0).to(device)
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
            if pred == label:
                selected.append(idx)
            if len(selected) >= num_samples:
                break
    
    return selected


def main():
    print("=" * 80)
    print("ğŸ¯ ResNet18 RL V3 ä¿®å¤ç‰ˆè®­ç»ƒ")
    print("=" * 80)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½ResNet18æ¨¡å‹...")
    model = torchvision.models.resnet18(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, 10)
    model.load_state_dict(torch.load('cifar10_resnet18.pth', 
                                     map_location=device, 
                                     weights_only=False))
    model = model.to(device)
    model.eval()
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    
    dataset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    
    # é€‰æ‹©ç®€å•æ ·æœ¬
    easy_samples = select_easy_samples(model, dataset, num_samples=100, device=device)
    
    if len(easy_samples) < 50:
        print("âŒ ç®€å•æ ·æœ¬å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒ")
        return
    
    # è®­ç»ƒé…ç½®
    print("\n" + "=" * 80)
    print("ğŸ“ æ”¹è¿›çš„è®­ç»ƒé…ç½®")
    print("=" * 80)
    
    config = {
        'max_steps': 10,           # å¢åŠ ï¼5â†’10
        'timesteps': 80000,        # å¢åŠ ï¼50kâ†’80k
        'confidence_weight': 15.0, # å¢åŠ ï¼5â†’15
        'save_path': 'models/ppo_resnet18_v3_fixed'
    }
    
    print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(easy_samples)} (ç®€å•æ ·æœ¬)")
    print(f"  max_steps: {config['max_steps']} (åŸæ¥5)")
    print(f"  è®­ç»ƒæ­¥æ•°: {config['timesteps']:,} (åŸæ¥50k)")
    print(f"  ç½®ä¿¡åº¦å¥–åŠ±æƒé‡: {config['confidence_weight']} (åŸæ¥5.0)")
    print(f"\né¢„è®¡è®­ç»ƒæ—¶é—´: 1.5-2.5å°æ—¶ï¼ˆGPUï¼‰")
    
    response = input("\nå¼€å§‹è®­ç»ƒï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        return
    
    # ä½¿ç”¨æ”¹è¿›çš„è®­ç»ƒæ–¹æ³•
    from ppo_trainer_v3_improved import DynamicSampleEnv, train_rl_multi_sample
    from stable_baselines3.common.vec_env import DummyVecEnv
    from stable_baselines3 import PPO
    from ppo_trainer_v2 import CNNFeatureExtractor
    
    # åˆ›å»ºç¯å¢ƒåŒ…è£…å™¨ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆç¯å¢ƒï¼‰
    class EasyDynamicEnv:
        def __init__(self):
            self.easy_samples = easy_samples
            self.dataset = dataset
            self.model = model
            self.device = device
            self.max_steps = config['max_steps']
            self.current_env = None
            self._reset_with_new_sample()
            self.action_space = self.current_env.action_space
            self.observation_space = self.current_env.observation_space
        
        def _reset_with_new_sample(self):
            idx = np.random.choice(self.easy_samples)
            image, label = self.dataset[idx]
            self.current_env = EnhancedSparseAttackEnvV2(
                clean_image=image,
                true_label=label,
                model=self.model,
                max_steps=self.max_steps,
                use_saliency=True,
                confidence_reward_weight=config['confidence_weight']
            )
        
        def reset(self, **kwargs):
            self._reset_with_new_sample()
            obs, info = self.current_env.reset(**kwargs)
            return obs, info  # å¿…é¡»è¿”å›å…ƒç»„
        
        def step(self, action):
            return self.current_env.step(action)
    
    # å¯¼å…¥gymä»¥ç»§æ‰¿
    import gymnasium as gym
    
    # ä½¿gymèƒ½è¯†åˆ«
    class EasyDynamicEnvGym(gym.Env, EasyDynamicEnv):
        def __init__(self):
            gym.Env.__init__(self)
            EasyDynamicEnv.__init__(self)
    
    # åˆ›å»ºç¯å¢ƒ
    def make_env():
        return EasyDynamicEnvGym()
    
    env = DummyVecEnv([make_env])
    
    # åˆ›å»ºagent
    policy_kwargs = dict(
        features_extractor_class=CNNFeatureExtractor,
        features_extractor_kwargs=dict(features_dim=256),
        net_arch=[dict(pi=[128, 128], vf=[128, 128])]
    )
    
    agent = PPO(
        policy="CnnPolicy",
        env=env,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.01,
        vf_coef=0.5,
        max_grad_norm=0.5,
        policy_kwargs=policy_kwargs,
        verbose=1,
        tensorboard_log="./logs/",
        device=device
    )
    
    # è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()
    
    try:
        agent.learn(
            total_timesteps=config['timesteps'],
            tb_log_name="ppo_resnet18_v3_fixed",
            progress_bar=True
        )
        
        elapsed = time.time() - start_time
        
        # ä¿å­˜
        os.makedirs('models', exist_ok=True)
        agent.save(config['save_path'])
        
        print("\n" + "=" * 80)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"â±ï¸  è€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ")
        print(f"ğŸ“ ä¿å­˜: {config['save_path']}.zip")
        print("=" * 80)
        
        # å¿«é€ŸéªŒè¯
        print("\nğŸ§ª å¿«é€ŸéªŒè¯ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰...")
        successes = 0
        
        for i in range(10):
            idx = easy_samples[i]
            image, label = dataset[idx]
            
            env_test = EnhancedSparseAttackEnvV2(
                clean_image=image,
                true_label=label,
                model=model,
                max_steps=config['max_steps'],
                use_saliency=True
            )
            
            obs, _ = env_test.reset()
            done = False
            steps = 0
            
            while not done and steps < 15:
                action, _ = agent.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env_test.step(action)
                done = terminated or truncated
                steps += 1
            
            with torch.no_grad():
                output = model(env_test.current_image)
                pred = output.argmax(dim=1).item()
            
            if pred != label:
                successes += 1
                print(f"  æ ·æœ¬{i}: âœ… æˆåŠŸ")
            else:
                print(f"  æ ·æœ¬{i}: âŒ å¤±è´¥")
        
        asr = successes / 10 * 100
        print(f"\nASR: {asr:.0f}%")
        
        if asr >= 60:
            print("ğŸ‰ æˆåŠŸï¼ASRè¾¾æ ‡ï¼")
        else:
            print("âš ï¸  ASRä»ç„¶è¾ƒä½ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
            
    except KeyboardInterrupt:
        print("\nè®­ç»ƒä¸­æ–­")
        agent.save(config['save_path'] + '_interrupted')
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

