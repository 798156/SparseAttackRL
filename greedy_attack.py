"""
Greedy Gradient Attack
ç®€å•ä½†æœ‰æ•ˆçš„ç¨€ç–æ”»å‡»baselineæ–¹æ³•
æ¯æ¬¡é€‰æ‹©æ¢¯åº¦æœ€å¤§çš„åƒç´ è¿›è¡Œä¿®æ”¹
"""

import torch
import numpy as np

def greedy_attack(image, label, model, max_pixels=10, step_size=0.3):
    """
    è´ªå¿ƒæ¢¯åº¦æ”»å‡»
    
    åŸç†ï¼š
    1. è®¡ç®—æŸå¤±å…³äºè¾“å…¥çš„æ¢¯åº¦
    2. é€‰æ‹©æ¢¯åº¦ç»å¯¹å€¼æœ€å¤§çš„åƒç´ 
    3. æ²¿è´Ÿæ¢¯åº¦æ–¹å‘ä¿®æ”¹
    4. é‡å¤max_pixelsæ¬¡
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ (C, H, W)
        label: çœŸå®æ ‡ç­¾
        model: ç›®æ ‡æ¨¡å‹
        max_pixels: æœ€å¤§ä¿®æ”¹åƒç´ æ•°
        step_size: æ¯æ¬¡ä¿®æ”¹çš„æ­¥é•¿
    
    è¿”å›:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ åˆ—è¡¨
    """
    device = next(model.parameters()).device
    adv_image = image.clone().to(device)
    
    # å½’ä¸€åŒ–å‚æ•°
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)
    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)
    
    modified_pixels = []
    modified_mask = torch.zeros_like(adv_image, dtype=torch.bool)
    
    # é¦–å…ˆæ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        output = model(adv_image.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        if pred != label:
            return False, adv_image, []
    
    # è¿­ä»£ä¿®æ”¹åƒç´ 
    for step in range(max_pixels):
        # æ£€æŸ¥æ˜¯å¦å·²æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            if pred != label:
                return True, adv_image, modified_pixels
        
        # è®¡ç®—æ¢¯åº¦
        adv_image_batch = adv_image.unsqueeze(0).requires_grad_(True)
        output = model(adv_image_batch)
        
        # å¯¹æ­£ç¡®ç±»åˆ«è®¡ç®—æŸå¤±
        loss = output[0, label]
        
        model.zero_grad()
        loss.backward()
        grad = adv_image_batch.grad[0]
        
        # å±è”½å·²ä¿®æ”¹çš„åƒç´ 
        grad[modified_mask] = 0
        
        # æ‰¾åˆ°æ¢¯åº¦ç»å¯¹å€¼æœ€å¤§çš„åƒç´ 
        grad_abs = torch.abs(grad)
        max_idx = grad_abs.argmax().item()
        
        # è½¬æ¢ä¸ºåæ ‡
        C, H, W = adv_image.shape
        c = max_idx // (H * W)
        h = (max_idx % (H * W)) // W
        w = max_idx % W
        
        # ä¿®æ”¹åƒç´ 
        with torch.no_grad():
            # åå½’ä¸€åŒ–
            img_unnorm = adv_image * std + mean
            
            # æ²¿è´Ÿæ¢¯åº¦æ–¹å‘ï¼ˆé™ä½æ­£ç¡®ç±»åˆ«çš„æ¿€æ´»ï¼‰
            perturbation = -torch.sign(grad[c, h, w]) * step_size
            img_unnorm[c, h, w] += perturbation
            
            # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
            img_unnorm = torch.clamp(img_unnorm, 0, 1)
            
            # é‡æ–°å½’ä¸€åŒ–
            adv_image = (img_unnorm - mean) / std
        
        # è®°å½•ä¿®æ”¹çš„åƒç´ 
        modified_pixels.append((w, h, c))
        modified_mask[c, h, w] = True
    
    # æœ€ç»ˆæ£€æŸ¥
    with torch.no_grad():
        output = model(adv_image.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        success = (pred != label)
    
    return success, adv_image, modified_pixels


def greedy_attack_adaptive(image, label, model, max_pixels=10):
    """
    è‡ªé€‚åº”æ­¥é•¿çš„è´ªå¿ƒæ”»å‡»
    
    æ ¹æ®æ¢¯åº¦å¤§å°è‡ªåŠ¨è°ƒæ•´æ­¥é•¿
    """
    device = next(model.parameters()).device
    adv_image = image.clone().to(device)
    
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)
    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)
    
    modified_pixels = []
    modified_mask = torch.zeros_like(adv_image, dtype=torch.bool)
    
    # æ£€æŸ¥åˆå§‹é¢„æµ‹
    with torch.no_grad():
        output = model(adv_image.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        if pred != label:
            return False, adv_image, []
    
    for step in range(max_pixels):
        # æ£€æŸ¥æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            if pred != label:
                return True, adv_image, modified_pixels
        
        # è®¡ç®—æ¢¯åº¦
        adv_image_batch = adv_image.unsqueeze(0).requires_grad_(True)
        output = model(adv_image_batch)
        loss = output[0, label]
        
        model.zero_grad()
        loss.backward()
        grad = adv_image_batch.grad[0]
        
        # å±è”½å·²ä¿®æ”¹åƒç´ 
        grad[modified_mask] = 0
        
        # æ‰¾åˆ°æœ€å¤§æ¢¯åº¦
        grad_abs = torch.abs(grad)
        max_idx = grad_abs.argmax().item()
        
        C, H, W = adv_image.shape
        c = max_idx // (H * W)
        h = (max_idx % (H * W)) // W
        w = max_idx % W
        
        # è‡ªé€‚åº”æ­¥é•¿ï¼šæ¢¯åº¦è¶Šå¤§ï¼Œæ­¥é•¿è¶Šå¤§
        grad_magnitude = grad_abs[c, h, w].item()
        adaptive_step = min(0.5, 0.1 + grad_magnitude * 0.5)
        
        with torch.no_grad():
            img_unnorm = adv_image * std + mean
            perturbation = -torch.sign(grad[c, h, w]) * adaptive_step
            img_unnorm[c, h, w] += perturbation
            img_unnorm = torch.clamp(img_unnorm, 0, 1)
            adv_image = (img_unnorm - mean) / std
        
        modified_pixels.append((w, h, c))
        modified_mask[c, h, w] = True
    
    # æœ€ç»ˆæ£€æŸ¥
    with torch.no_grad():
        output = model(adv_image.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        success = (pred != label)
    
    return success, adv_image, modified_pixels


if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯• Greedy Gradient Attack")
    
    import torchvision
    import torchvision.transforms as transforms
    from torch import nn
    
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = torchvision.models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 10)
    model.load_state_dict(torch.load('cifar10_resnet18.pth', map_location=device, weights_only=False))
    model.to(device)
    model.eval()
    
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    
    # æµ‹è¯•å‡ ä¸ªæ ·æœ¬
    print("\næµ‹è¯•Greedy Attack:")
    successes = 0
    
    for i in range(10):
        image, label = testset[i]
        
        # æ£€æŸ¥åˆå§‹é¢„æµ‹
        with torch.no_grad():
            pred = model(image.unsqueeze(0).to(device)).argmax(dim=1).item()
        
        if pred == label:
            success, adv_img, pixels = greedy_attack(
                image, label, model, max_pixels=10, step_size=0.3
            )
            
            if success:
                successes += 1
                print(f"æ ·æœ¬ {i}: âœ… æˆåŠŸ | ä¿®æ”¹åƒç´ æ•°: {len(pixels)}")
            else:
                print(f"æ ·æœ¬ {i}: âŒ å¤±è´¥")
    
    print(f"\næˆåŠŸç‡: {successes}/10 = {successes/10*100:.1f}%")
    print("âœ… æµ‹è¯•å®Œæˆï¼")



