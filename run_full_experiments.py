# run_full_experiments.py
"""
å®Œæ•´å®éªŒçŸ©é˜µ
å®éªŒé…ç½®ï¼š
- æ•°æ®é›†ï¼šCIFAR-10, CIFAR-100, ImageNetï¼ˆå¯é€‰ï¼‰
- æ¨¡å‹ï¼šResNet18, VGG16, MobileNetV2, DenseNet121
- æ”»å‡»æ–¹æ³•ï¼šSparseAttackRL V2, JSMA, One-Pixel, SparseFool
- æ ·æœ¬æ•°ï¼š500/æ•°æ®é›†

è¿è¡Œæ–¹å¼ï¼š
python run_full_experiments.py --quick_test  # å¿«é€Ÿæµ‹è¯•ï¼ˆ100æ ·æœ¬ï¼Œ2æ¨¡å‹ï¼‰
python run_full_experiments.py --full        # å®Œæ•´å®éªŒï¼ˆ500æ ·æœ¬ï¼Œ4æ¨¡å‹ï¼‰
"""

import torch
import numpy as np
import os
import time
import argparse
import json
from tqdm import tqdm
from datetime import datetime

# è®¾ç½®matplotlibåç«¯ï¼ˆé¿å…Qté”™è¯¯ï¼‰
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨æ— GUIåç«¯
import matplotlib.pyplot as plt
import seaborn as sns

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from dataset_loader import DatasetLoader, get_all_datasets
from model_loader import ModelLoader, get_experiment_models
from sparse_attack_env_v2 import SparseAttackEnvV2
from ppo_trainer_v2 import train_rl_agent_v2
from one_pixel_attack import one_pixel_attack
from jsma_attack import jsma_attack
from sparsefool_attack import sparsefool_attack_simple
from evaluation_metrics import MetricsAggregator, compute_all_metrics
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from scipy import stats as scipy_stats
import pandas as pd


class FullExperimentRunner:
    """å®Œæ•´å®éªŒçŸ©é˜µè¿è¡Œå™¨"""
    
    def __init__(self, config):
        """
        å‚æ•°:
            config: å®éªŒé…ç½®å­—å…¸
        """
        self.config = config
        self.device = 'cuda' if torch.cuda.is_available() and config['use_gpu'] else 'cpu'
        
        # åˆ›å»ºç»“æœç›®å½•
        self.exp_dir = config['exp_dir']
        os.makedirs(self.exp_dir, exist_ok=True)
        os.makedirs(f"{self.exp_dir}/plots", exist_ok=True)
        os.makedirs(f"{self.exp_dir}/models", exist_ok=True)
        os.makedirs(f"{self.exp_dir}/logs", exist_ok=True)
        
        print("\n" + "=" * 80)
        print("ğŸ”¬ å®Œæ•´å®éªŒçŸ©é˜µåˆå§‹åŒ–")
        print("=" * 80)
        print(f"ğŸ“ å®éªŒç›®å½•: {self.exp_dir}")
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ“Š æ ·æœ¬æ•°/æ•°æ®é›†: {config['num_samples']}")
        print(f"ğŸ”„ æœ€å¤§ä¿®æ”¹æ­¥æ•°: {config['max_steps']}")
        
        # åŠ è½½æ•°æ®é›†
        self.datasets = self._load_datasets()
        
        # æ‰€æœ‰ç»“æœ
        self.all_results = {}
    
    def _load_datasets(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®é›†"""
        print("\nğŸ“¦ åŠ è½½æ•°æ®é›†...")
        
        datasets = {}
        dataset_names = self.config.get('datasets', ['cifar10'])
        
        for name in dataset_names:
            try:
                loader = DatasetLoader(name, self.config['data_root'])
                test_set = loader.load_test_set()
                
                if test_set is not None:
                    # é‡‡æ ·å­é›†
                    indices = loader.get_sample_subset(
                        test_set, 
                        num_samples=self.config['num_samples']
                    )
                    
                    datasets[name] = {
                        'loader': loader,
                        'test_set': test_set,
                        'indices': indices
                    }
                    print(f"  âœ… {name.upper()}: {len(indices)} æ ·æœ¬")
            except Exception as e:
                print(f"  âŒ {name} åŠ è½½å¤±è´¥: {e}")
        
        return datasets
    
    def train_agents(self):
        """ä¸ºæ¯ä¸ªæ•°æ®é›†è®­ç»ƒRLæ™ºèƒ½ä½“"""
        print("\n" + "=" * 80)
        print("ğŸ“ è®­ç»ƒ RL æ™ºèƒ½ä½“")
        print("=" * 80)
        
        agents = {}
        
        for dataset_name, dataset_info in self.datasets.items():
            print(f"\nğŸ”§ è®­ç»ƒ {dataset_name.upper()} çš„æ™ºèƒ½ä½“...")
            
            agent_path = f"{self.exp_dir}/models/agent_{dataset_name}.zip"
            
            if os.path.exists(agent_path) and not self.config.get('retrain', False):
                print(f"  âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œç›´æ¥åŠ è½½")
                try:
                    agents[dataset_name] = PPO.load(agent_path)
                    continue
                except:
                    print(f"  âš ï¸ åŠ è½½å¤±è´¥ï¼Œé‡æ–°è®­ç»ƒ")
            
            # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ
            test_set = dataset_info['test_set']
            indices = dataset_info['indices']
            image, label = test_set[indices[0]]
            
            # åˆ›å»ºç¯å¢ƒ
            loader = dataset_info['loader']
            model = ModelLoader.load_model(
                'resnet18',  # è®­ç»ƒæ—¶ç”¨ResNet18
                num_classes=loader.num_classes
            ).to(self.device)
            
            env = SparseAttackEnvV2(
                image, label, model,
                max_steps=self.config['max_steps'],
                use_saliency=True
            )
            
            # è®­ç»ƒ
            agent = train_rl_agent_v2(
                env,
                timesteps=self.config['train_timesteps'],
                save_path=agent_path.replace('.zip', ''),
                use_cnn=True
            )
            
            agents[dataset_name] = agent
        
        return agents
    
    def run_single_experiment(self, dataset_name, model_name, method_name, 
                             agent, model, test_set, indices, max_steps):
        """
        è¿è¡Œå•ä¸ªå®éªŒç»„åˆ
        
        è¿”å›:
            results: MetricsAggregator
        """
        results = MetricsAggregator()
        loader = self.datasets[dataset_name]['loader']
        
        for idx in tqdm(indices, desc=f"{dataset_name}|{model_name}|{method_name}", leave=False):
            image, label = test_set[idx]
            
            start_time = time.time()
            success = False
            l0_norm = 0
            
            try:
                if method_name == 'rl_v2':
                    # SparseAttackRL V2
                    env = SparseAttackEnvV2(image, label, model, max_steps=max_steps, use_saliency=True)
                    vec_env = DummyVecEnv([lambda: env])
                    obs = vec_env.reset()
                    
                    done = False
                    steps = 0
                    
                    while not done and steps < max_steps:
                        action, _ = agent.predict(obs)
                        result = vec_env.step(action)
                        
                        if len(result) == 4:
                            obs, _, done, info = result
                        else:
                            obs, _, terminated, truncated, info = result
                            done = terminated[0] or truncated[0]
                        
                        info = info[0] if isinstance(info, list) else info
                        steps += 1
                        
                        if info.get('success', False):
                            success = True
                            adv_img = env.current_image.squeeze(0)
                            break
                    
                    if success:
                        metrics = compute_all_metrics(image, adv_img)
                        l0_norm = metrics['l0_norm']
                
                elif method_name == 'jsma':
                    # JSMA Attack
                    # å¢å¤§thetaä»¥ç¡®ä¿ä¿®æ”¹è¶³å¤Ÿå¤§
                    success, adv_img, pixels = jsma_attack(
                        image, label, model, max_pixels=max_steps, theta=10.0
                    )
                    if success:
                        metrics = compute_all_metrics(image, adv_img)
                        l0_norm = metrics['l0_norm']
                
                elif method_name == 'one_pixel':
                    # One-Pixel Attack
                    success, params = one_pixel_attack(
                        image, label, model, max_iter=100
                    )
                    if success:
                        l0_norm = 1.0
                
                elif method_name == 'sparsefool':
                    # SparseFool Attack
                    success, adv_img, pixels = sparsefool_attack_simple(
                        image, label, model, max_pixels=max_steps
                    )
                    if success:
                        metrics = compute_all_metrics(image, adv_img)
                        l0_norm = metrics['l0_norm']
            
            except Exception as e:
                # print(f"  âš ï¸ Error [{idx}]: {e}")
                pass
            
            attack_time = time.time() - start_time
            
            # è®°å½•ç»“æœ
            results.add(
                success=success,
                attack_time=attack_time,
                query_count=max_steps if not success else (l0_norm if l0_norm > 0 else 1),
                l0_norm=l0_norm if success else 0,
                l2_norm=0,  # ç®€åŒ–
                linf_norm=0,
                ssim=0,
                psnr=0
            )
        
        return results
    
    def run_all_experiments(self, agents):
        """è¿è¡Œæ‰€æœ‰å®éªŒç»„åˆ"""
        print("\n" + "=" * 80)
        print("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´å®éªŒçŸ©é˜µ")
        print("=" * 80)
        
        # å®éªŒçŸ©é˜µ
        methods = ['rl_v2', 'jsma', 'one_pixel', 'sparsefool']
        
        # æ€»è¿›åº¦
        total_experiments = 0
        for dataset_name in self.datasets.keys():
            models = get_experiment_models(
                num_classes=self.datasets[dataset_name]['loader'].num_classes,
                quick_test=self.config.get('quick_test', False)
            )
            total_experiments += len(models) * len(methods)
        
        print(f"\nğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
        print(f"   æ•°æ®é›†: {len(self.datasets)}")
        print(f"   æ¨¡å‹/æ•°æ®é›†: {len(models)}")
        print(f"   æ–¹æ³•: {len(methods)}")
        print("=" * 80 + "\n")
        
        # è¿è¡Œå®éªŒ
        exp_count = 0
        
        for dataset_name, dataset_info in self.datasets.items():
            print(f"\n{'='*80}")
            print(f"ğŸ“¦ æ•°æ®é›†: {dataset_name.upper()}")
            print(f"{'='*80}")
            
            test_set = dataset_info['test_set']
            indices = dataset_info['indices']
            agent = agents.get(dataset_name)
            
            # åŠ è½½è¯¥æ•°æ®é›†çš„æ‰€æœ‰æ¨¡å‹
            num_classes = dataset_info['loader'].num_classes
            models = get_experiment_models(
                num_classes=num_classes,
                quick_test=self.config.get('quick_test', False)
            )
            
            for model_name, model in models.items():
                print(f"\nğŸ”§ æ¨¡å‹: {model_name.upper()}")
                model = model.to(self.device).eval()
                
                for method_name in methods:
                    exp_count += 1
                    print(f"  [{exp_count}/{total_experiments}] {method_name.upper()}...")
                    
                    # è¿è¡Œå®éªŒ
                    results = self.run_single_experiment(
                        dataset_name, model_name, method_name,
                        agent, model, test_set, indices,
                        self.config['max_steps']
                    )
                    
                    # ä¿å­˜ç»“æœ
                    key = f"{dataset_name}_{model_name}_{method_name}"
                    self.all_results[key] = {
                        'dataset': dataset_name,
                        'model': model_name,
                        'method': method_name,
                        'results': results,
                        'stats': results.compute_statistics()
                    }
                    
                    # æ˜¾ç¤ºç®€è¦ç»“æœ
                    stats = self.all_results[key]['stats']
                    asr = stats.get('success_rate', 0) * 100
                    l0 = stats.get('l0_norm_mean', 0)
                    print(f"      ASR: {asr:.1f}%, L0: {l0:.2f}")
        
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")
        print("=" * 80)
    
    def save_results(self):
        """ä¿å­˜æ‰€æœ‰ç»“æœ"""
        print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
        
        # 1. ä¿å­˜JSONæ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
        stats_dict = {}
        for key, value in self.all_results.items():
            stats_dict[key] = value['stats']
        
        with open(f"{self.exp_dir}/all_stats.json", 'w') as f:
            json.dump(stats_dict, f, indent=2, default=str)
        print(f"  âœ… ç»Ÿè®¡ä¿¡æ¯: {self.exp_dir}/all_stats.json")
        
        # 2. ä¿å­˜CSVæ ¼å¼çš„è¯¦ç»†æ•°æ®
        for key, value in self.all_results.items():
            csv_path = f"{self.exp_dir}/logs/{key}_metrics.csv"
            value['results'].save_to_csv(csv_path)
        print(f"  âœ… è¯¦ç»†æ•°æ®: {self.exp_dir}/logs/")
        
        # 3. ç”Ÿæˆç»¼åˆè¡¨æ ¼
        self._generate_summary_table()
    
    def _generate_summary_table(self):
        """ç”Ÿæˆç»¼åˆç»“æœè¡¨æ ¼"""
        print("\nğŸ“Š ç”Ÿæˆç»¼åˆè¡¨æ ¼...")
        
        # åˆ›å»ºDataFrame
        rows = []
        for key, value in self.all_results.items():
            stats = value['stats']
            rows.append({
                'Dataset': value['dataset'],
                'Model': value['model'],
                'Method': value['method'],
                'ASR (%)': stats.get('success_rate', 0) * 100,
                'Avg L0': stats.get('l0_norm_mean', 0),
                'Avg Time (s)': stats.get('attack_time_mean', 0),
            })
        
        df = pd.DataFrame(rows)
        
        # ä¿å­˜ä¸ºCSV
        csv_path = f"{self.exp_dir}/summary_table.csv"
        df.to_csv(csv_path, index=False)
        print(f"  âœ… ç»¼åˆè¡¨æ ¼: {csv_path}")
        
        # æ‰“å°è¡¨æ ¼
        print("\n" + "=" * 100)
        print("ğŸ“Š ç»¼åˆå®éªŒç»“æœ")
        print("=" * 100)
        print(df.to_string(index=False))
        print("=" * 100)
    
    def generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        sns.set(style="whitegrid", font_scale=1.2)
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆå›¾è¡¨
        for dataset_name in self.datasets.keys():
            self._generate_dataset_plots(dataset_name)
        
        # ç”Ÿæˆè·¨æ•°æ®é›†å¯¹æ¯”
        self._generate_cross_dataset_plots()
        
        print(f"  âœ… å›¾è¡¨ä¿å­˜è‡³: {self.exp_dir}/plots/")
    
    def _generate_dataset_plots(self, dataset_name):
        """ä¸ºå•ä¸ªæ•°æ®é›†ç”Ÿæˆå›¾è¡¨"""
        # æå–è¯¥æ•°æ®é›†çš„æ‰€æœ‰ç»“æœ
        dataset_results = {k: v for k, v in self.all_results.items() 
                          if v['dataset'] == dataset_name}
        
        if not dataset_results:
            return
        
        # æŒ‰æ–¹æ³•èšåˆï¼ˆå¹³å‡æ‰€æœ‰æ¨¡å‹ï¼‰
        methods = {}
        for key, value in dataset_results.items():
            method = value['method']
            if method not in methods:
                methods[method] = []
            methods[method].append(value['stats'].get('success_rate', 0) * 100)
        
        # è®¡ç®—å¹³å‡ASR
        method_names = []
        asrs = []
        for method, asr_list in methods.items():
            method_names.append(method.upper())
            asrs.append(np.mean(asr_list))
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        plt.figure(figsize=(10, 6))
        colors = ['#e74c3c', '#f39c12', '#2ecc71', '#3498db']
        bars = plt.bar(method_names, asrs, color=colors[:len(method_names)], alpha=0.8)
        plt.ylabel('Attack Success Rate (%)', fontsize=14)
        plt.title(f'ASR Comparison on {dataset_name.upper()}', fontsize=16, weight='bold')
        plt.ylim(0, 105)
        
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 1.5,
                    f'{height:.1f}%', ha='center', va='bottom', fontsize=12)
        
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        plt.savefig(f"{self.exp_dir}/plots/asr_{dataset_name}.png", dpi=300, bbox_inches='tight')
        plt.savefig(f"{self.exp_dir}/plots/asr_{dataset_name}.pdf", bbox_inches='tight')
        plt.close()
    
    def _generate_cross_dataset_plots(self):
        """ç”Ÿæˆè·¨æ•°æ®é›†å¯¹æ¯”å›¾"""
        # è¿™é‡Œå¯ä»¥ç”Ÿæˆæ›´å¤æ‚çš„å¯¹æ¯”å›¾
        pass


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å®Œæ•´å®éªŒçŸ©é˜µ')
    parser.add_argument('--quick_test', action='store_true', 
                       help='å¿«é€Ÿæµ‹è¯•ï¼ˆ100æ ·æœ¬ï¼Œ2æ¨¡å‹ï¼‰')
    parser.add_argument('--full', action='store_true',
                       help='å®Œæ•´å®éªŒï¼ˆ500æ ·æœ¬ï¼Œ4æ¨¡å‹ï¼‰')
    parser.add_argument('--datasets', nargs='+', default=['cifar10'],
                       help='æ•°æ®é›†åˆ—è¡¨ (cifar10, cifar100, imagenet)')
    parser.add_argument('--num_samples', type=int, default=None,
                       help='æ ·æœ¬æ•°ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰')
    parser.add_argument('--max_steps', type=int, default=5,
                       help='æœ€å¤§ä¿®æ”¹æ­¥æ•°')
    parser.add_argument('--exp_dir', type=str, default='results/full_experiments',
                       help='å®éªŒç»“æœç›®å½•')
    parser.add_argument('--no_gpu', action='store_true',
                       help='ä¸ä½¿ç”¨GPU')
    parser.add_argument('--retrain', action='store_true',
                       help='é‡æ–°è®­ç»ƒRLæ™ºèƒ½ä½“')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # æ„å»ºé…ç½®
    config = {
        'data_root': './data',
        'exp_dir': args.exp_dir,
        'max_steps': args.max_steps,
        'use_gpu': not args.no_gpu,
        'retrain': args.retrain,
        'quick_test': args.quick_test,
        'datasets': args.datasets if not args.quick_test else ['cifar10'],
        'train_timesteps': 5000 if args.quick_test else 10000,
    }
    
    # æ ·æœ¬æ•°
    if args.num_samples:
        config['num_samples'] = args.num_samples
    elif args.quick_test:
        config['num_samples'] = 100
    elif args.full:
        config['num_samples'] = 500
    else:
        config['num_samples'] = 100  # é»˜è®¤
    
    # åˆ›å»ºå®éªŒè¿è¡Œå™¨
    runner = FullExperimentRunner(config)
    
    # 1. è®­ç»ƒRLæ™ºèƒ½ä½“
    agents = runner.train_agents()
    
    # 2. è¿è¡Œæ‰€æœ‰å®éªŒ
    runner.run_all_experiments(agents)
    
    # 3. ä¿å­˜ç»“æœ
    runner.save_results()
    
    # 4. ç”Ÿæˆå¯è§†åŒ–
    runner.generate_visualizations()
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {config['exp_dir']}/")
    print("=" * 80)


if __name__ == "__main__":
    main()

