# debug_jsma_saliency.py
"""è°ƒè¯•JSMAæ˜¾è‘—æ€§å›¾"""

import torch
from torchvision import datasets, transforms
from target_model import load_target_model
from jsma_attack import compute_jacobian, compute_saliency_map

print("=" * 70)
print("ğŸ” è°ƒè¯•JSMAæ˜¾è‘—æ€§å›¾")
print("=" * 70)

# åŠ è½½æ•°æ®
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])
test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

# åŠ è½½æ¨¡å‹
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = load_target_model().to(device).eval()

# æµ‹è¯•ä¸€ä¸ªæ ·æœ¬
image, label = test_set[0]
image = image.to(device).unsqueeze(0)

print(f"\nğŸ“Š æ ·æœ¬ä¿¡æ¯:")
print(f"  Label: {label}")

# åˆå§‹é¢„æµ‹
with torch.no_grad():
    output = model(image)
    pred = output.argmax(dim=1).item()
    probs = torch.softmax(output, dim=1)[0]
    print(f"  åˆå§‹é¢„æµ‹: {pred}, ç½®ä¿¡åº¦: {probs[pred]:.4f}")

# å¦‚æœé¢„æµ‹æ­£ç¡®ï¼Œé€‰æ‹©ç¬¬äºŒé«˜çš„ç±»åˆ«ä½œä¸ºç›®æ ‡
if pred == label:
    sorted_preds = output.argsort(dim=1, descending=True)[0]
    target_class = sorted_preds[1].item()
    print(f"  ç›®æ ‡ç±»åˆ«: {target_class}, ç½®ä¿¡åº¦: {probs[target_class]:.4f}")
else:
    target_class = pred
    print(f"  é¢„æµ‹å·²é”™ï¼Œç›®æ ‡ç±»åˆ«: {target_class}")

# è®¡ç®—é›…å¯æ¯”çŸ©é˜µ
image.requires_grad = True
output = model(image)
jacobian = compute_jacobian(model, image, output)

print(f"\nğŸ“ˆ é›…å¯æ¯”çŸ©é˜µ:")
print(f"  å½¢çŠ¶: {jacobian.shape}")
print(f"  ç›®æ ‡ç±»åˆ«æ¢¯åº¦èŒƒå›´: [{jacobian[0, target_class].min():.4f}, {jacobian[0, target_class].max():.4f}]")
print(f"  æºç±»åˆ«æ¢¯åº¦èŒƒå›´: [{jacobian[0, label].min():.4f}, {jacobian[0, label].max():.4f}]")

# è®¡ç®—æ˜¾è‘—æ€§å›¾
mask = torch.ones((3, 32, 32), dtype=torch.bool, device=device)
saliency_map = compute_saliency_map(jacobian, label, target_class, mask, increase=True)

print(f"\nğŸ¯ æ˜¾è‘—æ€§å›¾:")
print(f"  å½¢çŠ¶: {saliency_map.shape}")
print(f"  æœ€å¤§å€¼: {saliency_map.max().item():.6f}")
print(f"  éé›¶å…ƒç´ æ•°: {(saliency_map > 0).sum().item()}")
print(f"  éé›¶å…ƒç´ æ¯”ä¾‹: {100*(saliency_map > 0).sum().item() / saliency_map.numel():.2f}%")

if saliency_map.max() == 0:
    print(f"\nâŒ é—®é¢˜ï¼šæ˜¾è‘—æ€§å›¾å…¨ä¸º0ï¼")
    print(f"   å¯èƒ½åŸå› ï¼šæ‰¾ä¸åˆ°åŒæ—¶æ»¡è¶³æ¡ä»¶çš„åƒç´ ")
    print(f"   (grad_target > 0 ä¸” grad_source < 0)")
    
    # æ£€æŸ¥æ¯ä¸ªæ¡ä»¶
    grad_target = jacobian[0, target_class]
    grad_source = jacobian[0, label]
    
    target_pos = (grad_target > 0).sum().item()
    source_neg = (grad_source < 0).sum().item()
    both = ((grad_target > 0) & (grad_source < 0)).sum().item()
    
    print(f"\n  ç»Ÿè®¡:")
    print(f"    grad_target > 0: {target_pos} åƒç´  ({100*target_pos/grad_target.numel():.1f}%)")
    print(f"    grad_source < 0: {source_neg} åƒç´  ({100*source_neg/grad_source.numel():.1f}%)")
    print(f"    ä¸¤è€…åŒæ—¶æ»¡è¶³: {both} åƒç´  ({100*both/grad_target.numel():.1f}%)")
    
    if both == 0:
        print(f"\n  âš ï¸  æ²¡æœ‰åƒç´ åŒæ—¶æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼")
        print(f"     è¿™å¯èƒ½æ˜¯JSMAå¤±è´¥çš„åŸå› ")
        print(f"     è§£å†³æ–¹æ¡ˆï¼šæ”¾å®½æ¡ä»¶æˆ–ä½¿ç”¨å…¶ä»–ç­–ç•¥")
else:
    print(f"\nâœ… æ‰¾åˆ°æœ‰æ•ˆæ˜¾è‘—æ€§åƒç´ ")
    
    # æ‰¾åˆ°æœ€å¤§å€¼ä½ç½®
    flat_idx = saliency_map.argmax().item()
    C, H, W = 3, 32, 32
    c = flat_idx // (H * W)
    h = (flat_idx % (H * W)) // W
    w = flat_idx % W
    
    print(f"  æœ€å¤§æ˜¾è‘—æ€§ä½ç½®: é€šé“={c}, è¡Œ={h}, åˆ—={w}")
    print(f"  æ˜¾è‘—æ€§å€¼: {saliency_map[flat_idx].item():.6f}")
    print(f"  ç›®æ ‡ç±»åˆ«æ¢¯åº¦: {jacobian[0, target_class, c, h, w].item():.6f}")
    print(f"  æºç±»åˆ«æ¢¯åº¦: {jacobian[0, label, c, h, w].item():.6f}")

print("\n" + "=" * 70)

