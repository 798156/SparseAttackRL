# sparsefool_attack.py
"""
SparseFoolæ”»å‡»å®ç°
å‚è€ƒï¼šModas et al., "SparseFool: a few pixels make a big difference", CVPR 2019

æ ¸å¿ƒæ€æƒ³ï¼šè¿­ä»£åœ°æ‰¾åˆ°æœ€å°L0æ‰°åŠ¨ï¼Œæ¯æ¬¡ä¿®æ”¹å¯¹å†³ç­–è¾¹ç•Œå½±å“æœ€å¤§çš„åƒç´ 
"""

import torch
import numpy as np


def sparsefool_attack(image, label, model, max_iterations=100, lambda_=3.0, overshoot=0.02):
    """
    SparseFoolæ”»å‡»
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ (C, H, W)
        label: çœŸå®æ ‡ç­¾
        model: ç›®æ ‡æ¨¡å‹
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        lambda_: L0æ­£åˆ™åŒ–å‚æ•°ï¼ˆæ§åˆ¶ç¨€ç–æ€§ï¼‰
        overshoot: è¿‡å†²å‚æ•°
    
    è¿”å›:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ åˆ—è¡¨
    """
    device = next(model.parameters()).device
    adv_image = image.clone().to(device).unsqueeze(0)
    
    # è®°å½•ä¿®æ”¹çš„åƒç´ 
    modified_pixels = []
    
    # å½’ä¸€åŒ–å‚æ•°
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(1, 3, 1, 1).to(device)
    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(1, 3, 1, 1).to(device)
    
    # é¦–å…ˆæ£€æŸ¥åˆå§‹é¢„æµ‹æ˜¯å¦æ­£ç¡®
    with torch.no_grad():
        initial_output = model(adv_image)
        initial_pred = initial_output.argmax(dim=1).item()
        
        # å¦‚æœåˆå§‹é¢„æµ‹å°±é”™äº†ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
        if initial_pred != label:
            return False, adv_image.squeeze(0), []
    
    for iteration in range(max_iterations):
        adv_image.requires_grad = True
        
        # å‰å‘ä¼ æ’­
        output = model(adv_image)
        pred = output.argmax(dim=1).item()
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if pred != label:
            return True, adv_image.squeeze(0).detach(), modified_pixels
        
        # è®¡ç®—æ¢¯åº¦
        model.zero_grad()
        output[0, label].backward()
        grad = adv_image.grad.data
        
        # é€‰æ‹©æ¢¯åº¦æœ€å¤§çš„åƒç´ ï¼ˆå¯¹å†³ç­–è¾¹ç•Œå½±å“æœ€å¤§ï¼‰
        grad_abs = torch.abs(grad[0])
        
        # å±•å¹³å¹¶æ‰¾åˆ°æœ€å¤§æ¢¯åº¦ä½ç½®
        grad_flat = grad_abs.view(-1)
        max_idx = grad_flat.argmax().item()
        
        # è½¬æ¢ä¸ºåæ ‡
        C, H, W = adv_image.shape[1:]
        c = max_idx // (H * W)
        h = (max_idx % (H * W)) // W
        w = max_idx % W
        
        # è®¡ç®—æ‰°åŠ¨æ–¹å‘å’Œå¤§å°
        # ç®€åŒ–ç‰ˆï¼šæ²¿è´Ÿæ¢¯åº¦æ–¹å‘ç§»åŠ¨
        perturbation_direction = -torch.sign(grad[0, c, h, w])
        
        # åº”ç”¨æ‰°åŠ¨
        with torch.no_grad():
            # åå½’ä¸€åŒ–
            img_unnorm = adv_image * std + mean
            
            # æ·»åŠ æ‰°åŠ¨ï¼ˆå°æ­¥é•¿ï¼‰
            step_size = 0.1 * (1 + overshoot)
            img_unnorm[0, c, h, w] += perturbation_direction * step_size
            
            # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
            img_unnorm = torch.clamp(img_unnorm, 0, 1)
            
            # é‡æ–°å½’ä¸€åŒ–
            adv_image = (img_unnorm - mean) / std
            adv_image = adv_image.detach()
        
        # è®°å½•ä¿®æ”¹çš„åƒç´ 
        if (w, h, c) not in modified_pixels:
            modified_pixels.append((w, h, c))
    
    # æœ€åæ£€æŸ¥
    with torch.no_grad():
        output = model(adv_image)
        pred = output.argmax(dim=1).item()
        success = (pred != label)
    
    return success, adv_image.squeeze(0).detach(), modified_pixels


def sparsefool_attack_simple(image, label, model, max_pixels=5):
    """
    ç®€åŒ–ç‰ˆSparseFoolï¼Œé™åˆ¶æœ€å¤§ä¿®æ”¹åƒç´ æ•°
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ (C, H, W)
        label: çœŸå®æ ‡ç­¾
        model: ç›®æ ‡æ¨¡å‹
        max_pixels: æœ€å¤§ä¿®æ”¹åƒç´ æ•°
    
    è¿”å›:
        success: æ˜¯å¦æˆåŠŸ
        adv_image: å¯¹æŠ—æ ·æœ¬
        modified_pixels: ä¿®æ”¹çš„åƒç´ ä½ç½®åˆ—è¡¨ [(x, y), ...]
    """
    device = next(model.parameters()).device
    adv_image = image.clone().to(device)
    
    # å½’ä¸€åŒ–å‚æ•°
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)
    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)
    
    modified_pixels = []
    modified_mask = torch.zeros_like(adv_image, dtype=torch.bool)
    
    # é¦–å…ˆæ£€æŸ¥åˆå§‹é¢„æµ‹æ˜¯å¦æ­£ç¡®
    with torch.no_grad():
        initial_output = model(adv_image.unsqueeze(0))
        initial_pred = initial_output.argmax(dim=1).item()
        
        # å¦‚æœåˆå§‹é¢„æµ‹å°±é”™äº†ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
        if initial_pred != label:
            return False, adv_image, []
    
    for step in range(max_pixels):
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        with torch.no_grad():
            output = model(adv_image.unsqueeze(0))
            pred = output.argmax(dim=1).item()
            
            if pred != label:
                return True, adv_image, modified_pixels
        
        # è®¡ç®—æ¢¯åº¦
        adv_image_batch = adv_image.unsqueeze(0).requires_grad_(True)
        output = model(adv_image_batch)
        
        model.zero_grad()
        output[0, label].backward()
        grad = adv_image_batch.grad[0]
        
        # å±è”½å·²ä¿®æ”¹çš„åƒç´ 
        grad[modified_mask] = 0
        
        # æ‰¾åˆ°æ¢¯åº¦ç»å¯¹å€¼æœ€å¤§çš„åƒç´ 
        grad_abs = torch.abs(grad)
        max_idx = grad_abs.argmax().item()
        
        # è½¬æ¢ä¸ºåæ ‡
        C, H, W = adv_image.shape
        c = max_idx // (H * W)
        h = (max_idx % (H * W)) // W
        w = max_idx % W
        
        # åº”ç”¨æ‰°åŠ¨
        with torch.no_grad():
            # åå½’ä¸€åŒ–
            img_unnorm = adv_image * std + mean
            
            # æ²¿è´Ÿæ¢¯åº¦æ–¹å‘æ‰°åŠ¨ï¼ˆé™ä½æ­£ç¡®ç±»åˆ«çš„æ¿€æ´»ï¼‰
            # å¢å¤§æ‰°åŠ¨å¹…åº¦ä»¥ç¡®ä¿è¶³å¤Ÿçš„å½±å“
            perturbation = -torch.sign(grad[c, h, w]) * 0.8
            img_unnorm[c, h, w] += perturbation
            
            # è£å‰ª
            img_unnorm = torch.clamp(img_unnorm, 0, 1)
            
            # é‡æ–°å½’ä¸€åŒ–
            adv_image = (img_unnorm - mean) / std
        
        # è®°å½•
        modified_pixels.append((w, h))
        modified_mask[c, h, w] = True
    
    # æœ€ç»ˆæ£€æŸ¥
    with torch.no_grad():
        output = model(adv_image.unsqueeze(0))
        pred = output.argmax(dim=1).item()
        success = (pred != label)
    
    return success, adv_image, modified_pixels


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯• SparseFool Attack")
    
    from torchvision import datasets, transforms
    from target_model import load_target_model
    
    # åŠ è½½æ•°æ®å’Œæ¨¡å‹
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    model = load_target_model('resnet18', num_classes=10)
    
    # æµ‹è¯•å‡ ä¸ªæ ·æœ¬
    print("\næµ‹è¯• SparseFool Attack:")
    successes = 0
    
    for i in range(5):
        image, label = test_set[i]
        
        success, adv_img, pixels = sparsefool_attack_simple(
            image, label, model, max_pixels=5
        )
        
        if success:
            successes += 1
            print(f"æ ·æœ¬ {i}: âœ… æˆåŠŸ | ä¿®æ”¹åƒç´ æ•°: {len(pixels)}")
        else:
            print(f"æ ·æœ¬ {i}: âŒ å¤±è´¥")
    
    print(f"\næˆåŠŸç‡: {successes}/5 = {successes/5*100:.1f}%")
    print("âœ… æµ‹è¯•å®Œæˆï¼")

