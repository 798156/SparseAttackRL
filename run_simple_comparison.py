# run_simple_comparison.py
"""
ç®€åŒ–çš„å¯¹æ¯”å®éªŒè„šæœ¬
åªå¯¹æ¯”æ ¸å¿ƒæ–¹æ³•ï¼šV2 (Ours), JSMA, One-Pixel
é¿å…äº†Hybridçš„çŠ¶æ€ç©ºé—´åŒ¹é…é—®é¢˜
"""

import torch
import numpy as np
import os
from torchvision import datasets, transforms

# è®¾ç½®matplotlibåç«¯ï¼ˆé¿å…Qté”™è¯¯ï¼‰
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns

from target_model import load_target_model
from sparse_attack_env_v2 import SparseAttackEnvV2
from ppo_trainer_v2 import train_rl_agent_v2
from one_pixel_attack import one_pixel_attack
from jsma_attack import jsma_attack
from evaluation_metrics import MetricsAggregator, compute_all_metrics
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from tqdm import tqdm
import time
from scipy import stats as scipy_stats

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

# åŠ è½½æ•°æ®é›†
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])
test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

# åŠ è½½æ¨¡å‹
print("ğŸ”§ åŠ è½½ç›®æ ‡æ¨¡å‹...")
model = load_target_model('resnet18', num_classes=10)
model = model.eval().to(device)


def train_v2_agent():
    """è®­ç»ƒV2æ™ºèƒ½ä½“"""
    print("\n" + "=" * 60)
    print("ğŸ“ è®­ç»ƒ V2 æ™ºèƒ½ä½“")
    print("=" * 60)
    
    image, label = test_set[0]
    env_v2 = SparseAttackEnvV2(image, label, model, max_steps=5, use_saliency=True)
    
    if not os.path.exists("ppo_sparse_v2.zip"):
        agent_v2 = train_rl_agent_v2(env_v2, timesteps=10000, save_path="ppo_sparse_v2", use_cnn=True)
    else:
        print("  âœ… V2æ¨¡å‹å·²å­˜åœ¨ï¼Œç›´æ¥åŠ è½½")
        agent_v2 = PPO.load("ppo_sparse_v2")
    
    return agent_v2


def run_comparison(agent_v2, num_samples=100, max_steps=5):
    """è¿è¡Œç®€åŒ–çš„å¯¹æ¯”å®éªŒ"""
    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹å¯¹æ¯”å®éªŒ")
    print(f"   æ ·æœ¬æ•°é‡: {num_samples}")
    print(f"   æœ€å¤§æ­¥æ•°: {max_steps}")
    print(f"   å¯¹æ¯”æ–¹æ³•: V2 (Ours), JSMA, One-Pixel")
    print("=" * 60)
    
    results = {
        'rl_v2': MetricsAggregator(),
        'jsma': MetricsAggregator(),
        'one_pixel': MetricsAggregator()
    }
    
    pbar = tqdm(total=num_samples, desc="ğŸ“Š å®éªŒè¿›åº¦")
    
    for i in range(num_samples):
        image, label = test_set[i]
        
        # === V2 ===
        start_time = time.time()
        try:
            env_v2 = SparseAttackEnvV2(image, label, model, max_steps=max_steps, use_saliency=True)
            vec_env = DummyVecEnv([lambda: env_v2])
            obs = vec_env.reset()
            
            done = False
            steps = 0
            success_v2 = False
            
            while not done and steps < max_steps:
                action, _ = agent_v2.predict(obs)
                result = vec_env.step(action)
                
                if len(result) == 4:
                    obs, _, done, info = result
                else:
                    obs, _, terminated, truncated, info = result
                    done = terminated[0] or truncated[0]
                
                info = info[0] if isinstance(info, list) else info
                steps += 1
                
                if info.get('success', False):
                    success_v2 = True
                    adv_img_v2 = env_v2.current_image.squeeze(0)
                    break
            
            attack_time_v2 = time.time() - start_time
            
            if success_v2:
                metrics_v2 = compute_all_metrics(image, adv_img_v2)
                results['rl_v2'].add(
                    success=True,
                    attack_time=attack_time_v2,
                    query_count=steps,
                    l0_norm=metrics_v2['l0_norm'],
                    l2_norm=metrics_v2['l2_norm'],
                    linf_norm=metrics_v2['linf_norm'],
                    ssim=metrics_v2['ssim'],
                    psnr=metrics_v2['psnr']
                )
            else:
                results['rl_v2'].add(success=False, attack_time=attack_time_v2, query_count=steps,
                                   l0_norm=0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
        except Exception as e:
            results['rl_v2'].add(success=False, attack_time=0, query_count=0,
                               l0_norm=0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
        
        # === JSMA ===
        start_time = time.time()
        try:
            success_jsma, adv_img_jsma, pixels_jsma = jsma_attack(
                image, label, model, max_pixels=max_steps, theta=1.0
            )
            attack_time_jsma = time.time() - start_time
            
            if success_jsma:
                metrics_jsma = compute_all_metrics(image, adv_img_jsma)
                results['jsma'].add(
                    success=True,
                    attack_time=attack_time_jsma,
                    query_count=len(pixels_jsma),
                    l0_norm=metrics_jsma['l0_norm'],
                    l2_norm=metrics_jsma['l2_norm'],
                    linf_norm=metrics_jsma['linf_norm'],
                    ssim=metrics_jsma['ssim'],
                    psnr=metrics_jsma['psnr']
                )
            else:
                results['jsma'].add(success=False, attack_time=attack_time_jsma, query_count=max_steps,
                                  l0_norm=0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
        except Exception as e:
            results['jsma'].add(success=False, attack_time=0, query_count=0,
                              l0_norm=0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
        
        # === One-Pixel ===
        start_time = time.time()
        try:
            success_op, params_op = one_pixel_attack(image, label, model, max_iter=100)
            attack_time_op = time.time() - start_time
            
            if success_op:
                results['one_pixel'].add(success=True, attack_time=attack_time_op, query_count=100,
                                       l0_norm=1.0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
            else:
                results['one_pixel'].add(success=False, attack_time=attack_time_op, query_count=100,
                                       l0_norm=0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
        except Exception as e:
            results['one_pixel'].add(success=False, attack_time=0, query_count=0,
                                   l0_norm=0, l2_norm=0, linf_norm=0, ssim=0, psnr=0)
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.update(1)
        success_rates = {k: np.mean([m for m in v.metrics['success']]) for k, v in results.items()}
        pbar.set_postfix({
            'V2': f"{success_rates['rl_v2']:.1%}",
            'JSMA': f"{success_rates['jsma']:.1%}",
            'OP': f"{success_rates['one_pixel']:.1%}"
        })
    
    pbar.close()
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("âœ… å¯¹æ¯”å®éªŒå®Œæˆï¼")
    print("=" * 80)
    
    stats = {}
    for method_name, aggregator in results.items():
        stats[method_name] = aggregator.compute_statistics()
        os.makedirs("results/final", exist_ok=True)
        aggregator.save_to_csv(f"results/final/{method_name}_metrics.csv")
    
    # æ‰“å°ç»“æœè¡¨æ ¼
    print("\nğŸ“Š æ”»å‡»æ€§èƒ½å¯¹æ¯”:")
    print("-" * 90)
    print(f"{'æ–¹æ³•':<30} {'ASR (%)':>10} {'å¹³å‡L0':>10} {'å¹³å‡L2':>10} {'å¹³å‡æ—¶é—´ (s)':>15}")
    print("-" * 90)
    
    method_names = {
        'rl_v2': 'SparseAttackRL V2 (Ours) â­',
        'jsma': 'JSMA Attack',
        'one_pixel': 'One-Pixel Attack'
    }
    
    for key, name in method_names.items():
        st = stats[key]
        asr = st.get('success_rate', 0) * 100
        l0 = st.get('l0_norm_mean', 0)
        l2 = st.get('l2_norm_mean', 0)
        time_mean = st.get('attack_time_mean', 0)
        
        print(f"{name:<30} {asr:>9.1f} {l0:>9.2f} {l2:>9.2f} {time_mean:>14.2f}")
    
    print("-" * 90)
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
    print("\nğŸ“ˆ ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ:")
    print("-" * 60)
    
    v2_success = np.array(results['rl_v2'].metrics['success'], dtype=float)
    jsma_success = np.array(results['jsma'].metrics['success'], dtype=float)
    op_success = np.array(results['one_pixel'].metrics['success'], dtype=float)
    
    # V2 vs JSMA
    t_stat, p_value = scipy_stats.ttest_rel(v2_success, jsma_success)
    print(f"\n1. V2 vs JSMA:")
    print(f"   tç»Ÿè®¡é‡: {t_stat:.4f}")
    print(f"   på€¼: {p_value:.4f}")
    print(f"   æ˜¾è‘—æ€§(Î±=0.05): {'âœ… æ˜¾è‘—' if p_value < 0.05 else 'âŒ ä¸æ˜¾è‘—'}")
    
    # V2 vs One-Pixel
    t_stat, p_value = scipy_stats.ttest_rel(v2_success, op_success)
    print(f"\n2. V2 vs One-Pixel:")
    print(f"   tç»Ÿè®¡é‡: {t_stat:.4f}")
    print(f"   på€¼: {p_value:.4f}")
    print(f"   æ˜¾è‘—æ€§(Î±=0.05): {'âœ… æ˜¾è‘—' if p_value < 0.05 else 'âŒ ä¸æ˜¾è‘—'}")
    
    return stats, results


def generate_plots(stats):
    """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    os.makedirs("results/final/plots", exist_ok=True)
    sns.set(style="whitegrid", font_scale=1.3)
    
    methods = ['V2â­\n(Ours)', 'JSMA', 'One-Pixel']
    asrs = [
        stats['rl_v2'].get('success_rate', 0) * 100,
        stats['jsma'].get('success_rate', 0) * 100,
        stats['one_pixel'].get('success_rate', 0) * 100
    ]
    
    l0_norms = [
        stats['rl_v2'].get('l0_norm_mean', 0),
        stats['jsma'].get('l0_norm_mean', 0),
        1.0
    ]
    
    # ASRå¯¹æ¯”
    plt.figure(figsize=(10, 6))
    colors = ['#e74c3c', '#f39c12', '#2ecc71']
    bars = plt.bar(methods, asrs, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    plt.ylabel('Attack Success Rate (%)', fontsize=14)
    plt.title('Attack Success Rate Comparison', fontsize=16, pad=20, weight='bold')
    plt.ylim(0, 105)
    
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1.5,
                f'{height:.1f}%', ha='center', va='bottom', fontsize=13, weight='bold')
    
    plt.grid(axis='y', alpha=0.3, linestyle='--')
    plt.tight_layout()
    plt.savefig('results/final/plots/asr_comparison.png', dpi=300, bbox_inches='tight')
    plt.savefig('results/final/plots/asr_comparison.pdf', bbox_inches='tight')
    plt.close()
    
    # L0èŒƒæ•°å¯¹æ¯”
    plt.figure(figsize=(10, 6))
    bars = plt.bar(methods, l0_norms, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    plt.ylabel('Average Modified Pixels (L0 Norm)', fontsize=14)
    plt.title('Sparsity Comparison', fontsize=16, pad=20, weight='bold')
    
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                    f'{height:.2f}', ha='center', va='bottom', fontsize=13, weight='bold')
    
    plt.grid(axis='y', alpha=0.3, linestyle='--')
    plt.tight_layout()
    plt.savefig('results/final/plots/l0_comparison.png', dpi=300, bbox_inches='tight')
    plt.savefig('results/final/plots/l0_comparison.pdf', bbox_inches='tight')
    plt.close()
    
    print("âœ… å›¾è¡¨å·²ä¿å­˜è‡³: results/final/plots/")


if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("ğŸ”¬ SparseAttackRL æ ¸å¿ƒæ–¹æ³•å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    
    agent_v2 = train_v2_agent()
    stats, results = run_comparison(agent_v2, num_samples=100, max_steps=5)
    generate_plots(stats)
    
    print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print("ğŸ“ ç»“æœä¿å­˜åœ¨: results/final/")
    print("\n" + "=" * 80)
    print("ğŸ’¡ å®éªŒç»“æœæ€»ç»“:")
    print(f"   V2 (Ours):  ASR={stats['rl_v2'].get('success_rate', 0)*100:.1f}%, L0={stats['rl_v2'].get('l0_norm_mean', 0):.2f}")
    print(f"   JSMA:       ASR={stats['jsma'].get('success_rate', 0)*100:.1f}%, L0={stats['jsma'].get('l0_norm_mean', 0):.2f}")
    print(f"   One-Pixel:  ASR={stats['one_pixel'].get('success_rate', 0)*100:.1f}%, L0={stats['one_pixel'].get('l0_norm_mean', 0):.2f}")
    print("=" * 80)

