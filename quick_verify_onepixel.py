"""
One-Pixelæ”»å‡» - å¿«é€ŸéªŒè¯ç‰ˆï¼ˆ10æ ·æœ¬/æ¨¡å‹ï¼‰
å¿«é€Ÿç¡®è®¤è¶‹åŠ¿ï¼Œå®Œæ•´æµ‹è¯•äº¤ç»™æœåŠ¡å™¨
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
from pathlib import Path
import json
from tqdm import tqdm
import time

from one_pixel_attack import one_pixel_attack

def load_cifar10_data():
    """åŠ è½½CIFAR-10æµ‹è¯•æ•°æ®"""
    transform = transforms.Compose([transforms.ToTensor()])
    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    return testset

def load_model(model_name, device):
    """åŠ è½½æŒ‡å®šæ¨¡å‹"""
    if model_name == 'ResNet18':
        model = torchvision.models.resnet18(weights=None)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, 10)
        model.load_state_dict(torch.load('cifar10_resnet18.pth', map_location=device, weights_only=False))
    
    elif model_name == 'VGG16':
        model = torchvision.models.vgg16(weights=None)
        num_ftrs = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(num_ftrs, 10)
        model.load_state_dict(torch.load('cifar10_vgg16.pth', map_location=device, weights_only=False))
    
    elif model_name == 'MobileNetV2':
        model = torchvision.models.mobilenet_v2(weights=None)
        num_ftrs = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(num_ftrs, 10)
        model.load_state_dict(torch.load('cifar10_mobilenetv2.pth', map_location=device, weights_only=False))
    
    model.to(device)
    model.eval()
    return model

def quick_test_model(model_name, device, testset, num_samples=10):
    """å¿«é€Ÿæµ‹è¯•ï¼ˆ10æ ·æœ¬ï¼‰"""
    print(f"\n{'='*80}")
    print(f"âš¡ å¿«é€ŸéªŒè¯: {model_name}")
    print(f"{'='*80}")
    
    model = load_model(model_name, device)
    
    # é€‰æ‹©æ ·æœ¬
    selected_samples = []
    for idx in range(len(testset)):
        if len(selected_samples) >= num_samples:
            break
        image, label = testset[idx]
        image_batch = image.unsqueeze(0).to(device)
        with torch.no_grad():
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
        if pred == label:
            selected_samples.append((idx, image, label))
    
    print(f"âœ… é€‰æ‹©äº† {len(selected_samples)} ä¸ªæ ·æœ¬")
    print(f"â° é¢„è®¡æ—¶é—´: 8-15åˆ†é’Ÿ\n")
    
    # æ”»å‡»
    success_count = 0
    results = []
    
    for i, (idx, image, label) in enumerate(tqdm(selected_samples, desc=f"{model_name}")):
        start_time = time.time()
        
        success, adv_image, modified_info = one_pixel_attack(
            image=image,
            label=label,
            model=model,
            max_iter=50,
            pop_size=200
        )
        
        attack_time = time.time() - start_time
        
        if success:
            diff = (adv_image - image).abs()
            l0 = (diff.sum(dim=0) > 0).sum().item()
            success_count += 1
            results.append({'sample_id': int(idx), 'success': True, 'l0': float(l0)})
            print(f"  âœ… æ ·æœ¬{i+1}: æˆåŠŸ! (æ€»è®¡{success_count}/{i+1})")
        else:
            results.append({'sample_id': int(idx), 'success': False})
    
    asr = success_count / len(selected_samples) * 100
    
    print(f"\nğŸ“Š {model_name}: ASR = {asr:.1f}% ({success_count}/{len(selected_samples)})")
    
    return {
        'model': model_name,
        'asr': float(asr),
        'success_count': success_count,
        'total_samples': len(selected_samples),
        'results': results
    }

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("âš¡ One-Pixelå¿«é€ŸéªŒè¯ï¼ˆ10æ ·æœ¬/æ¨¡å‹ï¼‰")
    print("="*80)
    print("\nğŸ’¡ ç­–ç•¥:")
    print("  âœ… æ¯ä¸ªæ¨¡å‹10ä¸ªæ ·æœ¬")
    print("  âœ… å¿«é€ŸéªŒè¯è¶‹åŠ¿")
    print("  âœ… é¢„è®¡æ€»æ—¶é—´: 30-45åˆ†é’Ÿ")
    print("  âœ… å®Œæ•´æµ‹è¯•äº¤ç»™æœåŠ¡å™¨\n")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}\n")
    
    testset = load_cifar10_data()
    
    # æµ‹è¯•3ä¸ªæ¨¡å‹
    models = ['ResNet18', 'MobileNetV2', 'VGG16']
    all_results = []
    
    start_time_total = time.time()
    
    for model_name in models:
        result = quick_test_model(model_name, device, testset, num_samples=10)
        all_results.append(result)
    
    total_time = time.time() - start_time_total
    
    # æ±‡æ€»
    print(f"\n{'='*80}")
    print("ğŸ“Š å¿«é€ŸéªŒè¯æ±‡æ€»")
    print(f"{'='*80}")
    print(f"æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ\n")
    
    print(f"{'æ¨¡å‹':<15} {'ASR (10æ ·æœ¬)'}")
    print("-"*40)
    for r in all_results:
        print(f"{r['model']:<15} {r['asr']:.1f}%")
    
    # æ’åº
    print(f"\nğŸ† è„†å¼±æ€§æ’åºï¼ˆASRä»é«˜åˆ°ä½ï¼‰:")
    sorted_results = sorted(all_results, key=lambda x: x['asr'], reverse=True)
    for i, r in enumerate(sorted_results, 1):
        print(f"  {i}. {r['model']}: {r['asr']:.1f}%")
    
    # ä¿å­˜
    output_dir = Path('results/onepixel_quick_verify')
    output_dir.mkdir(exist_ok=True, parents=True)
    
    summary = {
        'test_type': 'quick_verification',
        'samples_per_model': 10,
        'total_time_minutes': float(total_time/60),
        'models': all_results
    }
    
    with open(output_dir / 'quick_verify_summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    print(f"\n{'='*80}")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    print(f"{'='*80}")
    print("åŸºäºè¿™ä¸ªå¿«é€ŸéªŒè¯ç»“æœï¼š")
    print("  1. å¦‚æœè¶‹åŠ¿æ˜ç¡® â†’ éƒ¨ç½²æœåŠ¡å™¨åš100æ ·æœ¬å®Œæ•´æµ‹è¯•")
    print("  2. æœåŠ¡å™¨é…ç½®ï¼šmaxiter=50, popsize=200, samples=100")
    print("  3. é¢„è®¡æœåŠ¡å™¨æ—¶é—´ï¼š2-3å°æ—¶/æ¨¡å‹")
    print("  4. åå°è¿è¡Œï¼Œæ˜å¤©æ—©ä¸Šçœ‹ç»“æœ")
    
    print(f"\nğŸ‰ å¿«é€ŸéªŒè¯å®Œæˆï¼")
    print(f"{'='*80}\n")

if __name__ == "__main__":
    main()







