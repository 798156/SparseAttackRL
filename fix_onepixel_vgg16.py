"""
One-Pixelæ”»å‡»ä¿®å¤å’Œå¢å¼ºæµ‹è¯•
ä¸“é—¨é’ˆå¯¹VGG16çš„0% ASRé—®é¢˜
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
from pathlib import Path
import json
from tqdm import tqdm
import time

# å¯¼å…¥One-Pixelæ”»å‡»
from one_pixel_attack import one_pixel_attack

def load_model():
    """åŠ è½½VGG16æ¨¡å‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åŠ è½½VGG16
    model = torchvision.models.vgg16(weights=None)
    num_ftrs = model.classifier[6].in_features
    model.classifier[6] = nn.Linear(num_ftrs, 10)
    
    # åŠ è½½æƒé‡
    model.load_state_dict(torch.load('cifar10_vgg16.pth', map_location=device))
    model.to(device)
    model.eval()
    
    return model, device

def load_test_data(num_samples=50):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    
    testset = torchvision.datasets.CIFAR10(
        root='./data', 
        train=False, 
        download=True, 
        transform=transform
    )
    
    return testset

def test_onepixel_config(model, device, testset, config_name, max_iter, pop_size, num_samples=50):
    """æµ‹è¯•ç‰¹å®šé…ç½®çš„One-Pixelæ”»å‡»"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª æµ‹è¯•é…ç½®: {config_name}")
    print(f"{'='*80}")
    print(f"å‚æ•°: maxiter={max_iter}, popsize={pop_size}")
    print(f"æ ·æœ¬æ•°: {num_samples}")
    
    # é€‰æ‹©æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬
    selected_samples = []
    for idx in range(len(testset)):
        if len(selected_samples) >= num_samples:
            break
        
        image, label = testset[idx]
        image_batch = image.unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
        
        if pred == label:
            selected_samples.append((idx, image, label))
    
    print(f"âœ… é€‰æ‹©äº† {len(selected_samples)} ä¸ªæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬")
    
    # æµ‹è¯•æ”»å‡»
    success_count = 0
    total_time = 0
    l0_values = []
    
    results = []
    
    for i, (idx, image, label) in enumerate(tqdm(selected_samples, desc="æ”»å‡»è¿›åº¦")):
        start_time = time.time()
        
        # One-Pixelæ”»å‡» (æ³¨æ„å‚æ•°é¡ºåºå’Œè¿”å›å€¼)
        success, adv_image, modified_info = one_pixel_attack(
            image=image,
            label=label,
            model=model,
            max_iter=max_iter,
            pop_size=pop_size
        )
        
        attack_time = time.time() - start_time
        
        # éªŒè¯æ”»å‡»æ˜¯å¦æˆåŠŸ
        if success:
            # è®¡ç®—L0
            diff = (adv_image - image).abs()
            modified_pixels = (diff.sum(dim=0) > 0).sum().item()
            l0_values.append(modified_pixels)
            success_count += 1
            
            results.append({
                'sample_id': idx,
                'success': True,
                'l0': modified_pixels,
                'time': attack_time,
                'modified_pixel': modified_info
            })
        else:
            results.append({
                'sample_id': idx,
                'success': False,
                'time': attack_time
            })
        
        total_time += attack_time
    
    # ç»Ÿè®¡ç»“æœ
    asr = success_count / len(selected_samples) * 100
    avg_time = total_time / len(selected_samples)
    avg_l0 = np.mean(l0_values) if l0_values else 0
    
    print(f"\nğŸ“Š ç»“æœ:")
    print(f"  ASR: {success_count}/{len(selected_samples)} = {asr:.1f}%")
    print(f"  å¹³å‡L0: {avg_l0:.2f}")
    print(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}ç§’")
    
    return {
        'config': config_name,
        'max_iter': max_iter,
        'pop_size': pop_size,
        'asr': asr,
        'success_count': success_count,
        'total_samples': len(selected_samples),
        'avg_l0': avg_l0,
        'avg_time': avg_time,
        'detailed_results': results
    }

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸ”§ One-Pixelæ”»å‡»ä¿®å¤ - VGG16ä¸“é¡¹æµ‹è¯•")
    print("="*80)
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½VGG16æ¨¡å‹...")
    model, device = load_model()
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®...")
    testset = load_test_data()
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
    
    # æµ‹è¯•ä¸åŒé…ç½®
    configs = [
        # åŸå§‹é…ç½®
        ("åŸå§‹é…ç½®", 100, 400, 30),
        
        # å¢åŠ è¿­ä»£æ¬¡æ•°
        ("å¢åŠ è¿­ä»£1", 200, 400, 30),
        ("å¢åŠ è¿­ä»£2", 300, 400, 30),
        
        # å¢åŠ ç§ç¾¤å¤§å°
        ("å¢åŠ ç§ç¾¤1", 100, 800, 30),
        ("å¢åŠ ç§ç¾¤2", 100, 1200, 30),
        
        # åŒæ—¶å¢åŠ 
        ("åŒå€é…ç½®", 200, 800, 30),
        ("ä¸‰å€é…ç½®", 300, 1200, 30),
    ]
    
    all_results = []
    
    for config_name, max_iter, pop_size, num_samples in configs:
        result = test_onepixel_config(
            model=model,
            device=device,
            testset=testset,
            config_name=config_name,
            max_iter=max_iter,
            pop_size=pop_size,
            num_samples=num_samples
        )
        all_results.append(result)
        
        # å¦‚æœæ‰¾åˆ°æœ‰æ•ˆé…ç½®ï¼Œå¯ä»¥æå‰åœæ­¢
        if result['asr'] > 5.0:
            print(f"\nâœ… æ‰¾åˆ°æœ‰æ•ˆé…ç½®ï¼ASR={result['asr']:.1f}%")
            print(f"ç»§ç»­æµ‹è¯•å‰©ä½™é…ç½®ä»¥æ‰¾åˆ°æœ€ä½³å‚æ•°...")
    
    # æ±‡æ€»ç»“æœ
    print(f"\n{'='*80}")
    print("ğŸ“Š æ‰€æœ‰é…ç½®æ±‡æ€»")
    print(f"{'='*80}\n")
    
    print(f"{'é…ç½®':<15} {'MaxIter':<10} {'PopSize':<10} {'ASR':<10} {'å¹³å‡L0':<10} {'å¹³å‡æ—¶é—´'}")
    print("-"*80)
    for r in all_results:
        print(f"{r['config']:<15} {r['max_iter']:<10} {r['pop_size']:<10} "
              f"{r['asr']:<10.1f} {r['avg_l0']:<10.2f} {r['avg_time']:.2f}s")
    
    # æ‰¾åˆ°æœ€ä½³é…ç½®
    best_config = max(all_results, key=lambda x: x['asr'])
    print(f"\n{'='*80}")
    print(f"ğŸ† æœ€ä½³é…ç½®: {best_config['config']}")
    print(f"{'='*80}")
    print(f"  MaxIter: {best_config['max_iter']}")
    print(f"  PopSize: {best_config['pop_size']}")
    print(f"  ASR: {best_config['asr']:.1f}%")
    print(f"  å¹³å‡L0: {best_config['avg_l0']:.2f}")
    print(f"  å¹³å‡æ—¶é—´: {best_config['avg_time']:.2f}ç§’")
    
    # å¦‚æœæœ€ä½³é…ç½®ASR > 0ï¼Œç”¨å®ƒè¿›è¡Œå®Œæ•´æµ‹è¯•ï¼ˆ100æ ·æœ¬ï¼‰
    if best_config['asr'] > 0:
        print(f"\n{'='*80}")
        print("ğŸš€ ä½¿ç”¨æœ€ä½³é…ç½®è¿›è¡Œå®Œæ•´æµ‹è¯•ï¼ˆ100æ ·æœ¬ï¼‰")
        print(f"{'='*80}")
        
        final_result = test_onepixel_config(
            model=model,
            device=device,
            testset=testset,
            config_name="æœ€ç»ˆé…ç½®",
            max_iter=best_config['max_iter'],
            pop_size=best_config['pop_size'],
            num_samples=100
        )
        
        # ä¿å­˜ç»“æœ
        output_dir = Path('results/onepixel_fix')
        output_dir.mkdir(exist_ok=True, parents=True)
        
        with open(output_dir / 'vgg16_onepixel_optimized.json', 'w') as f:
            json.dump(final_result, f, indent=2)
        
        print(f"\nâœ… æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°: {output_dir / 'vgg16_onepixel_optimized.json'}")
    else:
        print(f"\n{'='*80}")
        print("âš ï¸  æ‰€æœ‰é…ç½®çš„ASRéƒ½æ˜¯0%")
        print(f"{'='*80}")
        print("\nè¿™å¯èƒ½æ„å‘³ç€:")
        print("  1. VGG16å¯¹One-Pixelæ”»å‡»ç¡®å®é«˜åº¦é²æ£’")
        print("  2. è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶å‘ç°ï¼")
        print("  3. è®ºæ–‡ä¸­éœ€è¦è¯¦ç»†è®¨è®ºè¿™ä¸ªç°è±¡")
    
    # ä¿å­˜æ‰€æœ‰é…ç½®çš„ç»“æœ
    output_dir = Path('results/onepixel_fix')
    output_dir.mkdir(exist_ok=True, parents=True)
    
    with open(output_dir / 'all_configs_comparison.json', 'w') as f:
        json.dump(all_results, f, indent=2)
    
    print(f"\nâœ… æ‰€æœ‰é…ç½®å¯¹æ¯”å·²ä¿å­˜åˆ°: {output_dir / 'all_configs_comparison.json'}")
    
    print(f"\n{'='*80}")
    print("ğŸ‰ One-Pixelä¿®å¤æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}\n")

if __name__ == "__main__":
    main()

