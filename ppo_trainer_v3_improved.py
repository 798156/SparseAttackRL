# ppo_trainer_v3_improved.py
"""
æ”¹è¿›ç‰ˆPPOè®­ç»ƒå™¨ - å¤šæ ·æœ¬è®­ç»ƒ
æ ¸å¿ƒæ”¹è¿›ï¼š
1. âœ… å¤šæ ·æœ¬å¹¶è¡Œè®­ç»ƒï¼ˆè§£å†³è¿‡æ‹Ÿåˆï¼‰
2. âœ… åŠ¨æ€æ ·æœ¬é‡‡æ ·ï¼ˆå¢åŠ å¤šæ ·æ€§ï¼‰
3. âœ… è¯¾ç¨‹å­¦ä¹ ï¼ˆä»ç®€å•åˆ°å›°éš¾ï¼‰
4. âœ… æ¨¡å‹ç‰¹å®šè®­ç»ƒï¼ˆæ¯ä¸ªæ¨¡å‹å•ç‹¬è®­ç»ƒï¼‰
"""

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
from stable_baselines3.common.callbacks import BaseCallback
import torch
import numpy as np
from torch.utils.data import DataLoader, Subset
import os
import gymnasium as gym


class DynamicSampleEnv(gym.Env):
    """
    åŠ¨æ€é‡‡æ ·ç¯å¢ƒåŒ…è£…å™¨
    æ¯æ¬¡resetæ—¶éšæœºé€‰æ‹©æ–°çš„è®­ç»ƒæ ·æœ¬
    """
    
    def __init__(self, env_class, model, dataset, device='cuda', 
                 num_samples=100, max_steps=5):
        """
        å‚æ•°:
            env_class: ç¯å¢ƒç±»ï¼ˆå¦‚SparseAttackEnvV2ï¼‰
            model: ç›®æ ‡æ¨¡å‹
            dataset: è®­ç»ƒæ•°æ®é›†
            num_samples: è®­ç»ƒæ ·æœ¬æ± å¤§å°
            max_steps: æœ€å¤§æ­¥æ•°
        """
        super().__init__()  # åˆå§‹åŒ–gym.Env
        
        self.env_class = env_class
        self.model = model
        self.dataset = dataset
        self.device = device
        self.max_steps = max_steps
        
        # é€‰æ‹©æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬
        print(f"ğŸ“Š é€‰æ‹©{num_samples}ä¸ªè®­ç»ƒæ ·æœ¬...")
        self.train_samples = self._select_samples(num_samples)
        print(f"âœ… é€‰æ‹©äº†{len(self.train_samples)}ä¸ªæ ·æœ¬")
        
        # å½“å‰ç¯å¢ƒ
        self.current_env = None
        self._reset_with_new_sample()
        
        # ç¯å¢ƒå±æ€§
        self.action_space = self.current_env.action_space
        self.observation_space = self.current_env.observation_space
    
    def _select_samples(self, num_samples):
        """é€‰æ‹©æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬"""
        correct_indices = []
        
        with torch.no_grad():
            for idx in range(min(len(self.dataset), num_samples * 3)):
                image, label = self.dataset[idx]
                image = image.unsqueeze(0).to(self.device)
                output = self.model(image)
                pred = output.argmax(dim=1).item()
                
                if pred == label:
                    correct_indices.append(idx)
                
                if len(correct_indices) >= num_samples:
                    break
        
        return correct_indices
    
    def _reset_with_new_sample(self):
        """ç”¨æ–°æ ·æœ¬åˆ›å»ºç¯å¢ƒ"""
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬
        sample_idx = np.random.choice(self.train_samples)
        image, label = self.dataset[sample_idx]
        
        # åˆ›å»ºæ–°ç¯å¢ƒ
        self.current_env = self.env_class(
            clean_image=image,
            true_label=label,
            model=self.model,
            max_steps=self.max_steps,
            use_saliency=True
        )
    
    def reset(self, **kwargs):
        """é‡ç½®ç¯å¢ƒ - éšæœºé€‰æ‹©æ–°æ ·æœ¬"""
        self._reset_with_new_sample()
        return self.current_env.reset(**kwargs)
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        return self.current_env.step(action)


class CurriculumCallback(BaseCallback):
    """
    è¯¾ç¨‹å­¦ä¹ å›è°ƒ
    åŠ¨æ€è°ƒæ•´æ ·æœ¬éš¾åº¦
    """
    
    def __init__(self, env_wrapper, verbose=0):
        super().__init__(verbose)
        self.env_wrapper = env_wrapper
        self.success_rate = 0.0
        self.check_interval = 1000
    
    def _on_step(self):
        # æ¯éš”ä¸€æ®µæ—¶é—´æ£€æŸ¥æˆåŠŸç‡
        if self.n_calls % self.check_interval == 0:
            # æ ¹æ®æˆåŠŸç‡è°ƒæ•´éš¾åº¦
            if self.success_rate > 0.7:
                # æˆåŠŸç‡é«˜ï¼Œå¢åŠ éš¾åº¦
                self.env_wrapper.max_steps = max(3, self.env_wrapper.max_steps - 1)
                if self.verbose:
                    print(f"ğŸ“ˆ å¢åŠ éš¾åº¦: max_steps = {self.env_wrapper.max_steps}")
            elif self.success_rate < 0.3:
                # æˆåŠŸç‡ä½ï¼Œé™ä½éš¾åº¦
                self.env_wrapper.max_steps = min(10, self.env_wrapper.max_steps + 1)
                if self.verbose:
                    print(f"ğŸ“‰ é™ä½éš¾åº¦: max_steps = {self.env_wrapper.max_steps}")
        
        return True


def train_rl_multi_sample(
    model,
    dataset,
    env_class,
    num_train_samples=100,
    timesteps=50000,
    save_path="ppo_sparse_multi",
    device='cuda',
    max_steps=5,
    verbose=1
):
    """
    å¤šæ ·æœ¬è®­ç»ƒRL agent
    
    å‚æ•°:
        model: ç›®æ ‡æ¨¡å‹
        dataset: è®­ç»ƒæ•°æ®é›†ï¼ˆCIFAR-10ï¼‰
        env_class: ç¯å¢ƒç±»
        num_train_samples: è®­ç»ƒæ ·æœ¬æ•°
        timesteps: è®­ç»ƒæ­¥æ•°
        save_path: ä¿å­˜è·¯å¾„
        device: è®¾å¤‡
        max_steps: åˆå§‹æœ€å¤§æ­¥æ•°
        verbose: æ—¥å¿—çº§åˆ«
    
    è¿”å›:
        trained_agent: è®­ç»ƒå¥½çš„agent
    """
    print("=" * 80)
    print("ğŸš€ å¤šæ ·æœ¬RLè®­ç»ƒ - æ”¹è¿›ç‰ˆ")
    print("=" * 80)
    print(f"\né…ç½®:")
    print(f"  ç›®æ ‡æ¨¡å‹: {model.__class__.__name__}")
    print(f"  è®­ç»ƒæ ·æœ¬æ•°: {num_train_samples}")
    print(f"  è®­ç»ƒæ­¥æ•°: {timesteps}")
    print(f"  åˆå§‹max_steps: {max_steps}")
    print(f"  è®¾å¤‡: {device}")
    
    # åˆ›å»ºåŠ¨æ€é‡‡æ ·ç¯å¢ƒ
    def make_env():
        return DynamicSampleEnv(
            env_class=env_class,
            model=model,
            dataset=dataset,
            device=device,
            num_samples=num_train_samples,
            max_steps=max_steps
        )
    
    # åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒï¼ˆå¯é€‰ï¼šå¹¶è¡Œè®­ç»ƒï¼‰
    env = DummyVecEnv([make_env])
    
    # å¯¼å…¥CNNç‰¹å¾æå–å™¨
    from ppo_trainer_v2 import CNNFeatureExtractor
    
    # é…ç½®ç­–ç•¥ç½‘ç»œ
    policy_kwargs = dict(
        features_extractor_class=CNNFeatureExtractor,
        features_extractor_kwargs=dict(features_dim=256),
        net_arch=[dict(pi=[128, 128], vf=[128, 128])]
    )
    
    # åˆ›å»ºPPO agent
    agent = PPO(
        policy="CnnPolicy",
        env=env,
        learning_rate=3e-4,
        n_steps=2048,
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.01,  # ç†µç³»æ•°ï¼šé¼“åŠ±æ¢ç´¢
        vf_coef=0.5,
        max_grad_norm=0.5,
        policy_kwargs=policy_kwargs,
        verbose=verbose,
        tensorboard_log="./logs/",
        device=device
    )
    
    print(f"\nğŸ“ å¼€å§‹è®­ç»ƒ...")
    print(f"   æ¯æ¬¡resetä¼šéšæœºé€‰æ‹©æ–°æ ·æœ¬")
    print(f"   æ€»è®¡{num_train_samples}ä¸ªè®­ç»ƒæ ·æœ¬\n")
    
    # è®­ç»ƒ
    agent.learn(
        total_timesteps=timesteps,
        tb_log_name="ppo_multi_sample",
        progress_bar=True
    )
    
    # ä¿å­˜æ¨¡å‹
    agent.save(save_path)
    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}.zip")
    
    return agent


def train_model_specific_agent(
    model,
    model_name,
    dataset,
    env_class,
    num_train_samples=100,
    timesteps=50000,
    save_dir="models",
    device='cuda'
):
    """
    ä¸ºç‰¹å®šæ¨¡å‹è®­ç»ƒä¸“é—¨çš„RL agent
    
    å‚æ•°:
        model: ç›®æ ‡æ¨¡å‹
        model_name: æ¨¡å‹åç§°ï¼ˆå¦‚'resnet18', 'vgg16'ï¼‰
        dataset: è®­ç»ƒæ•°æ®é›†
        env_class: ç¯å¢ƒç±»
        num_train_samples: è®­ç»ƒæ ·æœ¬æ•°
        timesteps: è®­ç»ƒæ­¥æ•°
        save_dir: ä¿å­˜ç›®å½•
        device: è®¾å¤‡
    
    è¿”å›:
        agent: è®­ç»ƒå¥½çš„agent
    """
    print("\n" + "=" * 80)
    print(f"ğŸ¯ ä¸º {model_name.upper()} è®­ç»ƒä¸“é—¨çš„RL agent")
    print("=" * 80)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"ppo_sparse_{model_name}")
    
    # è®­ç»ƒ
    agent = train_rl_multi_sample(
        model=model,
        dataset=dataset,
        env_class=env_class,
        num_train_samples=num_train_samples,
        timesteps=timesteps,
        save_path=save_path,
        device=device,
        verbose=1
    )
    
    # éªŒè¯agentæ€§èƒ½
    print(f"\nğŸ§ª éªŒè¯ {model_name} agent...")
    test_agent_performance(agent, model, dataset, num_test=20, device=device)
    
    return agent


def test_agent_performance(agent, model, dataset, num_test=20, device='cuda'):
    """
    æµ‹è¯•agentæ€§èƒ½
    """
    from sparse_attack_env_v2 import SparseAttackEnvV2
    
    successes = 0
    total_l0 = 0
    
    print(f"\næµ‹è¯•{num_test}ä¸ªæ ·æœ¬...")
    
    with torch.no_grad():
        # é€‰æ‹©æµ‹è¯•æ ·æœ¬
        test_indices = []
        for idx in range(len(dataset)):
            if len(test_indices) >= num_test:
                break
            
            image, label = dataset[idx]
            image_batch = image.unsqueeze(0).to(device)
            output = model(image_batch)
            pred = output.argmax(dim=1).item()
            
            if pred == label:
                test_indices.append(idx)
    
    for idx in test_indices:
        image, label = dataset[idx]
        
        # åˆ›å»ºç¯å¢ƒ
        env = SparseAttackEnvV2(
            clean_image=image,
            true_label=label,
            model=model,
            max_steps=5,
            use_saliency=True
        )
        
        # æ‰§è¡Œæ”»å‡»
        obs, _ = env.reset()
        done = False
        steps = 0
        
        while not done and steps < 10:
            action, _ = agent.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            done = terminated or truncated
            steps += 1
        
        # æ£€æŸ¥ç»“æœ
        with torch.no_grad():
            adv_image = torch.tensor(env.current_image, dtype=torch.float32).to(device)
            output = model(adv_image)
            pred = output.argmax(dim=1).item()
        
        if pred != label:
            successes += 1
            l0 = (env.modification_mask.sum().item())
            total_l0 += l0
    
    asr = successes / num_test * 100
    avg_l0 = total_l0 / max(successes, 1)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   ASR: {asr:.1f}%")
    print(f"   å¹³å‡L0: {avg_l0:.2f}")
    
    return asr, avg_l0


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

if __name__ == "__main__":
    import torchvision
    from torchvision import transforms
    
    print("ğŸ§ª æµ‹è¯•æ”¹è¿›ç‰ˆRLè®­ç»ƒ")
    
    # åŠ è½½æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])
    
    dataset = torchvision.datasets.CIFAR10(
        root='./data', 
        train=False, 
        download=True, 
        transform=transform
    )
    
    # åŠ è½½æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # ResNet18
    print("\n" + "=" * 80)
    print("è®­ç»ƒ ResNet18 ä¸“ç”¨agent")
    print("=" * 80)
    
    resnet18 = torchvision.models.resnet18(weights=None)
    resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, 10)
    resnet18.load_state_dict(torch.load('cifar10_resnet18.pth', map_location=device))
    resnet18 = resnet18.to(device)
    resnet18.eval()
    
    from sparse_attack_env_v2 import SparseAttackEnvV2
    
    agent_resnet = train_model_specific_agent(
        model=resnet18,
        model_name='resnet18',
        dataset=dataset,
        env_class=SparseAttackEnvV2,
        num_train_samples=100,  # 100ä¸ªè®­ç»ƒæ ·æœ¬
        timesteps=50000,        # 5ä¸‡æ­¥è®­ç»ƒ
        device=device
    )
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")

