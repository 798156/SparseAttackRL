#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¤šä¸ªé˜²å¾¡æ¨¡å‹
å¯¹æ¯”ä¸åŒé˜²å¾¡ç­–ç•¥å¯¹L0æ”»å‡»çš„é²æ£’æ€§
"""

import torch
import torchvision
import torchvision.transforms as transforms
import json
from pathlib import Path
from datetime import datetime
import numpy as np
from tqdm import tqdm

try:
    from robustbench import load_model
    ROBUSTBENCH_AVAILABLE = True
except ImportError:
    ROBUSTBENCH_AVAILABLE = False
    print("âš ï¸ RobustBenchæœªå®‰è£…ï¼Œæ— æ³•ç»§ç»­")

from attack_adapters import (
    jsma_attack_adapter,
    sparsefool_attack_adapter,
    greedy_attack_adapter,
    pixel_gradient_attack_adapter,
    random_sparse_attack_adapter
)

class MultiDefenseModelTester:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.output_dir = Path('results/multi_defense_models')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”»å‡»æ–¹æ³•é…ç½®
        self.attack_methods = {
            'jsma': {
                'func': jsma_attack_adapter,
                'config': {'max_pixels': 10, 'theta': 1.0, 'max_iterations': 100}
            },
            'sparsefool': {
                'func': sparsefool_attack_adapter,
                'config': {'max_iter': 20, 'overshoot': 0.02, 'lambda_': 3.0}
            },
            'greedy': {
                'func': greedy_attack_adapter,
                'config': {'max_pixels': 10, 'alpha': 0.1, 'max_iterations': 100}
            },
            'pixelgrad': {
                'func': pixel_gradient_attack_adapter,
                'config': {'max_pixels': 10, 'alpha': 0.2, 'beta': 0.9}
            },
            'randomsparse': {
                'func': random_sparse_attack_adapter,
                'config': {'max_pixels': 10, 'perturbation_size': 0.2, 'max_attempts': 50}
            }
        }
        
        # é˜²å¾¡æ¨¡å‹åˆ—è¡¨ï¼ˆé‡æ–°æµ‹è¯•Rice2020ç¡®ä¿å…¬å¹³å¯¹æ¯”ï¼‰
        self.defense_models = {
            'Rice2020Overfitting': {
                'model_name': 'Rice2020Overfitting',
                'description': 'TRADESå¼ºé˜²å¾¡ï¼ˆå¼ºLâˆé²æ£’æ€§ï¼‰',
                'threat_model': 'Linf'
            }
        }
        
        print(f"Device: {self.device}")
        print(f"æµ‹è¯• {len(self.defense_models)} ä¸ªé˜²å¾¡æ¨¡å‹")
        print(f"ä½¿ç”¨ {len(self.attack_methods)} ç§æ”»å‡»æ–¹æ³•")
    
    def load_test_data(self, num_samples=100):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        print("\n" + "="*60)
        print(f"ğŸ“‚ åŠ è½½CIFAR-10æµ‹è¯•é›†ï¼ˆç›®æ ‡ï¼š{num_samples}ä¸ªæ ·æœ¬ï¼‰...")
        print("="*60)
        
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(42)
        np.random.seed(42)
        
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        
        testset = torchvision.datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform
        )
        test_loader = torch.utils.data.DataLoader(
            testset, batch_size=1, shuffle=False
        )
        
        return test_loader
    
    def select_samples(self, model, test_loader, num_samples=100):
        """é€‰æ‹©æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬"""
        print(f"\nğŸ¯ é€‰æ‹©{num_samples}ä¸ªè¢«æ¨¡å‹æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬...")
        
        samples = []
        
        with torch.no_grad():
            for images, labels in test_loader:
                if len(samples) >= num_samples:
                    break
                
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                outputs = model(images)
                pred = outputs.argmax(dim=1)
                
                if pred.item() == labels.item():
                    samples.append({
                        'image': images.cpu(),
                        'label': labels.item()
                    })
        
        print(f"âœ“ é€‰æ‹©å®Œæˆï¼å…±{len(samples)}ä¸ªæ ·æœ¬")
        return samples
    
    def test_attack_on_samples(self, model, samples, attack_name, attack_func, attack_config):
        """åœ¨æ ·æœ¬ä¸Šæµ‹è¯•æ”»å‡»"""
        results = []
        success_count = 0
        
        l0_values = []
        l2_values = []
        ssim_values = []
        time_values = []
        
        for i, sample in enumerate(tqdm(samples, desc=f"  {attack_name}")):
            image = sample['image'].to(self.device)
            label = sample['label']
            label_tensor = torch.tensor([label]).to(self.device)
            
            try:
                import time
                start_time = time.time()
                
                adv_image, success, info = attack_func(
                    model, image, label_tensor, device=self.device, **attack_config
                )
                
                elapsed = time.time() - start_time
                
                result = {
                    'sample_id': i,
                    'success': bool(success),
                    'time': float(elapsed)
                }
                
                if success:
                    result['l0'] = float(info.get('l0', 0))
                    result['l2'] = float(info.get('l2', 0))
                    result['ssim'] = float(info.get('ssim', 0))
                    
                    l0_values.append(result['l0'])
                    l2_values.append(result['l2'])
                    ssim_values.append(result['ssim'])
                    time_values.append(result['time'])
                    
                    success_count += 1
                
                results.append(result)
                
            except Exception as e:
                results.append({
                    'sample_id': i,
                    'success': False,
                    'error': str(e)[:100]
                })
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        summary = {
            'method': attack_name,
            'asr': (success_count / len(samples)) * 100 if samples else 0,
            'success_count': success_count,
            'total_samples': len(samples),
            'avg_l0': float(np.mean(l0_values)) if l0_values else 0,
            'avg_l2': float(np.mean(l2_values)) if l2_values else 0,
            'avg_ssim': float(np.mean(ssim_values)) if ssim_values else 0,
            'avg_time': float(np.mean(time_values)) if time_values else 0,
            'std_l0': float(np.std(l0_values)) if l0_values else 0,
            'std_l2': float(np.std(l2_values)) if l2_values else 0
        }
        
        return results, summary
    
    def test_defense_model(self, model_key, num_samples=100):
        """æµ‹è¯•å•ä¸ªé˜²å¾¡æ¨¡å‹"""
        print("\n" + "ğŸš€"*30)
        print(f"æµ‹è¯•é˜²å¾¡æ¨¡å‹: {model_key}")
        print(f"æè¿°: {self.defense_models[model_key]['description']}")
        print("ğŸš€"*30)
        
        # åŠ è½½æ¨¡å‹
        model_name = self.defense_models[model_key]['model_name']
        threat_model = self.defense_models[model_key]['threat_model']
        
        try:
            print(f"\nğŸ“¥ åŠ è½½æ¨¡å‹: {model_name}...")
            model = load_model(
                model_name=model_name,
                dataset='cifar10',
                threat_model=threat_model
            )
            model = model.to(self.device)
            model.eval()
            print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_loader = self.load_test_data(num_samples)
        
        # é€‰æ‹©æ ·æœ¬
        samples = self.select_samples(model, test_loader, num_samples)
        
        if len(samples) < num_samples:
            print(f"âš ï¸  è­¦å‘Šï¼šåªæ‰¾åˆ°{len(samples)}ä¸ªæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬")
        
        # æµ‹è¯•æ‰€æœ‰æ”»å‡»æ–¹æ³•
        all_results = {}
        all_summaries = {}
        
        print("\n" + "="*60)
        print("ğŸ“Š å¼€å§‹æ”»å‡»æµ‹è¯•...")
        print("="*60)
        
        for attack_name, attack_info in self.attack_methods.items():
            results, summary = self.test_attack_on_samples(
                model, samples, attack_name,
                attack_info['func'], attack_info['config']
            )
            all_results[attack_name] = results
            all_summaries[attack_name] = summary
            
            print(f"  âœ“ {attack_name.upper()}: ASR={summary['asr']:.1f}%")
        
        # ä¿å­˜ç»“æœ
        output_data = {
            'defense_model': model_key,
            'model_name': model_name,
            'description': self.defense_models[model_key]['description'],
            'test_samples': len(samples),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'summaries': all_summaries,
            'detailed_results': all_results
        }
        
        output_file = self.output_dir / f'{model_key.lower()}_results.json'
        with open(output_file, 'w') as f:
            json.dump(output_data, f, indent=2)
        
        print(f"\nâœ“ ç»“æœå·²ä¿å­˜: {output_file}")
        
        return all_summaries
    
    def run_all_tests(self, num_samples=100):
        """è¿è¡Œæ‰€æœ‰é˜²å¾¡æ¨¡å‹æµ‹è¯•"""
        print("\n" + "ğŸ¯"*30)
        print(f"å¼€å§‹æµ‹è¯• {len(self.defense_models)} ä¸ªé˜²å¾¡æ¨¡å‹")
        print("ğŸ¯"*30)
        
        all_model_results = {}
        
        for model_key in self.defense_models.keys():
            try:
                summaries = self.test_defense_model(model_key, num_samples)
                if summaries:
                    all_model_results[model_key] = summaries
            except Exception as e:
                print(f"\nâŒ æµ‹è¯• {model_key} æ—¶å‡ºé”™: {e}")
                continue
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self.generate_comparison_report(all_model_results)
        
        print("\n" + "ğŸ‰"*30)
        print("æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("ğŸ‰"*30)
        print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
    
    def generate_comparison_report(self, all_results):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
        print("="*60)
        
        report = f"""# å¤šé˜²å¾¡æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**æµ‹è¯•çš„é˜²å¾¡æ¨¡å‹æ•°é‡:** {len(all_results)}  
**æ”»å‡»æ–¹æ³•æ•°é‡:** 5

---

## 1. æµ‹è¯•çš„é˜²å¾¡æ¨¡å‹

"""
        
        for i, (model_key, model_info) in enumerate(self.defense_models.items(), 1):
            if model_key in all_results:
                report += f"{i}. **{model_key}:** {model_info['description']}\n"
        
        report += "\n---\n\n## 2. æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰å¯¹æ¯”\n\n"
        report += "| é˜²å¾¡æ¨¡å‹ | JSMA | SparseFool | Greedy | PixelGrad | RandomSparse |\n"
        report += "|----------|------|------------|--------|-----------|---------------|\n"
        
        for model_key, summaries in all_results.items():
            row = [model_key]
            for method in ['jsma', 'sparsefool', 'greedy', 'pixelgrad', 'randomsparse']:
                asr = summaries.get(method, {}).get('asr', 0)
                row.append(f"{asr:.1f}%")
            report += "| " + " | ".join(row) + " |\n"
        
        report += "\n---\n\n## 3. å¹³å‡L0èŒƒæ•°å¯¹æ¯”\n\n"
        report += "| é˜²å¾¡æ¨¡å‹ | JSMA | SparseFool | Greedy | PixelGrad | RandomSparse |\n"
        report += "|----------|------|------------|--------|-----------|---------------|\n"
        
        for model_key, summaries in all_results.items():
            row = [model_key]
            for method in ['jsma', 'sparsefool', 'greedy', 'pixelgrad', 'randomsparse']:
                l0 = summaries.get(method, {}).get('avg_l0', 0)
                row.append(f"{l0:.2f}")
            report += "| " + " | ".join(row) + " |\n"
        
        report += "\n---\n\n## 4. å…³é”®å‘ç°\n\n"
        
        # æ‰¾å‡ºæœ€é²æ£’çš„æ¨¡å‹
        avg_asrs = {}
        for model_key, summaries in all_results.items():
            asrs = [s.get('asr', 0) for s in summaries.values()]
            avg_asrs[model_key] = np.mean(asrs) if asrs else 0
        
        most_robust = min(avg_asrs.items(), key=lambda x: x[1])
        least_robust = max(avg_asrs.items(), key=lambda x: x[1])
        
        report += f"### 4.1 é˜²å¾¡æ¨¡å‹é²æ£’æ€§æ’å\n\n"
        report += "æŒ‰å¹³å‡ASRæ’åºï¼ˆè¶Šä½è¶Šé²æ£’ï¼‰ï¼š\n\n"
        
        for rank, (model_key, avg_asr) in enumerate(sorted(avg_asrs.items(), key=lambda x: x[1]), 1):
            report += f"{rank}. **{model_key}:** {avg_asr:.1f}% å¹³å‡ASR\n"
        
        report += f"\n### 4.2 ä¸»è¦æ´å¯Ÿ\n\n"
        report += f"1. **æœ€é²æ£’æ¨¡å‹:** {most_robust[0]} (å¹³å‡ASR: {most_robust[1]:.1f}%)\n"
        report += f"2. **æœ€è„†å¼±æ¨¡å‹:** {least_robust[0]} (å¹³å‡ASR: {least_robust[1]:.1f}%)\n"
        report += f"3. **é²æ£’æ€§å·®è·:** {least_robust[1] - most_robust[1]:.1f} ä¸ªç™¾åˆ†ç‚¹\n\n"
        
        report += "### 4.3 æ–¹æ³•-æ¨¡å‹äº¤äº’\n\n"
        report += "åˆ†æä¸åŒé˜²å¾¡ç­–ç•¥å¯¹ä¸åŒæ”»å‡»æ–¹æ³•çš„æ•ˆæœå·®å¼‚...\n\n"
        
        report += f"\n---\n\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.output_dir / 'multi_defense_comparison.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ“ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    if not ROBUSTBENCH_AVAILABLE:
        print("âŒ è¯·å…ˆå®‰è£…RobustBench:")
        print("   pip install git+https://github.com/RobustBench/robustbench.git")
        return 1
    
    tester = MultiDefenseModelTester()
    
    # è¿è¡Œæµ‹è¯•ï¼ˆé»˜è®¤100ä¸ªæ ·æœ¬ï¼‰
    tester.run_all_tests(num_samples=100)
    
    return 0

if __name__ == '__main__':
    exit(main())

